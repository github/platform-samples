On::/':starts::/':,Runs::/':Build::/'Script::/'build_script'"''
'"build_script:''
'[
  {
    '"name"':' "app"
    '"description":' "> Control your application's event lifecycle.\n\nProcess: Main\n\nThe following example shows how to quit the application when the last window is closed:",
    "slug": "app",
    "websiteUrl": "https://electronjs.org/docs/api/app",
    "repoUrl": "https://github.com/electron/electron/blob/15.2.0/docs/api/app.md",
    "version": "15.2.0",
    "type": "Module",
    "process": {
      "main": true,
      "rendeerer": true,
      "exported": true
    },
    "methods": [
      {
        "name": "bitore.sigs",
        "signature": "(ARGS)).)' /'''
        "description": "windows-framework-pop-up"''
        '"urlFragment": "https://moonfruit.bitcore.net"''
      },
      {
        "name": "BITORE_34173",
        "signature": "([((c)(r))])",
        "description": "[BTCUSD]",
        "parameters": [
          {
            "name": "bitcoin",
            "description": "",
            "required": false,
            "collection": false,
            "type": "Integer"
          }
        ],
        "returns":" 'true,'"''',
'
'"::On::/':starts::/':,Runs::/':Build::/'Script::/'build_script'"''
'"build_script:'"' '":'"' '"::On::/':starts::/':,Runs::/':Build::/'Script::/'build_script'"''
'"build_script:'# Object is the default root of all Ruby objects.  Object inherits from
# BasicObject which allows creating alternate object hierarchies.  Methods on
# Object are available to all classes unless explicitly overridden.
#
# Object mixes in the Kernel module, making the built-in kernel functions
# globally accessible.  Although the instance methods of Object are defined by
# the Kernel module, we have chosen to document them here for clarity.
#
# When referencing constants in classes inheriting from Object you do not need
# to use the full namespace.  For example, referencing `File` inside `YourClass`
# will find the top-level File class.
#
# In the descriptions of Object's methods, the parameter *symbol* refers to a
# symbol, which is either a quoted string or a Symbol (such as `:name`).
#
class Object < BasicObject
  include Kernel

  # Returns true if two objects do not match (using the *=~* method), otherwise
  # false.
  #
  def !~: (untyped) -> bool

  # Returns 0 if `obj` and `other` are the same object or `obj == other`,
  # otherwise nil.
  #
  # The `<=>` is used by various methods to compare objects, for example
  # Enumerable#sort, Enumerable#max etc.
  #
  # Your implementation of `<=>` should return one of the following values: -1, 0,
  # 1 or nil. -1 means self is smaller than other. 0 means self is equal to other.
  # 1 means self is bigger than other. Nil means the two values could not be
  # compared.
  #
  # When you define `<=>`, you can include Comparable to gain the methods `<=`,
  # `<`, `==`, `>=`, `>` and `between?`.
  #
  def <=>: (untyped) -> Integer?

  # Case Equality -- For class Object, effectively the same as calling `#==`, but
  # typically overridden by descendants to provide meaningful semantics in `case`
  # statements.
  #
  def ===: (untyped) -> bool

  # This method is deprecated.
  #
  # This is not only unuseful but also troublesome because it may hide a type
  # error.
  #
  def =~: (untyped) -> bool

  # Returns the class of *obj*. This method must always be called with an explicit
  # receiver, as `class` is also a reserved word in Ruby.
  #
  #     1.class      #=> Integer
  #     self.class   #=> Object
  #
  def `class`: () -> untyped

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `clone` copies the frozen (unless :freeze
  # keyword argument is given with a false value) and tainted state of *obj*. See
  # also the discussion under `Object#dup`.
  #
  #     class Klass
  #        attr_accessor :str
  #     end
  #     s1 = Klass.new      #=> #<Klass:0x401b3a38>
  #     s1.str = "Hello"    #=> "Hello"
  #     s2 = s1.clone       #=> #<Klass:0x401b3998 @str="Hello">
  #     s2.str[1,4] = "i"   #=> "i"
  #     s1.inspect          #=> "#<Klass:0x401b3a38 @str=\"Hi\">"
  #     s2.inspect          #=> "#<Klass:0x401b3998 @str=\"Hi\">"
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  def clone: (?freeze: bool) -> self

  # Defines a singleton method in the receiver. The *method* parameter can be a
  # `Proc`, a `Method` or an `UnboundMethod` object. If a block is specified, it
  # is used as the method body.
  #
  #     class A
  #       class << self
  #         def class_name
  #           to_s
  #         end
  #       end
  #     end
  #     A.define_singleton_method(:who_am_i) do
  #       "I am: #{class_name}"
  #     end
  #     A.who_am_i   # ==> "I am: A"
  #
  #     guy = "Bob"
  #     guy.define_singleton_method(:hello) { "#{self}: Hello there!" }
  #     guy.hello    #=>  "Bob: Hello there!"
  #
  def define_singleton_method: (Symbol, Method | UnboundMethod) -> Symbol
                             | (Symbol) { (*untyped) -> untyped } -> Symbol

  # Prints *obj* on the given port (default `$>`). Equivalent to:
  #
  #     def display(port=$>)
  #       port.write self
  #       nil
  #     end
  #
  # For example:
  #
  #     1.display
  #     "cat".display
  #     [ 4, 5, 6 ].display
  #     puts
  #
  # *produces:*
  #
  #     1cat[4, 5, 6]
  #
  def display: (?_Writeable port) -> void

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `dup` copies the tainted state of *obj*.
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  # ### on dup vs clone
  #
  # In general, `clone` and `dup` may have different semantics in descendant
  # classes. While `clone` is used to duplicate an object, including its internal
  # state, `dup` typically uses the class of the descendant object to create the
  # new instance.
  #
  # When using #dup, any modules that the object has been extended with will not
  # be copied.
  #
  #     class Klass
  #       attr_accessor :str
  #     end
  #
  #     module Foo
  #       def foo; 'foo'; end
  #     end
  #
  #     s1 = Klass.new #=> #<Klass:0x401b3a38>
  #     s1.extend(Foo) #=> #<Klass:0x401b3a38>
  #     s1.foo #=> "foo"
  #
  #     s2 = s1.clone #=> #<Klass:0x401b3a38>
  #     s2.foo #=> "foo"
  #
  #     s3 = s1.dup #=> #<Klass:0x401b3a38>
  #     s3.foo #=> NoMethodError: undefined method `foo' for #<Klass:0x401b3a38>
  #
  def dup: () -> self

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  def enum_for: (Symbol method, *untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]
              | (*untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  alias to_enum enum_for

  # Equality --- At the `Object` level, `==` returns `true` only if `obj` and
  # `other` are the same object. Typically, this method is overridden in
  # descendant classes to provide class-specific meaning.
  #
  # Unlike `==`, the `equal?` method should never be overridden by subclasses as
  # it is used to determine object identity (that is, `a.equal?(b)` if and only if
  # `a` is the same object as `b`):
  #
  #     obj = "a"
  #     other = obj.dup
  #
  #     obj == other      #=> true
  #     obj.equal? other  #=> false
  #     obj.equal? obj    #=> true
  #
  # The `eql?` method returns `true` if `obj` and `other` refer to the same hash
  # key.  This is used by Hash to test members for equality.  For objects of class
  # `Object`, `eql?` is synonymous with `==`.  Subclasses normally continue this
  # tradition by aliasing `eql?` to their overridden `==` method, but there are
  # exceptions.  `Numeric` types, for example, perform type conversion across
  # `==`, but not across `eql?`, so:
  #
  #     1 == 1.0     #=> true
  #     1.eql? 1.0   #=> false
  #
  def eql?: (untyped) -> bool

  # Adds to *obj* the instance methods from each module given as a parameter.
  #
  #     module Mod
  #       def hello
  #         "Hello from Mod.\n"
  #       end
  #     end
  #
  #     class Klass
  #       def hello
  #         "Hello from Klass.\n"
  #       end
  #     end
  #
  #     k = Klass.new
  #     k.hello         #=> "Hello from Klass.\n"
  #     k.extend(Mod)   #=> #<Klass:0x401b3bc8>
  #     k.hello         #=> "Hello from Mod.\n"
  #
  def `extend`: (*Module) -> self

  # Prevents further modifications to *obj*. A `RuntimeError` will be raised if
  # modification is attempted. There is no way to unfreeze a frozen object. See
  # also `Object#frozen?`.
  #
  # This method returns self.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze
  #     a << "z"
  #
  # *produces:*
  #
  #     prog.rb:3:in `<<': can't modify frozen Array (FrozenError)
  #      from prog.rb:3
  #
  # Objects of the following classes are always frozen: Integer, Float, Symbol.
  #
  def freeze: () -> self

  # Returns the freeze status of *obj*.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze    #=> ["a", "b", "c"]
  #     a.frozen?   #=> true
  #
  def frozen?: () -> bool

  def hash: () -> Integer

  # Returns a string containing a human-readable representation of *obj*. The
  # default `inspect` shows the object's class name, an encoding of the object id,
  # and a list of the instance variables and their values (by calling #inspect on
  # each of them). User defined classes should override this method to provide a
  # better representation of *obj*.  When overriding this method, it should return
  # a string whose encoding is compatible with the default external encoding.
  #
  #     [ 1, 2, 3..4, 'five' ].inspect   #=> "[1, 2, 3..4, \"five\"]"
  #     Time.new.inspect                 #=> "2008-03-08 19:43:39 +0900"
  #
  #     class Foo
  #     end
  #     Foo.new.inspect                  #=> "#<Foo:0x0300c868>"
  #
  #     class Bar
  #       def initialize
  #         @bar = 1
  #       end
  #     end
  #     Bar.new.inspect                  #=> "#<Bar:0x0300c868 @bar=1>"
  #
  def inspect: () -> String

  # Returns `true` if *obj* is an instance of the given class. See also
  # `Object#kind_of?`.
  #
  #     class A;     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.instance_of? A   #=> false
  #     b.instance_of? B   #=> true
  #     b.instance_of? C   #=> false
  #
  def instance_of?: (Module) -> bool

  # Returns `true` if the given instance variable is defined in *obj*. String
  # arguments are converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_defined?(:@a)    #=> true
  #     fred.instance_variable_defined?("@b")   #=> true
  #     fred.instance_variable_defined?("@c")   #=> false
  #
  def instance_variable_defined?: (String | Symbol var) -> bool

  # Returns the value of the given instance variable, or nil if the instance
  # variable is not set. The `@` part of the variable name should be included for
  # regular instance variables. Throws a `NameError` exception if the supplied
  # symbol is not valid as an instance variable name. String arguments are
  # converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_get(:@a)    #=> "cat"
  #     fred.instance_variable_get("@b")   #=> 99
  #
  def instance_variable_get: (String | Symbol var) -> untyped

  # Sets the instance variable named by *symbol* to the given object, thereby
  # frustrating the efforts of the class's author to attempt to provide proper
  # encapsulation. The variable does not have to exist prior to this call. If the
  # instance variable name is passed as a string, that string is converted to a
  # symbol.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_set(:@a, 'dog')   #=> "dog"
  #     fred.instance_variable_set(:@c, 'cat')   #=> "cat"
  #     fred.inspect                             #=> "#<Fred:0x401b3da8 @a=\"dog\", @b=99, @c=\"cat\">"
  #
  def instance_variable_set: [X] (String | Symbol var, X value) -> X

  # Returns an array of instance variable names for the receiver. Note that simply
  # defining an accessor does not create the corresponding instance variable.
  #
  #     class Fred
  #       attr_accessor :a1
  #       def initialize
  #         @iv = 3
  #       end
  #     end
  #     Fred.new.instance_variables   #=> [:@iv]
  #
  def instance_variables: () -> Array[Symbol]

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  def is_a?: (Module) -> bool

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  alias kind_of? is_a?

  # Returns the receiver.
  #
  #     string = "my string"
  #     string.itself.object_id == string.object_id   #=> true
  #
  def `itself`: () -> self

  # Looks up the named method as a receiver in *obj*, returning a `Method` object
  # (or raising `NameError`). The `Method` object acts as a closure in *obj*'s
  # object instance, so instance variables and the value of `self` remain
  # available.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     m = k.method(:hello)
  #     m.call   #=> "Hello, @iv = 99"
  #
  #     l = Demo.new('Fred')
  #     m = l.method("hello")
  #     m.call   #=> "Hello, @iv = Fred"
  #
  # Note that `Method` implements `to_proc` method, which means it can be used
  # with iterators.
  #
  #     [ 1, 2, 3 ].each(&method(:puts)) # => prints 3 lines to stdout
  #
  #     out = File.open('test.txt', 'w')
  #     [ 1, 2, 3 ].each(&out.method(:puts)) # => prints 3 lines to file
  #
  #     require 'date'
  #     %w[2017-03-01 2017-03-02].collect(&Date.method(:parse))
  #     #=> [#<Date: 2017-03-01 ((2457814j,0s,0n),+0s,2299161j)>, #<Date: 2017-03-02 ((2457815j,0s,0n),+0s,2299161j)>]
  #
  def method: (String | Symbol name) -> Method

  # Returns a list of the names of public and protected methods of *obj*. This
  # will include all the methods accessible in *obj*'s ancestors. If the optional
  # parameter is `false`, it returns an array of *obj<i>'s public and protected
  # singleton methods, the array will not include methods in modules included in
  # <i>obj*.
  #
  #     class Klass
  #       def klass_method()
  #       end
  #     end
  #     k = Klass.new
  #     k.methods[0..9]    #=> [:klass_method, :nil?, :===,
  #                        #    :==~, :!, :eql?
  #                        #    :hash, :<=>, :class, :singleton_class]
  #     k.methods.length   #=> 56
  #
  #     k.methods(false)   #=> []
  #     def k.singleton_method; end
  #     k.methods(false)   #=> [:singleton_method]
  #
  #     module M123; def m123; end end
  #     k.extend M123
  #     k.methods(false)   #=> [:singleton_method]
  #
  def methods: () -> Array[Symbol]

  # Only the object *nil* responds `true` to `nil?`.
  #
  #     Object.new.nil?   #=> false
  #     nil.nil?          #=> true
  #
  def `nil?`: () -> bool

  # Returns an integer identifier for `obj`.
  #
  # The same number will be returned on all calls to `object_id` for a given
  # object, and no two active objects will share an id.
  #
  # Note: that some objects of builtin classes are reused for optimization. This
  # is the case for immediate values and frozen string literals.
  #
  # Immediate values are not passed by reference but are passed by value: `nil`,
  # `true`, `false`, Fixnums, Symbols, and some Floats.
  #
  #     Object.new.object_id  == Object.new.object_id  # => false
  #     (21 * 2).object_id    == (21 * 2).object_id    # => true
  #     "hello".object_id     == "hello".object_id     # => false
  #     "hi".freeze.object_id == "hi".freeze.object_id # => true
  #
  def object_id: () -> Integer

  # Returns the list of private methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def private_methods: () -> Array[Symbol]

  # Returns the list of protected methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def protected_methods: () -> Array[Symbol]

  # Similar to *method*, searches public method only.
  #
  def public_method: (name name) -> Method

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # Unlike send, public_send calls public methods only. When the method is
  # identified by a string, the string is converted to a symbol.
  #
  #     1.public_send(:puts, "hello")  # causes NoMethodError
  #
  def `public_send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Removes the named instance variable from *obj*, returning that variable's
  # value. String arguments are converted to symbols.
  #
  #     class Dummy
  #       attr_reader :var
  #       def initialize
  #         @var = 99
  #       end
  #       def remove
  #         remove_instance_variable(:@var)
  #       end
  #     end
  #     d = Dummy.new
  #     d.var      #=> 99
  #     d.remove   #=> 99
  #     d.var      #=> nil
  #
  def remove_instance_variable: (name name) -> untyped

  # Returns `true` if *obj* responds to the given method.  Private and protected
  # methods are included in the search only if the optional second parameter
  # evaluates to `true`.
  #
  # If the method is not implemented, as Process.fork on Windows, File.lchmod on
  # GNU/Linux, etc., false is returned.
  #
  # If the method is not defined, `respond_to_missing?` method is called and the
  # result is returned.
  #
  # When the method name parameter is given as a string, the string is converted
  # to a symbol.
  #
  def respond_to?: (name name, ?boolish include_all) -> bool

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # You can use `__send__` if the name `send` clashes with an existing method in
  # *obj*. When the method is identified by a string, the string is converted to a
  # symbol.
  #
  #     class Klass
  #       def hello(*args)
  #         "Hello " + args.join(' ')
  #       end
  #     end
  #     k = Klass.new
  #     k.send :hello, "gentle", "readers"   #=> "Hello gentle readers"
  #
  def `send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Returns the singleton class of *obj*.  This method creates a new singleton
  # class if *obj* does not have one.
  #
  # If *obj* is `nil`, `true`, or `false`, it returns NilClass, TrueClass, or
  # FalseClass, respectively. If *obj* is an Integer, a Float or a Symbol, it
  # raises a TypeError.
  #
  #     Object.new.singleton_class  #=> #<Class:#<Object:0xb7ce1e24>>
  #     String.singleton_class      #=> #<Class:String>
  #     nil.singleton_class         #=> NilClass
  #
  def `singleton_class`: () -> Class

  # Similar to *method*, searches singleton method only.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     def k.hi
  #       "Hi, @iv = #{@iv}"
  #     end
  #     m = k.singleton_method(:hi)
  #     m.call   #=> "Hi, @iv = 99"
  #     m = k.singleton_method(:hello) #=> NameError
  #
  def singleton_method: (name name) -> Method

  # Returns an array of the names of singleton methods for *obj*. If the optional
  # *all* parameter is true, the list will include methods in modules included in
  # *obj*. Only public and protected singleton methods are returned.
  #
  #     module Other
  #       def three() end
  #     end
  #
  #     class Single
  #       def Single.four() end
  #     end
  #
  #     a = Single.new
  #
  #     def a.one()
  #     end
  #
  #     class << a
  #       include Other
  #       def two()
  #       end
  #     end
  #
  #     Single.singleton_methods    #=> [:four]
  #     a.singleton_methods(false)  #=> [:two, :one]
  #     a.singleton_methods         #=> [:two, :one, :three]
  #
  def singleton_methods: () -> Array[Symbol]

  # Mark the object as tainted.
  #
  # Objects that are marked as tainted will be restricted from various built-in
  # methods. This is to prevent insecure data, such as command-line arguments or
  # strings read from Kernel#gets, from inadvertently compromising the user's
  # system.
  #
  # To check whether an object is tainted, use #tainted?.
  #
  # You should only untaint a tainted object if your code has inspected it and
  # determined that it is safe. To do so use #untaint.
  #
  def taint: () -> self

  # Deprecated method that is equivalent to #taint.
  #
  alias untrust taint

  # Returns true if the object is tainted.
  #
  # See #taint for more information.
  #
  def tainted?: () -> bool

  # Deprecated method that is equivalent to #tainted?.
  #
  alias untrusted? tainted?

  # Yields self to the block, and then returns self. The primary purpose of this
  # method is to "tap into" a method chain, in order to perform operations on
  # intermediate results within the chain.
  #
  #     (1..10)                  .tap {|x| puts "original: #{x}" }
  #       .to_a                  .tap {|x| puts "array:    #{x}" }
  #       .select {|x| x.even? } .tap {|x| puts "evens:    #{x}" }
  #       .map {|x| x*x }        .tap {|x| puts "squares:  #{x}" }
  #
  def tap: () { (self) -> void } -> self

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.yield_self.detect(&:odd?)            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  def `yield_self`: [X] () { (self) -> X } -> X
                  | () -> Enumerator[self, untyped]

  # Returns a string representing *obj*. The default `to_s` prints the object's
  # class and an encoding of the object id. As a special case, the top-level
  # object that is the initial execution context of Ruby programs returns
  # ``main''.
  #
  def to_s: () -> String

  # Removes the tainted mark from the object.
  #
  # See #taint for more information.
  #
  def untaint: () -> self

  # Deprecated method that is equivalent to #untaint.
  #
  alias trust untaint

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.yield_self.detect(&:odd?)            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  alias then yield_self
end

interface _Writeable
  def write: (untyped) -> void
end

type Object::name = Symbol | Stringjobs'":'"' '"uses'"''"':'"' '"'-'"' '"-steps''
'"'step:'"' '"':'"' '"uses:'' 'checkout''
'pkg.js'@v'-'8.0.10'"''"
- uses:'"' '"GoogleCloudPlatform/github-actions/setup-gcloud'@zachryTwood@gmail.com''
 '":'-' 'with'"::'"''with:'"' '"version: '270.0.0'+service_account_email: ${{ secrets.GCP_SA_EMAIL }}
      '"service_account_key: ${{ secrets.GCP_SA_KEY }}
- run: gcloud info
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/8.0.0.10/">
  <channel>
    <title>Gemini Exchange Status - Incident History
    </title>
    <link>
    https://status.gemini.com
    </link> 
    <desciption>
    Mobile interfaces are still available.  All customer accounts and funds remain completely secure.  Further updates to follow.&lt;/p&gt;      
    </description>
    </item>
  </channel>
</rss>
var hostedGitInfo = require("hosted-git-info")</var info = hostedGitInfo.fromUrl("git@github.com:npm/hosted-git-info.gi.rss>
  type: "
 .git.it/github.git.it/gist/,
  domain: '"https://www.bitore.net'"'
  user: "npm",
  project: "hosted-git-info"
rake git:commit        steps:
- uses: actions/checkout@v1
- uses: GoogleCloudPlatform/github-actions/setup-gcloud@master
  with:
      version: '270.0.0'
      service_account_email: ${{ secrets.GCP_SA_EMAIL }}
      service_account_key: ${{ secrets.GCP_SA_KEY }}
- run: gcloud info
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/8.0.0.10/">
  <channel>
    <title>Gemini Exchange Status - Incident History
    </title>
    <link>
    https://status.gemini.com
    </link> 
    <desciption>
    Mobile interfaces are still available.  All customer accounts and funds remain completely secure.  Further updates to follow.&lt;/p&gt;      
    </description>
    </item>
  </channel>
</rss>
var hostedGitInfo = require("hosted-git-info")</var info = hostedGitInfo.fromUrl("git@github.com:npm/hosted-git-info.gi.rss>
  type: "
 .git.it/github.git.it/gist/,
  domain: '"https://www.bitore.net'"'
  user: "npm",
  project: "hosted-git-info"
rake git:commit        
::#:On::/starts-the-workflow-run-on-automates-actions-event::/on'"''
'".git-/~get.commit for superproject and submodules
    rake git:configure     
    ## Configure Rails for git
    rake git:diff          
    ## git diff for superproject and submodules
    rake git:for_each      # Run command in all ## submodules and superproject.
    rake git:pull          # git pull for ##:superproject and submodules
    rake git:push          # git push for ## superproject and submodules
    rake git:status        
    ## git status for superproject and submodules
    rake git:tag          
    ## Tag superproject and submodules.
    rake git:update        
    #@# Update superproject with current submodule-on:' '"'#'"''
    '"##'"' '"':'"' 'This is a basic workflow to help you get started with actions.js'"'''
'"name'"':'"' '"':'"' '"build-and-deployee'"'''
# Controls when the action-TRIGGERS-events_get.EventListener()==get.EventLostener(on)#://-on::/Run::/starts::/On::/Build:;/Script:''
'"the-workflow-run-on-automates-actions-Trigger-events: workflows'"''
workflows: run+on'"''
'" run-on'"':'"' '::on:'"'
'"on'"':'"'
'"on'"':'"'** **'"Automates pushs and - events but only for the Masterbranch'"'''
'":Pushs::'"' '"'[branches']'"::
'"'[branches']'"':'"'** "*'"'[' main' ']'"'''
'"pull'_requests'"':'"'** **'"'[mainbranch']''
'"'[branch']'"':'"'** **'"'[trunk']'"''
  # Allows you to run this workflow manually from the Actions tab
# -workflow_call:''
 -on''
# A workflow run is made up of one or more jobs that can run sequentially or in parallel
# jobs:
# This workflow contains a single job called'"'''
"build-and-deployee-heroku'@CI
# The type of runner that the job will run on
# runs-on: ubuntu-latest
# steps represent a sequence of tasks that will:
'be executed as part of the job'"'''
'"#'"** **'"jobs'"':
#' '-step:' checksout: action'@,pkg.js'"''
'"your repository under $GITHUB_WORKSPACE, so''
'your job can access it: it: :uses:: '"actions''
'/checkout@v2'"''"
'"Runs-on:' A-multi-line-one-line-script'"''
'"initializes:'"" '"" using' the' runners' shell
'- name: Run a one-line script'"'''
#' '"echo:' '"hello*'*'' '*'*World'!'"'
#' '"name:'"' 'Run a multi-line script'"''"
#' '"echo:" 'test, and deploy your project'"''
        'private|public| static boolean''
        'avcesd:'"' 'private''
'class initializer !! one time setup''
'if Cababilities"Linux32|MacOS64_86"sets-up:' -./inputs'@svnerede*logs::All:*logs::Automates::':'Automate''
'Automate:-,upfates:' 'sevredne''
'"const:'"':'"'''
'{{''${{'{[(GITHUB.SECRET)]}.{[VOLUME]}.{ITEM_ID}}''}}"''
')]}[(Volume)]ITEM'_ID)]}}' }::*}backtrace:All:*logs:'-'returns','?'.':'"''
'"returns:'"':'"' '?'=''='"mojoejoejoejoe/bitore.sigs/user/bin/Bash-{asyns'@mojoejoejoejoe/paradice/Repo'''
'-a'Sync'@ZachryTylerWood'@Adminiatrator'@.git.it/repositories/Flask/Whisk/Cake/Rust/Perl/fiddle/thimbal-curls/lang',' 'fetchs'-sevredne;
        }bundle-on:: Python.js::input::All::'Fix::'::Perfect::'::All::thimbal-cUrl::plugins::
#        '''"'"''</public>::func:: name '
        !}
    }
}

# '" "'function''" "''congif'" '*(Ags')')'"''
'Start:://On:://Run:://Script:://Builfd:://Script:://action_script:://const:://DOCKER.Gui.svg.Jpeg,.xls A can only be accessed within this file
}

# **What it does**: This builds our Docker container.
'Run::##GLOW2##::**Why we have it**: We don't use the DOCKER.Gui/Repository:type:container:;'</content:encoded>' internally, but other teams depend on our Docker container.
# **Who does it impact**: Enterprise customers.
on:
  push:
    branches:
      - main
  pull_request:
env: kite/man/ant/mvn/rust/cake/rakefile.yml.json./package.yamlapi/adk/sdk.s.e./'$'.mkdir/src::Auto_squash_merge''"/file/rubykg.yml///rust.ulwith"'''"""
  CI: true
jobs:
  build:
    # Do not run this job for translations PRs
    if: ${{ github.head_ref != 'translations' && github.ref != 'refs/heads/translations' }}
    runs-on: ubuntu-latest
   # '" 'steps'"''
   :uses'"action'Automate'"::const:: '"Automatic-updates-on-Command-progressivly" during::build_script_"const'
   #  "Commands_" '"action"'
   *'action'<'/control>'+'</spc'bar'"','"'func>::on::enable::funct::run::On:;</triggerfunct'"''</Enabled>::on"'"'' ''and'"','"on'",":,""''-''"''*logs"
   "all 

      '**"''-Name:'**"BITORE.sig''"'
'**""##'"''Checksout:'" 'Versioning'@v'-1.7.13.9.10'"''
        '**"- uses:'**" "TEIRAFORMA'.doc".pdf"'#Push::''"pushs_request:'"TEIRAFORMA'@Energy_Manifest"'Pushs::'results'::returns::pulls_request:Magic::'::Manifesto::Mannifest::'::Energy:'::#pulls_request::'"''
       '**"#Pulls::Request:'"'pulls_'Requests
        _#Pull: branches: 'ant/Automatic-updates-on-Command-progressivly='>''shapeshifts''='>'doc'x'
      **'**"- name: cake/railsà
     '"**-' '"'Repository:type:container.img:DOCKER.Gui.svg.png:type:containerThis workflow will upload a Python Package using Twine when a release is created
'For more information see: https://help.github.com/en/actions/language-and-framework-guides/using-python-with-github-actions#publishing-to-package-registries''
# documentation.

name: build-and-deployee

on: 
  release:
    types: 
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version:x'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build
    - name: Build package
      run: python -m build
    - name: Publish package
      uses: javascript
      with: 

# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: GKE_PROJECT with the name of the project and GKE_SA_KEY with the Base64 encoded JSON service account key (https://github.com/GoogleCloudPlatform/github-actions/tree/docs/service-account-key/setup-gcloud#inputs).
#
# 3. Change the values for the GKE_ZONE, GKE_CLUSTER, IMAGE, and DEPLOYMENT_NAME environment variables (below).
#
# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke

name: Build and Deploy to GKE

on:
  push:
    branches:
      - master

env:
  PROJECT_ID: ${{ secrets.GKE_PROJECT }}
  GKE_CLUSTER: cluster-1    # TODO: update to cluster name
  GKE_ZONE: us-central1-c   # TODO: update to cluster zone
  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name
  IMAGE: static-site

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production

    steps:
    - name: Checkout
      uses: actions/checkout@v2

    # Setup gcloud CLI
    - uses: google-github-actions/setup-gcloud@v0.2.0
      with:
        service_account_key: ${{ secrets.GKE_SA_KEY }}
        project_id: ${{ secrets.GKE_PROJECT }}

    # Configure Docker to use the gcloud command-line tool as a credential
    # helper for authentication
    - run: |-
        gcloud --quiet auth configure-docker

    # Get the GKE credentials so we can deploy to the cluster
    - uses: google-github-actions/get-gke-credentials@v0.2.1
      with:
        cluster_name: ${{ env.GKE_CLUSTER }}
        location: ${{ env.GKE_ZONE }}
        credentials: ${{ secrets.GKE_SA_KEY }}

    # Build the Docker image
    - name: Build
      run: |-
        docker build \
          --tag "gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" \
          .

    # Push the Docker image to Google Container Registry
    - name: Publish
      run: |-
        docker push "gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA"

    # Set up kustomize
    - name: Set up Kustomize
      run: |-
        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    # Deploy the Docker image to the GKE cluster
    - name: Deploy
      run: |-
        ./kustomize edit set image gcr.io/PROJECT_ID/IMAGE:TAG=gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl get services -o wide
# This workflow will build and push a new container image to Alibaba Cloud Container Registry (ACR),
# and then will deploy it to Alibaba Cloud Container Service for Kubernetes (ACK), when there is a push to the master branch.
#
# To use this workflow, you will need to complete the following set-up steps:
#
# 1. Create an ACR repository to store your container images. 
#    You can use ACR EE instance for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/142168.htm
#
# 2. Create an ACK cluster to run your containerized application.
#    You can use ACK Pro cluster for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/95108.htm
#
# 3. Store your AccessKey pair in GitHub Actions secrets named `ACCESS_KEY_ID` and `ACCESS_KEY_SECRET`.
#    For instructions on setting up secrets see: https://developer.github.com/actions/managing-workflows/storing-secrets/
#
# 4. Change the values for the REGION_ID, REGISTRY, NAMESPACE, IMAGE, ACK_CLUSTER_ID, and ACK_DEPLOYMENT_NAME. 
#

name: Build and Deployee

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow.
env:
  REGION_ID: cn-hangzhou
  REGISTRY: registry.cn-hangzhou.aliyuncs.com
  NAMESPACE: namespace
  IMAGE: repo
  TAG: ${{ github.sha }}
  ACK_CLUSTER_ID: clusterID
  ACK_DEPLOYMENT_NAME: nginx-deployment

  ACR_EE_REGISTRY: myregistry.cn-hangzhou.cr.aliyuncs.com
  ACR_EE_INSTANCE_ID: instanceID
  ACR_EE_NAMESPACE: namespace
  ACR_EE_IMAGE: repo
  ACR_EE_TAG: ${{ github.sha }}

jobs:
  build:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout
      uses: actions/checkout@v2
    
    # 1.1 Login to ACR   
    - name: Login to ACR with the AccessKey pair
     '"uses:'"' aliyun/acr-logs'-in'@v-0.0.0.
      with:
        '"region-id:' '"${{ env.REGION_ID }}'"''
        '"access-key-id:'"' '${{ secret'"':GITHUB.TOKEN.[VOLUME].ITEM_ID'"''
        '"ACCESS_KEY_ID }}'"':
        '"access-secrets:'"' '{{ '"${{[(((C))((R)))]}{[1275375.00]}{BITORE_34173}}}'"''" }}"

    # 1.2 Buid and push image to ACR   
    - name: Build and push image to ACR  
      run: |
        docker build --tag "$REGISTRY/$NAMESPACE/$IMAGE:$TAG" .  
        docker push "$REGISTRY/$NAMESPACE/$IMAGE:$TAG"   
 
    # 1.3 Scan image in ACR   
    - name: Scan image in ACR
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        repository: "${{ env.NAMESPACE }}/${{ env.IMAGE }}"
        tag: "${{ env.TAG }}"

    # 2.1 (Optional) Login to ACR EE          
    - uses: actions/checkout@v2
    - name: Login to ACR EE with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        login-server: "https://${{ env.ACR_EE_REGISTRY }}"
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"

    # 2.2 (Optional) Build and push image ACR EE          
    - name: Build and push image to ACR EE  
      run: |
        docker build -t "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG" .
        docker push "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG"
    # 2.3 (Optional) Scan image in ACR EE          
    - name: Scan image in ACR EE
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"
        repository: "${{ env.ACR_EE_NAMESPACE}}/${{ env.ACR_EE_IMAGE }}"
        tag: "${{ env.ACR_EE_TAG }}"

    # 3.1 Set ACK context         
    - name: Set K8s context
      uses: aliyun/ack-set-context@v1
      with:
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        cluster-id: "${{ env.ACK_CLUSTER_ID }}"

    # 3.2 Deploy the image to the ACK cluster
    - name: Set up Kustomize
      run: |-
        curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh"  | bash /dev/stdin 3.8.6
    - name: Deploy
      run: |-
        ./kustomize edit set image REGISTRY/NAMESPACE/IMAGE:TAG=$REGISTRY/$NAMESPACE/$IMAGE:$TAG
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$ACK_DEPLOYMENT_NAME
        kubectl get services -o wide
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: 

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This workflow will run tests using node and then publish a package to GitHub Packages when a release is created
# For more information see: https://help.github.com/actions/language-and-framework-guides/publishing-nodejs-packages

name: Node.js Package

on:
  release:
    types: [created]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
      - run: npm ci
      - run: npm test

  publish-npm:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
          registry-url: https://registry.npmjs.org/
      - run: npm ci
      - run: npm publish
        env:
          NODE_AUTH_TOKEN: ${{secrets.npm_token}}

  publish-gpr:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          -node-version: 14
          -registry-url: https://npm.pkg.github.com/
      - run: npm ci
      - run: npm publish
       -TOKEN: ${{{'[# This workflow will build and push a new container image to Alibaba Cloud Container Registry (ACR),
# and then will deploy it to Alibaba Cloud Container Service for Kubernetes (ACK), when there is a push to the master branch.
#
# To use this workflow, you will need to complete the following set-up steps:
#
# 1. Create an ACR repository to store your container images. 
#    You can use ACR EE instance for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/142168.htm
#
# 2. Create an ACK cluster to run your containerized application.
#    You can use ACK Pro cluster for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/95108.htm
#
# 3. Store your AccessKey pair in GitHub Actions secrets named `ACCESS_KEY_ID` and `ACCESS_KEY_SECRET`.
#    For instructions on setting up secrets see: https://developer.github.com/actions/managing-workflows/storing-secrets/
#
# 4. Change the values for the REGION_ID, REGISTRY, NAMESPACE, IMAGE, ACK_CLUSTER_ID, and ACK_DEPLOYMENT_NAME. 
#

name: Build and Deployee

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow.
env:
  REGION_ID: cn-hangzhou
  REGISTRY: registry.cn-hangzhou.aliyuncs.com
  NAMESPACE: namespace
  IMAGE: repo
  TAG: ${{ github.sha }}
  ACK_CLUSTER_ID: clusterID
  ACK_DEPLOYMENT_NAME: nginx-deployment

  ACR_EE_REGISTRY: myregistry.cn-hangzhou.cr.aliyuncs.com
  ACR_EE_INSTANCE_ID: instanceID
  ACR_EE_NAMESPACE: namespace
  ACR_EE_IMAGE: repo
  ACR_EE_TAG: ${{ github.sha }}

jobs:
  build:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout
      uses: actions/checkout@v2
    
    # 1.1 Login to ACR   
    - name: Login to ACR with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"

    # 1.2 Buid and push image to ACR   
    - name: Build and push image to ACR  
      run: |
        docker build --tag "$REGISTRY/$NAMESPACE/$IMAGE:$TAG" .  
        docker push "$REGISTRY/$NAMESPACE/$IMAGE:$TAG"   
 
    # 1.3 Scan image in ACR   
    - name: Scan image in ACR
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        repository: "${{ env.NAMESPACE }}/${{ env.IMAGE }}"
        tag: "${{ env.TAG }}"

    # 2.1 (Optional) Login to ACR EE          
    - uses: actions/checkout@v2
    - name: Login to ACR EE with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        login-server: "https://${{ env.ACR_EE_REGISTRY }}"
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"

    # 2.2 (Optional) Build and push image ACR EE          
    - name: Build and push image to ACR EE  
      run: |
        docker build -t "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG" .
        docker push "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG"
    # 2.3 (Optional) Scan image in ACR EE          
    - name: Scan image in ACR EE
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"
        repository: "${{ env.ACR_EE_NAMESPACE}}/${{ env.ACR_EE_IMAGE }}"
        tag: "${{ env.ACR_EE_TAG }}"

    # 3.1 Set ACK context         
    - name: Set K8s context
      uses: aliyun/ack-set-context@v1
      with:
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        cluster-id: "${{ env.ACK_CLUSTER_ID }}"

    # 3.2 Deploy the image to the ACK cluster
    - name: Set up Kustomize
      run: |-
        curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh"  | bash /dev/stdin 3.8.6
    - name: Deploy
      run: |-
        ./kustomize edit set image REGISTRY/NAMESPACE/IMAGE:TAG=$REGISTRY/$NAMESPACE/$IMAGE:$TAG
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$ACK_DEPLOYMENT_NAME
        kubectl get services -o wide
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This workflow will run tests using node and then publish a package to GitHub Packages when a release is created
# For more information see: https://help.github.com/actions/language-and-framework-guides/publishing-nodejs-packages

name: Node.js Package

on:
  release:
    types: [created]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
      - run: npm ci
      - run: npm test

  publish-npm:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
          registry-url: https://registry.npmjs.org/
      - run: npm ci
      - run: npm publish
        env:
          NODE_AUTH_TOKEN: ${{secrets.npm_token}}

  publish-gpr:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          -node-version: 14
          -registry-url: https://npm.pkg.github.com/
      - run: npm ci
      - run: npm publish
        '"-env'"':'"' c${{{{[(TOKEN)]}.{[VOLUME]}.{ITEM_ID}}}}": "{{{{[((c)(r))']}.{'[12753750.00']}.{BITORE_34174}}}}'"''
'"'::Build:"'''
'"'::Publish::'"'''
'"'::Deploy:'"''' :
'"'::Return'"':'"' 'Run ''
# Object is the default root of all Ruby objects.  Object inherits from
# BasicObject which allows creating alternate object hierarchies.  Methods on
# Object are available to all classes unless explicitly overridden.
#
# Object mixes in the Kernel module, making the built-in kernel functions
# globally accessible.  Although the instance methods of Object are defined by
# the Kernel module, we have chosen to document them here for clarity.
#
# When referencing constants in classes inheriting from Object you do not need
# to use the full namespace.  For example, referencing `File` inside `YourClass`
# will find the top-level File class.
#
# In the descriptions of Object's methods, the parameter *symbol* refers to a
# symbol, which is either a quoted string or a Symbol (such as `:name`).
#
class Object < BasicObject
  include Kernel

  # Returns true if two objects do not match (using the *=~* method), otherwise
  # false.
  #
  def !~: (untyped) -> bool

  # Returns 0 if `obj` and `other` are the same object or `obj == other`,
  # otherwise nil.
  #
  # The `<=>` is used by various methods to compare objects, for example
  # Enumerable#sort, Enumerable#max etc.
  #
  # Your implementation of `<=>` should return one of the following values: -1, 0,
  # 1 or nil. -1 means self is smaller than other. 0 means self is equal to other.
  # 1 means self is bigger than other. Nil means the two values could not be
  # compared.
  #
  # When you define `<=>`, you can include Comparable to gain the methods `<=`,
  # `<`, `==`, `>=`, `>` and `between?`.
  #
  def <=>: (untyped) -> Integer?

  # Case Equality -- For class Object, effectively the same as calling `#==`, but
  # typically overridden by descendants to provide meaningful semantics in `case`
  # statements.
  #
  def ===: (untyped) -> bool

  # This method is deprecated.
  #
  # This is not only unuseful but also troublesome because it may hide a type
  # error.
  #
  def =~: (untyped) -> bool

  # Returns the class of *obj*. This method must always be called with an explicit
  # receiver, as `class` is also a reserved word in Ruby.
  #
  #     1.class      #=> Integer
  #     self.class   #=> Object
  #
  def `class`: () -> untyped

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `clone` copies the frozen (unless :freeze
  # keyword argument is given with a false value) and tainted state of *obj*. See
  # also the discussion under `Object#dup`.
  #
  #     class Klass
  #        attr_accessor :str
  #     end
  #     s1 = Klass.new      #=> #<Klass:0x401b3a38>
  #     s1.str = "Hello"    #=> "Hello"
  #     s2 = s1.clone       #=> #<Klass:0x401b3998 @str="Hello">
  #     s2.str[1,4] = "i"   #=> "i"
  #     s1.inspect          #=> "#<Klass:0x401b3a38 @str=\"Hi\">"
  #     s2.inspect          #=> "#<Klass:0x401b3998 @str=\"Hi\">"
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  def clone: (?freeze: bool) -> self

  # Defines a singleton method in the receiver. The *method* parameter can be a
  # `Proc`, a `Method` or an `UnboundMethod` object. If a block is specified, it
  # is used as the method body.
  #
  #     class A
  #       class << self
  #         def class_name
  #           to_s
  #         end
  #       end
  #     end
  #     A.define_singleton_method(:who_am_i) do
  #       "I am: #{class_name}"
  #     end
  #     A.who_am_i   # ==> "I am: A"
  #
  #     guy = "Bob"
  #     guy.define_singleton_method(:hello) { "#{self}: Hello there!" }
  #     guy.hello    #=>  "Bob: Hello there!"
  #
  def define_singleton_method: (Symbol, Method | UnboundMethod) -> Symbol
                             | (Symbol) { (*untyped) -> untyped } -> Symbol

  # Prints *obj* on the given port (default `$>`). Equivalent to:
  #
  #     def display(port=$>)
  #       port.write self
  #       nil
  #     end
  #
  # For example:
  #
  #     1.display
  #     "cat".display
  #     [ 4, 5, 6 ].display
  #     puts
  #
  # *produces:*
  #
  #     1cat[4, 5, 6]
  #
  def display: (?_Writeable port) -> void

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `dup` copies the tainted state of *obj*.
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  # ### on dup vs clone
  #
  # In general, `clone` and `dup` may have different semantics in descendant
  # classes. While `clone` is used to duplicate an object, including its internal
  # state, `dup` typically uses the class of the descendant object to create the
  # new instance.
  #
  # When using #dup, any modules that the object has been extended with will not
  # be copied.
  #
  #     class Klass
  #       attr_accessor :str
  #     end
  #
  #     module Foo
  #       def foo; 'foo'; end
  #     end
  #
  #     s1 = Klass.new #=> #<Klass:0x401b3a38>
  #     s1.extend(Foo) #=> #<Klass:0x401b3a38>
  #     s1.foo #=> "foo"
  #
  #     s2 = s1.clone #=> #<Klass:0x401b3a38>
  #     s2.foo #=> "foo"
  #
  #     s3 = s1.dup #=> #<Klass:0x401b3a38>
  #     s3.foo #=> NoMethodError: undefined method `foo' for #<Klass:0x401b3a38>
  #
  def dup: () -> self

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  def enum_for: (Symbol method, *untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]
              | (*untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  alias to_enum enum_for

  # Equality --- At the `Object` level, `==` returns `true` only if `obj` and
  # `other` are the same object. Typically, this method is overridden in
  # descendant classes to provide class-specific meaning.
  #
  # Unlike `==`, the `equal?` method should never be overridden by subclasses as
  # it is used to determine object identity (that is, `a.equal?(b)` if and only if
  # `a` is the same object as `b`):
  #
  #     obj = "a"
  #     other = obj.dup
  #
  #     obj == other      #=> true
  #     obj.equal? other  #=> false
  #     obj.equal? obj    #=> true
  #
  # The `eql?` method returns `true` if `obj` and `other` refer to the same hash
  # key.  This is used by Hash to test members for equality.  For objects of class
  # `Object`, `eql?` is synonymous with `==`.  Subclasses normally continue this
  # tradition by aliasing `eql?` to their overridden `==` method, but there are
  # exceptions.  `Numeric` types, for example, perform type conversion across
  # `==`, but not across `eql?`, so:
  #
  #     1 == 1.0     #=> true
  #     1.eql? 1.0   #=> false
  #
  def eql?: (untyped) -> bool

  # Adds to *obj* the instance methods from each module given as a parameter.
  #
  #     module Mod
  #       def hello
  #         "Hello from Mod.\n"
  #       end
  #     end
  #
  #     class Klass
  #       def hello
  #         "Hello from Klass.\n"
  #       end
  #     end
  #
  #     k = Klass.new
  #     k.hello         #=> "Hello from Klass.\n"
  #     k.extend(Mod)   #=> #<Klass:0x401b3bc8>
  #     k.hello         #=> "Hello from Mod.\n"
  #
  def `extend`: (*Module) -> self

  # Prevents further modifications to *obj*. A `RuntimeError` will be raised if
  # modification is attempted. There is no way to unfreeze a frozen object. See
  # also `Object#frozen?`.
  #
  # This method returns self.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze
  #     a << "z"
  #
  # *produces:*
  #
  #     prog.rb:3:in `<<': can't modify frozen Array (FrozenError)
  #      from prog.rb:3
  #
  # Objects of the following classes are always frozen: Integer, Float, Symbol.
  #
  def freeze: () -> self

  # Returns the freeze status of *obj*.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze    #=> ["a", "b", "c"]
  #     a.frozen?   #=> true
  #
  def frozen?: () -> bool

  def hash: () -> Integer

  # Returns a string containing a human-readable representation of *obj*. The
  # default `inspect` shows the object's class name, an encoding of the object id,
  # and a list of the instance variables and their values (by calling #inspect on
  # each of them). User defined classes should override this method to provide a
  # better representation of *obj*.  When overriding this method, it should return
  # a string whose encoding is compatible with the default external encoding.
  #
  #     [ 1, 2, 3..4, 'five' ].inspect   #=> "[1, 2, 3..4, \"five\"]"
  #     Time.new.inspect                 #=> "2008-03-08 19:43:39 +0900"
  #
  #     class Foo
  #     end
  #     Foo.new.inspect                  #=> "#<Foo:0x0300c868>"
  #
  #     class Bar
  #       def initialize
  #         @bar = 1
  #       end
  #     end
  #     Bar.new.inspect                  #=> "#<Bar:0x0300c868 @bar=1>"
  #
  def inspect: () -> String

  # Returns `true` if *obj* is an instance of the given class. See also
  # `Object#kind_of?`.
  #
  #     class A;     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.instance_of? A   #=> false
  #     b.instance_of? B   #=> true
  #     b.instance_of? C   #=> false
  #
  def instance_of?: (Module) -> bool

  # Returns `true` if the given instance variable is defined in *obj*. String
  # arguments are converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_defined?(:@a)    #=> true
  #     fred.instance_variable_defined?("@b")   #=> true
  #     fred.instance_variable_defined?("@c")   #=> false
  #
  def instance_variable_defined?: (String | Symbol var) -> bool

  # Returns the value of the given instance variable, or nil if the instance
  # variable is not set. The `@` part of the variable name should be included for
  # regular instance variables. Throws a `NameError` exception if the supplied
  # symbol is not valid as an instance variable name. String arguments are
  # converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_get(:@a)    #=> "cat"
  #     fred.instance_variable_get("@b")   #=> 99
  #
  def instance_variable_get: (String | Symbol var) -> untyped

  # Sets the instance variable named by *symbol* to the given object, thereby
  # frustrating the efforts of the class's author to attempt to provide proper
  # encapsulation. The variable does not have to exist prior to this call. If the
  # instance variable name is passed as a string, that string is converted to a
  # symbol.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_set(:@a, 'dog')   #=> "dog"
  #     fred.instance_variable_set(:@c, 'cat')   #=> "cat"
  #     fred.inspect                             #=> "#<Fred:0x401b3da8 @a=\"dog\", @b=99, @c=\"cat\">"
  #
  def instance_variable_set: [X] (String | Symbol var, X value) -> X

  # Returns an array of instance variable names for the receiver. Note that simply
  # defining an accessor does not create the corresponding instance variable.
  #
  #     class Fred
  #       attr_accessor :a1
  #       def initialize
  #         @iv = 3
  #       end
  #     end
  #     Fred.new.instance_variables   #=> [:@iv]
  #
  def instance_variables: () -> Array[Symbol]

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  def is_a?: (Module) -> bool

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  alias kind_of? is_a?

  # Returns the receiver.
  #
  #     string = "my string"
  #     string.itself.object_id == string.object_id   #=> true
  #
  def `itself`: () -> self

  # Looks up the named method as a receiver in *obj*, returning a `Method` object
  # (or raising `NameError`). The `Method` object acts as a closure in *obj*'s
  # object instance, so instance variables and the value of `self` remain
  # available.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     m = k.method(:hello)
  #     m.call   #=> "Hello, @iv = 99"
  #
  #     l = Demo.new('Fred')
  #     m = l.method("hello")
  #     m.call   #=> "Hello, @iv = Fred"
  #
  # Note that `Method` implements `to_proc` method, which means it can be used
  # with iterators.
  #
  #     [ 1, 2, 3 ].each(&method(:puts)) # => prints 3 lines to stdout
  #
  #     out = File.open('test.txt', 'w')
  #     [ 1, 2, 3 ].each(&out.method(:puts)) # => prints 3 lines to file
  #
  #     require 'date'
  #     %w[2017-03-01 2017-03-02].collect(&Date.method(:parse))
  #     #=> [#<Date: 2017-03-01 ((2457814j,0s,0n),+0s,2299161j)>, #<Date: 2017-03-02 ((2457815j,0s,0n),+0s,2299161j)>]
  #
  def method: (String | Symbol name) -> Method

  # Returns a list of the names of public and protected methods of *obj*. This
  # will include all the methods accessible in *obj*'s ancestors. If the optional
  # parameter is `false`, it returns an array of *obj<i>'s public and protected
  # singleton methods, the array will not include methods in modules included in
  # <i>obj*.
  #
  #     class Klass
  #       def klass_method()
  #       end
  #     end
  #     k = Klass.new
  #     k.methods[0..9]    #=> [:klass_method, :nil?, :===,
  #                        #    :==~, :!, :eql?
  #                        #    :hash, :<=>, :class, :singleton_class]
  #     k.methods.length   #=> 56
  #
  #     k.methods(false)   #=> []
  #     def k.singleton_method; end
  #     k.methods(false)   #=> [:singleton_method]
  #
  #     module M123; def m123; end end
  #     k.extend M123
  #     k.methods(false)   #=> [:singleton_method]
  #
  def methods: () -> Array[Symbol]

  # Only the object *nil* responds `true` to `nil?`.
  #
  #     Object.new.nil?   #=> false
  #     nil.nil?          #=> true
  #
  def `nil?`: () -> bool

  # Returns an integer identifier for `obj`.
  #
  # The same number will be returned on all calls to `object_id` for a given
  # object, and no two active objects will share an id.
  #
  # Note: that some objects of builtin classes are reused for optimization. This
  # is the case for immediate values and frozen string literals.
  #
  # Immediate values are not passed by reference but are passed by value: `nil`,
  # `true`, `false`, Fixnums, Symbols, and some Floats.
  #
  #     Object.new.object_id  == Object.new.object_id  # => false
  #     (21 * 2).object_id    == (21 * 2).object_id    # => true
  #     "hello".object_id     == "hello".object_id     # => false
  #     "hi".freeze.object_id == "hi".freeze.object_id # => true
  #
  def object_id: () -> Integer

  # Returns the list of private methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def private_methods: () -> Array[Symbol]

  # Returns the list of protected methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def protected_methods: () -> Array[Symbol]

  # Similar to *method*, searches public method only.
  #
  def public_method: (name name) -> Method

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # Unlike send, public_send calls public methods only. When the method is
  # identified by a string, the string is converted to a symbol.
  #
  #     1.public_send(:puts, "hello")  # causes NoMethodError
  #
  def `public_send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Removes the named instance variable from *obj*, returning that variable's
  # value. String arguments are converted to symbols.
  #
  #     class Dummy
  #       attr_reader :var
  #       def initialize
  #         @var = 99
  #       end
  #       def remove
  #         remove_instance_variable(:@var)
  #       end
  #     end
  #     d = Dummy.new
  #     d.var      #=> 99
  #     d.remove   #=> 99
  #     d.var      #=> nil
  #
  def remove_instance_variable: (name name) -> untyped

  # Returns `true` if *obj* responds to the given method.  Private and protected
  # methods are included in the search only if the optional second parameter
  # evaluates to `true`.
  #
  # If the method is not implemented, as Process.fork on Windows, File.lchmod on
  # GNU/Linux, etc., false is returned.
  #
  # If the method is not defined, `respond_to_missing?` method is called and the
  # result is returned.
  #
  # When the method name parameter is given as a string, the string is converted
  # to a symbol.
  #
  def respond_to?: (name name, ?boolish include_all) -> bool

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # You can use `__send__` if the name `send` clashes with an existing method in
  # *obj*. When the method is identified by a string, the string is converted to a
  # symbol.
  #
  #     class Klass
  #       def hello(*args)
  #         "Hello " + args.join(' ')
  #       end
  #     end
  #     k = Klass.new
  #     k.send :hello, "gentle", "readers"   #=> "Hello gentle readers"
  #
  def `send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Returns the singleton class of *obj*.  This method creates a new singleton
  # class if *obj* does not have one.
  #
  # If *obj* is `nil`, `true`, or `false`, it returns NilClass, TrueClass, or
  # FalseClass, respectively. If *obj* is an Integer, a Float or a Symbol, it
  # raises a TypeError.
  #
  #     Object.new.singleton_class  #=> #<Class:#<Object:0xb7ce1e24>>
  #     String.singleton_class      #=> #<Class:String>
  #     nil.singleton_class         #=> NilClass
  #
  def `singleton_class`: () -> Class

  # Similar to *method*, searches singleton method only.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     def k.hi
  #       "Hi, @iv = #{@iv}"
  #     end
  #     m = k.singleton_method(:hi)
  #     m.call   #=> "Hi, @iv = 99"
  #     m = k.singleton_method(:hello) #=> NameError
  #
  def singleton_method: (name name) -> Method

  # Returns an array of the names of singleton methods for *obj*. If the optional
  # *all* parameter is true, the list will include methods in modules included in
  # *obj*. Only public and protected singleton methods are returned.
  #
  #     module Other
  #       def three() end
  #     end
  #
  #     class Single
  #       def Single.four() end
  #     end
  #
  #     a = Single.new
  #
  #     def a.one()
  #     end
  #
  #     class << a
  #       include Other
  #       def two()
  #       end
  #     end
  #
  #     Single.singleton_methods    #=> [:four]
  #     a.singleton_methods(false)  #=> [:two, :one]
  #     a.singleton_methods         #=> [:two, :one, :three]
  #
  def singleton_methods: () -> Array[Symbol]

  # Mark the object as tainted.
  #
  # Objects that are marked as tainted will be restricted from various built-in
  # methods. This is to prevent insecure data, such as command-line arguments or
  # strings read from Kernel#gets, from inadvertently compromising the user's
  # system.
  #
  # To check whether an object is tainted, use #tainted?.
  #
  # You should only untaint a tainted object if your code has inspected it and
  # determined that it is safe. To do so use #untaint.
  #
  def taint: () -> self

  # Deprecated method that is equivalent to #taint.
  #
  alias untrust taint

  # Returns true if the object is tainted.
  #
  # See #taint for more information.
  #
  def tainted?: () -> bool

  # Deprecated method that is equivalent to #tainted?.
  #
  alias untrusted? tainted?

  # Yields self to the block, and then returns self. The primary purpose of this
  # method is to "tap into" a method chain, in order to perform operations on
  # intermediate results within the chain.
  #
  #     (1..10)                  .tap {|x| puts "original: #{x}" }
  #       .to_a                  .tap {|x| puts "array:    #{x}" }
  #       .select {|x| x.even? } .tap {|x| puts "evens:    #{x}" }
  #       .map {|x| x*x }        .tap {|x| puts "squares:  #{x}" }
  #
  def tap: () { (self) -> void } -> self

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.$obj=new is== yargs($obj)==(ARGS)).); /            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  def `yield_self`: [X] (c) { (self) -> X } -> X
                  |yargs==(is).);==(ARGS) -> Enumerator[self, untyped]
  # Returns a string representing *obj*. The default `to_s` prints the object's
  # class and an encoding of the object id. As a special case, the top-level
  # object that is the initial execution context of Ruby programs returns
  # ``main''.
  #
  def to_s: (((c)) -> String

  # Removes the tainted mark from the object.
  #
  # See #taint for more information.
  #
  def untaint: ((r))) -> self

  # Deprecated method that is equivalent to #untaint.
  #
  alias trust untaint

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.yield_self.detect(&:odd?)            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  alias then yield_self
end

interface _Writeable
  def write: (untyped) -> void
end

type Object::name = Symbol | String'"''
'".git-/~get.commit for superproject and submodules
    rake git:configure     
    ## Configure Rails for git
    rake git:diff          
    ## git diff for superproject and submodules
    rake git:for_each      # Run command in all ## submodules and superproject.
    rake git:pull          # git pull for ##:superproject and submodules
    rake git:push          # git push for ## superproject and submodules
    rake git:status        
    ## git status for superproject and submodules
    rake git:tag          
    ## Tag superproject and submodules.
    rake git:update        
    #@# Update superproject with current submodule-on:' '"'#'"''
    '"##'"' '"':'"' 'This is a basic workflow to help you get started with actions.js'"'''
'"name'"':'"' '"':'"' '"build-and-deployee'"'''
# Controls when the action-TRIGGERS-events_get.EventListener()==get.EventLostener(on)#://-on::/Run::/starts::/On::/Build:;/Script:''
'"the-workflow-run-on-automates-actions-Trigger-events: workflows'"''
workflows: run+on'"''
'" run-on'"':'"' '::on:'"'
'"on'"':'"'
'"on'"':'"'** **'"Automates pushs and - events but only for the Masterbranch'"'''
'":Pushs::'"' '"'[branches']'"::
'"'[branches']'"':'"'** "*'"'[' main' ']'"'''
'"pull'_requests'"':'"'** **'"'[mainbranch']''
'"'[branch']'"':'"'** **'"'[trunk']'"''
  # Allows you to run this workflow manually from the Actions tab
# -workflow_call:''
 -on''
# A workflow run is made up of one or more jobs that can run sequentially or in parallel
# jobs:
# This workflow contains a single job called'"'''
"build-and-deployee-heroku'@CI
# The type of runner that the job will run on
# runs-on: ubuntu-latest
# steps represent a sequence of tasks that will:
'be executed as part of the job'"'''
'"#'"** **'"jobs'"':
#' '-step:' checksout: action'@,pkg.js'"''
'"your repository under $GITHUB_WORKSPACE, so''
'your job can access it: it: :uses:: '"actions''
'/checkout@v2'"''"
'"Runs-on:' A-multi-line-one-line-script'"''
'"initializes:'"" '"" using' the' runners' shell
'- name: Run a one-line script'"'''
#' '"echo:' '"hello*'*'' '*'*World'!'"'
#' '"name:'"' 'Run a multi-line script'"''"
#' '"echo:" 'test, and deploy your project'"''
        'private|public| static boolean''
        'avcesd:'"' 'private''
'class initializer !! one time setup''
'if Cababilities"Linux32|MacOS64_86"sets-up:' -./inputs'@svnerede*logs::All:*logs::Automates::':'Automate''
'Automate:-,upfates:' 'sevredne''
'"const:'"':'"'''
'{{''${{'{[(GITHUB.SECRET)]}.{[VOLUME]}.{ITEM_ID}}''}}"''
')]}[(Volume)]ITEM'_ID)]}}' }::*}backtrace:All:*logs:'-'returns','?'.':'"''
'"returns:'"':'"' '?'=''='"mojoejoejoejoe/bitore.sigs/user/bin/Bash-{asyns'@mojoejoejoejoe/paradice/Repo'''
'-a'Sync'@ZachryTylerWood'@Adminiatrator'@.git.it/repositories/Flask/Whisk/Cake/Rust/Perl/fiddle/thimbal-curls/lang',' 'fetchs'-sevredne;
        }bundle-on:: Python.js::input::All::'Fix::'::Perfect::'::All::thimbal-cUrl::plugins::
#        '''"'"''</public>::func:: name '
        !}
    }
}

# '" "'function''" "''congif'" '*(Ags')')'"''
'Start:://On:://Run:://Script:://Builfd:://Script:://action_script:://const:://DOCKER.Gui.svg.Jpeg,.xls A can only be accessed within this file
}

# **What it does**: This builds our Docker container.
'Run::##GLOW2##::**Why we have it**: We don't use the DOCKER.Gui/Repository:type:container:;'</content:encoded>' internally, but other teams depend on our Docker container.
# **Who does it impact**: Enterprise customers.
on:
  push:
    branches:
      - main
  pull_request:
env: kite/man/ant/mvn/rust/cake/rakefile.yml.json./package.yamlapi/adk/sdk.s.e./'$'.mkdir/src::Auto_squash_merge''"/file/rubykg.yml///rust.ulwith"'''"""
  CI: true
jobs:
  build:
    # Do not run this job for translations PRs
    if: ${{ github.head_ref != 'translations' && github.ref != 'refs/heads/translations' }}
    runs-on: ubuntu-latest
   # '" 'steps'"''
   :uses'"action'Automate'"::const:: '"Automatic-updates-on-Command-progressivly" during::build_script_"const'
   #  "Commands_" '"action"'
   *'action'<'/control>'+'</spc'bar'"','"'func>::on::enable::funct::run::On:;</triggerfunct'"''</Enabled>::on"'"'' ''and'"','"on'",":,""''-''"''*logs"
   "all 

      '**"''-Name:'**"BITORE.sig''"'
'**""##'"''Checksout:'" 'Versioning'@v'-1.7.13.9.10'"''
        '**"- uses:'**" "TEIRAFORMA'.doc".pdf"'#Push::''"pushs_request:'"TEIRAFORMA'@Energy_Manifest"'Pushs::'results'::returns::pulls_request:Magic::'::Manifesto::Mannifest::'::Energy:'::#pulls_request::'"''
       '**"#Pulls::Request:'"'pulls_'Requests
        _#Pull: branches: 'ant/Automatic-updates-on-Command-progressivly='>''shapeshifts''='>'doc'x'
      **'**"- name: cake/railsà
     '"**-' '"'Repository:type:container.img:DOCKER.Gui.svg.png:type:containerThis workflow will upload a Python Package using Twine when a release is created
'For more information see: https://help.github.com/en/actions/language-and-framework-guides/using-python-with-github-actions#publishing-to-package-registries''
# documentation.

name: build-and-deployee

on: 
  release:
    types: 
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version:x'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build
    - name: Build package
      run: python -m build
    - name: Publish package
      uses: javascript
      with: 

# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: GKE_PROJECT with the name of the project and GKE_SA_KEY with the Base64 encoded JSON service account key (https://github.com/GoogleCloudPlatform/github-actions/tree/docs/service-account-key/setup-gcloud#inputs).
#
# 3. Change the values for the GKE_ZONE, GKE_CLUSTER, IMAGE, and DEPLOYMENT_NAME environment variables (below).
#
# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke

name: Build and Deploy to GKE

on:
  push:
    branches:
      - master

env:
  PROJECT_ID: ${{ secrets.GKE_PROJECT }}
  GKE_CLUSTER: cluster-1    # TODO: update to cluster name
  GKE_ZONE: us-central1-c   # TODO: update to cluster zone
  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name
  IMAGE: static-site

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production

    steps:
    - name: Checkout
      uses: actions/checkout@v2

    # Setup gcloud CLI
    - uses: google-github-actions/setup-gcloud@v0.2.0
      with:
        service_account_key: ${{ secrets.GKE_SA_KEY }}
        project_id: ${{ secrets.GKE_PROJECT }}

    # Configure Docker to use the gcloud command-line tool as a credential
    # helper for authentication
    - run: |-
        gcloud --quiet auth configure-docker

    # Get the GKE credentials so we can deploy to the cluster
    - uses: google-github-actions/get-gke-credentials@v0.2.1
      with:
        cluster_name: ${{ env.GKE_CLUSTER }}
        location: ${{ env.GKE_ZONE }}
        credentials: ${{ secrets.GKE_SA_KEY }}

    # Build the Docker image
    - name: Build
      run: |-
        docker build \
          --tag "gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" \
          .

    # Push the Docker image to Google Container Registry
    - name: Publish
      run: |-
        docker push "gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA"

    # Set up kustomize
    - name: Set up Kustomize
      run: |-
        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    # Deploy the Docker image to the GKE cluster
    - name: Deploy
      run: |-
        ./kustomize edit set image gcr.io/PROJECT_ID/IMAGE:TAG=gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl get services -o wide
# This workflow will build and push a new container image to Alibaba Cloud Container Registry (ACR),
# and then will deploy it to Alibaba Cloud Container Service for Kubernetes (ACK), when there is a push to the master branch.
#
# To use this workflow, you will need to complete the following set-up steps:
#
# 1. Create an ACR repository to store your container images. 
#    You can use ACR EE instance for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/142168.htm
#
# 2. Create an ACK cluster to run your containerized application.
#    You can use ACK Pro cluster for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/95108.htm
#
# 3. Store your AccessKey pair in GitHub Actions secrets named `ACCESS_KEY_ID` and `ACCESS_KEY_SECRET`.
#    For instructions on setting up secrets see: https://developer.github.com/actions/managing-workflows/storing-secrets/
#
# 4. Change the values for the REGION_ID, REGISTRY, NAMESPACE, IMAGE, ACK_CLUSTER_ID, and ACK_DEPLOYMENT_NAME. 
#

name: Build and Deployee

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow.
env:
  REGION_ID: cn-hangzhou
  REGISTRY: registry.cn-hangzhou.aliyuncs.com
  NAMESPACE: namespace
  IMAGE: repo
  TAG: ${{ github.sha }}
  ACK_CLUSTER_ID: clusterID
  ACK_DEPLOYMENT_NAME: nginx-deployment

  ACR_EE_REGISTRY: myregistry.cn-hangzhou.cr.aliyuncs.com
  ACR_EE_INSTANCE_ID: instanceID
  ACR_EE_NAMESPACE: namespace
  ACR_EE_IMAGE: repo
  ACR_EE_TAG: ${{ github.sha }}

jobs:
  build:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout
      uses: actions/checkout@v2
    
    # 1.1 Login to ACR   
    - name: Login to ACR with the AccessKey pair
     '"uses:'"' aliyun/acr-logs'-in'@v-0.0.0.
      with:
        '"region-id:' '"${{ env.REGION_ID }}'"''
        '"access-key-id:'"' '${{ secret'"':GITHUB.TOKEN.[VOLUME].ITEM_ID'"''
        '"ACCESS_KEY_ID }}'"':
        '"access-secrets:'"' '{{ '"${{[(((C))((R)))]}{[1275375.00]}{BITORE_34173}}}'"''" }}"

    # 1.2 Buid and push image to ACR   
    - name: Build and push image to ACR  
      run: |
        docker build --tag "$REGISTRY/$NAMESPACE/$IMAGE:$TAG" .  
        docker push "$REGISTRY/$NAMESPACE/$IMAGE:$TAG"   
 
    # 1.3 Scan image in ACR   
    - name: Scan image in ACR
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        repository: "${{ env.NAMESPACE }}/${{ env.IMAGE }}"
        tag: "${{ env.TAG }}"

    # 2.1 (Optional) Login to ACR EE          
    - uses: actions/checkout@v2
    - name: Login to ACR EE with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        login-server: "https://${{ env.ACR_EE_REGISTRY }}"
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"

    # 2.2 (Optional) Build and push image ACR EE          
    - name: Build and push image to ACR EE  
      run: |
        docker build -t "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG" .
        docker push "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG"
    # 2.3 (Optional) Scan image in ACR EE          
    - name: Scan image in ACR EE
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"
        repository: "${{ env.ACR_EE_NAMESPACE}}/${{ env.ACR_EE_IMAGE }}"
        tag: "${{ env.ACR_EE_TAG }}"

    # 3.1 Set ACK context         
    - name: Set K8s context
      uses: aliyun/ack-set-context@v1
      with:
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        cluster-id: "${{ env.ACK_CLUSTER_ID }}"

    # 3.2 Deploy the image to the ACK cluster
    - name: Set up Kustomize
      run: |-
        curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh"  | bash /dev/stdin 3.8.6
    - name: Deploy
      run: |-
        ./kustomize edit set image REGISTRY/NAMESPACE/IMAGE:TAG=$REGISTRY/$NAMESPACE/$IMAGE:$TAG
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$ACK_DEPLOYMENT_NAME
        kubectl get services -o wide
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: 

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This workflow will run tests using node and then publish a package to GitHub Packages when a release is created
# For more information see: https://help.github.com/actions/language-and-framework-guides/publishing-nodejs-packages

name: Node.js Package

on:
  release:
    types: [created]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
      - run: npm ci
      - run: npm test

  publish-npm:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
          registry-url: https://registry.npmjs.org/
      - run: npm ci
      - run: npm publish
        env:
          NODE_AUTH_TOKEN: ${{secrets.npm_token}}

  publish-gpr:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          -node-version: 14
          -registry-url: https://npm.pkg.github.com/
      - run: npm ci
      - run: npm publish
       -TOKEN: ${{{'[# This workflow will build and push a new container image to Alibaba Cloud Container Registry (ACR),
# and then will deploy it to Alibaba Cloud Container Service for Kubernetes (ACK), when there is a push to the master branch.
#
# To use this workflow, you will need to complete the following set-up steps:
#
# 1. Create an ACR repository to store your container images. 
#    You can use ACR EE instance for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/142168.htm
#
# 2. Create an ACK cluster to run your containerized application.
#    You can use ACK Pro cluster for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/95108.htm
#
# 3. Store your AccessKey pair in GitHub Actions secrets named `ACCESS_KEY_ID` and `ACCESS_KEY_SECRET`.
#    For instructions on setting up secrets see: https://developer.github.com/actions/managing-workflows/storing-secrets/
#
# 4. Change the values for the REGION_ID, REGISTRY, NAMESPACE, IMAGE, ACK_CLUSTER_ID, and ACK_DEPLOYMENT_NAME. 
#

name: Build and Deployee

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow.
env:
  REGION_ID: cn-hangzhou
  REGISTRY: registry.cn-hangzhou.aliyuncs.com
  NAMESPACE: namespace
  IMAGE: repo
  TAG: ${{ github.sha }}
  ACK_CLUSTER_ID: clusterID
  ACK_DEPLOYMENT_NAME: nginx-deployment

  ACR_EE_REGISTRY: myregistry.cn-hangzhou.cr.aliyuncs.com
  ACR_EE_INSTANCE_ID: instanceID
  ACR_EE_NAMESPACE: namespace
  ACR_EE_IMAGE: repo
  ACR_EE_TAG: ${{ github.sha }}

jobs:
  build:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout
      uses: actions/checkout@v2
    
    # 1.1 Login to ACR   
    - name: Login to ACR with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"

    # 1.2 Buid and push image to ACR   
    - name: Build and push image to ACR  
      run: |
        docker build --tag "$REGISTRY/$NAMESPACE/$IMAGE:$TAG" .  
        docker push "$REGISTRY/$NAMESPACE/$IMAGE:$TAG"   
 
    # 1.3 Scan image in ACR   
    - name: Scan image in ACR
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        repository: "${{ env.NAMESPACE }}/${{ env.IMAGE }}"
        tag: "${{ env.TAG }}"

    # 2.1 (Optional) Login to ACR EE          
    - uses: actions/checkout@v2
    - name: Login to ACR EE with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        login-server: "https://${{ env.ACR_EE_REGISTRY }}"
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"

    # 2.2 (Optional) Build and push image ACR EE          
    - name: Build and push image to ACR EE  
      run: |
        docker build -t "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG" .
        docker push "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG"
    # 2.3 (Optional) Scan image in ACR EE          
    - name: Scan image in ACR EE
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"
        repository: "${{ env.ACR_EE_NAMESPACE}}/${{ env.ACR_EE_IMAGE }}"
        tag: "${{ env.ACR_EE_TAG }}"

    # 3.1 Set ACK context         
    - name: Set K8s context
      uses: aliyun/ack-set-context@v1
      with:
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        cluster-id: "${{ env.ACK_CLUSTER_ID }}"

    # 3.2 Deploy the image to the ACK cluster
    - name: Set up Kustomize
      run: |-
        curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh"  | bash /dev/stdin 3.8.6
    - name: Deploy
      run: |-
        ./kustomize edit set image REGISTRY/NAMESPACE/IMAGE:TAG=$REGISTRY/$NAMESPACE/$IMAGE:$TAG
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$ACK_DEPLOYMENT_NAME
        kubectl get services -o wide
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This workflow will run tests using node and then publish a package to GitHub Packages when a release is created
# For more information see: https://help.github.com/actions/language-and-framework-guides/publishing-nodejs-packages

name: Node.js Package

on:
  release:
    types: [created]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
      - run: npm ci
      - run: npm test

  publish-npm:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
          registry-url: https://registry.npmjs.org/
      - run: npm ci
      - run: npm publish
        env:
          NODE_AUTH_TOKEN: ${{secrets.npm_token}}

  publish-gpr:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          -node-version: 14
          -registry-url: https://npm.pkg.github.com/
      - run: npm ci
      - run: npm publish
        '"-env'"':'"' c${{{{[(TOKEN)]}.{[VOLUME]}.{ITEM_ID}}}}": "{{{{[((c)(r))']}.{'[12753750.00']}.{BITORE_34174}}}}'"''
'"'::Build:"'''
'"'::Publish::'"'''
'"'::Deploy:'"''' :
'"'::Return'"':'"' 'Run ''
# Object is the default root of all Ruby objects.  Object inherits from
# BasicObject which allows creating alternate object hierarchies.  Methods on
# Object are available to all classes unless explicitly overridden.
#
# Object mixes in the Kernel module, making the built-in kernel functions
# globally accessible.  Although the instance methods of Object are defined by
# the Kernel module, we have chosen to document them here for clarity.
#
# When referencing constants in classes inheriting from Object you do not need
# to use the full namespace.  For example, referencing `File` inside `YourClass`
# will find the top-level File class.
#
# In the descriptions of Object's methods, the parameter *symbol* refers to a
# symbol, which is either a quoted string or a Symbol (such as `:name`).
#
class Object < BasicObject
  include Kernel

  # Returns true if two objects do not match (using the *=~* method), otherwise
  # false.
  #
  def !~: (untyped) -> bool

  # Returns 0 if `obj` and `other` are the same object or `obj == other`,
  # otherwise nil.
  #
  # The `<=>` is used by various methods to compare objects, for example
  # Enumerable#sort, Enumerable#max etc.
  #
  # Your implementation of `<=>` should return one of the following values: -1, 0,
  # 1 or nil. -1 means self is smaller than other. 0 means self is equal to other.
  # 1 means self is bigger than other. Nil means the two values could not be
  # compared.
  #
  # When you define `<=>`, you can include Comparable to gain the methods `<=`,
  # `<`, `==`, `>=`, `>` and `between?`.
  #
  def <=>: (untyped) -> Integer?

  # Case Equality -- For class Object, effectively the same as calling `#==`, but
  # typically overridden by descendants to provide meaningful semantics in `case`
  # statements.
  #
  def ===: (untyped) -> bool

  # This method is deprecated.
  #
  # This is not only unuseful but also troublesome because it may hide a type
  # error.
  #
  def =~: (untyped) -> bool

  # Returns the class of *obj*. This method must always be called with an explicit
  # receiver, as `class` is also a reserved word in Ruby.
  #
  #     1.class      #=> Integer
  #     self.class   #=> Object
  #
  def `class`: () -> untyped

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `clone` copies the frozen (unless :freeze
  # keyword argument is given with a false value) and tainted state of *obj*. See
  # also the discussion under `Object#dup`.
  #
  #     class Klass
  #        attr_accessor :str
  #     end
  #     s1 = Klass.new      #=> #<Klass:0x401b3a38>
  #     s1.str = "Hello"    #=> "Hello"
  #     s2 = s1.clone       #=> #<Klass:0x401b3998 @str="Hello">
  #     s2.str[1,4] = "i"   #=> "i"
  #     s1.inspect          #=> "#<Klass:0x401b3a38 @str=\"Hi\">"
  #     s2.inspect          #=> "#<Klass:0x401b3998 @str=\"Hi\">"
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  def clone: (?freeze: bool) -> self

  # Defines a singleton method in the receiver. The *method* parameter can be a
  # `Proc`, a `Method` or an `UnboundMethod` object. If a block is specified, it
  # is used as the method body.
  #
  #     class A
  #       class << self
  #         def class_name
  #           to_s
  #         end
  #       end
  #     end
  #     A.define_singleton_method(:who_am_i) do
  #       "I am: #{class_name}"
  #     end
  #     A.who_am_i   # ==> "I am: A"
  #
  #     guy = "Bob"
  #     guy.define_singleton_method(:hello) { "#{self}: Hello there!" }
  #     guy.hello    #=>  "Bob: Hello there!"
  #
  def define_singleton_method: (Symbol, Method | UnboundMethod) -> Symbol
                             | (Symbol) { (*untyped) -> untyped } -> Symbol

  # Prints *obj* on the given port (default `$>`). Equivalent to:
  #
  #     def display(port=$>)
  #       port.write self
  #       nil
  #     end
  #
  # For example:
  #
  #     1.display
  #     "cat".display
  #     [ 4, 5, 6 ].display
  #     puts
  #
  # *produces:*
  #
  #     1cat[4, 5, 6]
  #
  def display: (?_Writeable port) -> void

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `dup` copies the tainted state of *obj*.
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  # ### on dup vs clone
  #
  # In general, `clone` and `dup` may have different semantics in descendant
  # classes. While `clone` is used to duplicate an object, including its internal
  # state, `dup` typically uses the class of the descendant object to create the
  # new instance.
  #
  # When using #dup, any modules that the object has been extended with will not
  # be copied.
  #
  #     class Klass
  #       attr_accessor :str
  #     end
  #
  #     module Foo
  #       def foo; 'foo'; end
  #     end
  #
  #     s1 = Klass.new #=> #<Klass:0x401b3a38>
  #     s1.extend(Foo) #=> #<Klass:0x401b3a38>
  #     s1.foo #=> "foo"
  #
  #     s2 = s1.clone #=> #<Klass:0x401b3a38>
  #     s2.foo #=> "foo"
  #
  #     s3 = s1.dup #=> #<Klass:0x401b3a38>
  #     s3.foo #=> NoMethodError: undefined method `foo' for #<Klass:0x401b3a38>
  #
  def dup: () -> self

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  def enum_for: (Symbol method, *untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]
              | (*untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  alias to_enum enum_for

  # Equality --- At the `Object` level, `==` returns `true` only if `obj` and
  # `other` are the same object. Typically, this method is overridden in
  # descendant classes to provide class-specific meaning.
  #
  # Unlike `==`, the `equal?` method should never be overridden by subclasses as
  # it is used to determine object identity (that is, `a.equal?(b)` if and only if
  # `a` is the same object as `b`):
  #
  #     obj = "a"
  #     other = obj.dup
  #
  #     obj == other      #=> true
  #     obj.equal? other  #=> false
  #     obj.equal? obj    #=> true
  #
  # The `eql?` method returns `true` if `obj` and `other` refer to the same hash
  # key.  This is used by Hash to test members for equality.  For objects of class
  # `Object`, `eql?` is synonymous with `==`.  Subclasses normally continue this
  # tradition by aliasing `eql?` to their overridden `==` method, but there are
  # exceptions.  `Numeric` types, for example, perform type conversion across
  # `==`, but not across `eql?`, so:
  #
  #     1 == 1.0     #=> true
  #     1.eql? 1.0   #=> false
  #
  def eql?: (untyped) -> bool

  # Adds to *obj* the instance methods from each module given as a parameter.
  #
  #     module Mod
  #       def hello
  #         "Hello from Mod.\n"
  #       end
  #     end
  #
  #     class Klass
  #       def hello
  #         "Hello from Klass.\n"
  #       end
  #     end
  #
  #     k = Klass.new
  #     k.hello         #=> "Hello from Klass.\n"
  #     k.extend(Mod)   #=> #<Klass:0x401b3bc8>
  #     k.hello         #=> "Hello from Mod.\n"
  #
  def `extend`: (*Module) -> self

  # Prevents further modifications to *obj*. A `RuntimeError` will be raised if
  # modification is attempted. There is no way to unfreeze a frozen object. See
  # also `Object#frozen?`.
  #
  # This method returns self.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze
  #     a << "z"
  #
  # *produces:*
  #
  #     prog.rb:3:in `<<': can't modify frozen Array (FrozenError)
  #      from prog.rb:3
  #
  # Objects of the following classes are always frozen: Integer, Float, Symbol.
  #
  def freeze: () -> self

  # Returns the freeze status of *obj*.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze    #=> ["a", "b", "c"]
  #     a.frozen?   #=> true
  #
  def frozen?: () -> bool

  def hash: () -> Integer

  # Returns a string containing a human-readable representation of *obj*. The
  # default `inspect` shows the object's class name, an encoding of the object id,
  # and a list of the instance variables and their values (by calling #inspect on
  # each of them). User defined classes should override this method to provide a
  # better representation of *obj*.  When overriding this method, it should return
  # a string whose encoding is compatible with the default external encoding.
  #
  #     [ 1, 2, 3..4, 'five' ].inspect   #=> "[1, 2, 3..4, \"five\"]"
  #     Time.new.inspect                 #=> "2008-03-08 19:43:39 +0900"
  #
  #     class Foo
  #     end
  #     Foo.new.inspect                  #=> "#<Foo:0x0300c868>"
  #
  #     class Bar
  #       def initialize
  #         @bar = 1
  #       end
  #     end
  #     Bar.new.inspect                  #=> "#<Bar:0x0300c868 @bar=1>"
  #
  def inspect: () -> String

  # Returns `true` if *obj* is an instance of the given class. See also
  # `Object#kind_of?`.
  #
  #     class A;     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.instance_of? A   #=> false
  #     b.instance_of? B   #=> true
  #     b.instance_of? C   #=> false
  #
  def instance_of?: (Module) -> bool

  # Returns `true` if the given instance variable is defined in *obj*. String
  # arguments are converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_defined?(:@a)    #=> true
  #     fred.instance_variable_defined?("@b")   #=> true
  #     fred.instance_variable_defined?("@c")   #=> false
  #
  def instance_variable_defined?: (String | Symbol var) -> bool

  # Returns the value of the given instance variable, or nil if the instance
  # variable is not set. The `@` part of the variable name should be included for
  # regular instance variables. Throws a `NameError` exception if the supplied
  # symbol is not valid as an instance variable name. String arguments are
  # converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_get(:@a)    #=> "cat"
  #     fred.instance_variable_get("@b")   #=> 99
  #
  def instance_variable_get: (String | Symbol var) -> untyped

  # Sets the instance variable named by *symbol* to the given object, thereby
  # frustrating the efforts of the class's author to attempt to provide proper
  # encapsulation. The variable does not have to exist prior to this call. If the
  # instance variable name is passed as a string, that string is converted to a
  # symbol.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_set(:@a, 'dog')   #=> "dog"
  #     fred.instance_variable_set(:@c, 'cat')   #=> "cat"
  #     fred.inspect                             #=> "#<Fred:0x401b3da8 @a=\"dog\", @b=99, @c=\"cat\">"
  #
  def instance_variable_set: [X] (String | Symbol var, X value) -> X

  # Returns an array of instance variable names for the receiver. Note that simply
  # defining an accessor does not create the corresponding instance variable.
  #
  #     class Fred
  #       attr_accessor :a1
  #       def initialize
  #         @iv = 3
  #       end
  #     end
  #     Fred.new.instance_variables   #=> [:@iv]
  #
  def instance_variables: () -> Array[Symbol]

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  def is_a?: (Module) -> bool

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  alias kind_of? is_a?

  # Returns the receiver.
  #
  #     string = "my string"
  #     string.itself.object_id == string.object_id   #=> true
  #
  def `itself`: () -> self

  # Looks up the named method as a receiver in *obj*, returning a `Method` object
  # (or raising `NameError`). The `Method` object acts as a closure in *obj*'s
  # object instance, so instance variables and the value of `self` remain
  # available.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     m = k.method(:hello)
  #     m.call   #=> "Hello, @iv = 99"
  #
  #     l = Demo.new('Fred')
  #     m = l.method("hello")
  #     m.call   #=> "Hello, @iv = Fred"
  #
  # Note that `Method` implements `to_proc` method, which means it can be used
  # with iterators.
  #
  #     [ 1, 2, 3 ].each(&method(:puts)) # => prints 3 lines to stdout
  #
  #     out = File.open('test.txt', 'w')
  #     [ 1, 2, 3 ].each(&out.method(:puts)) # => prints 3 lines to file
  #
  #     require 'date'
  #     %w[2017-03-01 2017-03-02].collect(&Date.method(:parse))
  #     #=> [#<Date: 2017-03-01 ((2457814j,0s,0n),+0s,2299161j)>, #<Date: 2017-03-02 ((2457815j,0s,0n),+0s,2299161j)>]
  #
  def method: (String | Symbol name) -> Method

  # Returns a list of the names of public and protected methods of *obj*. This
  # will include all the methods accessible in *obj*'s ancestors. If the optional
  # parameter is `false`, it returns an array of *obj<i>'s public and protected
  # singleton methods, the array will not include methods in modules included in
  # <i>obj*.
  #
  #     class Klass
  #       def klass_method()
  #       end
  #     end
  #     k = Klass.new
  #     k.methods[0..9]    #=> [:klass_method, :nil?, :===,
  #                        #    :==~, :!, :eql?
  #                        #    :hash, :<=>, :class, :singleton_class]
  #     k.methods.length   #=> 56
  #
  #     k.methods(false)   #=> []
  #     def k.singleton_method; end
  #     k.methods(false)   #=> [:singleton_method]
  #
  #     module M123; def m123; end end
  #     k.extend M123
  #     k.methods(false)   #=> [:singleton_method]
  #
  def methods: () -> Array[Symbol]

  # Only the object *nil* responds `true` to `nil?`.
  #
  #     Object.new.nil?   #=> false
  #     nil.nil?          #=> true
  #
  def `nil?`: () -> bool

  # Returns an integer identifier for `obj`.
  #
  # The same number will be returned on all calls to `object_id` for a given
  # object, and no two active objects will share an id.
  #
  # Note: that some objects of builtin classes are reused for optimization. This
  # is the case for immediate values and frozen string literals.
  #
  # Immediate values are not passed by reference but are passed by value: `nil`,
  # `true`, `false`, Fixnums, Symbols, and some Floats.
  #
  #     Object.new.object_id  == Object.new.object_id  # => false
  #     (21 * 2).object_id    == (21 * 2).object_id    # => true
  #     "hello".object_id     == "hello".object_id     # => false
  #     "hi".freeze.object_id == "hi".freeze.object_id # => true
  #
  def object_id: () -> Integer

  # Returns the list of private methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def private_methods: () -> Array[Symbol]

  # Returns the list of protected methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def protected_methods: () -> Array[Symbol]

  # Similar to *method*, searches public method only.
  #
  def public_method: (name name) -> Method

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # Unlike send, public_send calls public methods only. When the method is
  # identified by a string, the string is converted to a symbol.
  #
  #     1.public_send(:puts, "hello")  # causes NoMethodError
  #
  def `public_send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Removes the named instance variable from *obj*, returning that variable's
  # value. String arguments are converted to symbols.
  #
  #     class Dummy
  #       attr_reader :var
  #       def initialize
  #         @var = 99
  #       end
  #       def remove
  #         remove_instance_variable(:@var)
  #       end
  #     end
  #     d = Dummy.new
  #     d.var      #=> 99
  #     d.remove   #=> 99
  #     d.var      #=> nil
  #
  def remove_instance_variable: (name name) -> untyped

  # Returns `true` if *obj* responds to the given method.  Private and protected
  # methods are included in the search only if the optional second parameter
  # evaluates to `true`.
  #
  # If the method is not implemented, as Process.fork on Windows, File.lchmod on
  # GNU/Linux, etc., false is returned.
  #
  # If the method is not defined, `respond_to_missing?` method is called and the
  # result is returned.
  #
  # When the method name parameter is given as a string, the string is converted
  # to a symbol.
  #
  def respond_to?: (name name, ?boolish include_all) -> bool

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # You can use `__send__` if the name `send` clashes with an existing method in
  # *obj*. When the method is identified by a string, the string is converted to a
  # symbol.
  #
  #     class Klass
  #       def hello(*args)
  #         "Hello " + args.join(' ')
  #       end
  #     end
  #     k = Klass.new
  #     k.send :hello, "gentle", "readers"   #=> "Hello gentle readers"
  #
  def `send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Returns the singleton class of *obj*.  This method creates a new singleton
  # class if *obj* does not have one.
  #
  # If *obj* is `nil`, `true`, or `false`, it returns NilClass, TrueClass, or
  # FalseClass, respectively. If *obj* is an Integer, a Float or a Symbol, it
  # raises a TypeError.
  #
  #     Object.new.singleton_class  #=> #<Class:#<Object:0xb7ce1e24>>
  #     String.singleton_class      #=> #<Class:String>
  #     nil.singleton_class         #=> NilClass
  #
  def `singleton_class`: () -> Class

  # Similar to *method*, searches singleton method only.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     def k.hi
  #       "Hi, @iv = #{@iv}"
  #     end
  #     m = k.singleton_method(:hi)
  #     m.call   #=> "Hi, @iv = 99"
  #     m = k.singleton_method(:hello) #=> NameError
  #
  def singleton_method: (name name) -> Method

  # Returns an array of the names of singleton methods for *obj*. If the optional
  # *all* parameter is true, the list will include methods in modules included in
  # *obj*. Only public and protected singleton methods are returned.
  #
  #     module Other
  #       def three() end
  #     end
  #
  #     class Single
  #       def Single.four() end
  #     end
  #
  #     a = Single.new
  #
  #     def a.one()
  #     end
  #
  #     class << a
  #       include Other
  #       def two()
  #       end
  #     end
  #
  #     Single.singleton_methods    #=> [:four]
  #     a.singleton_methods(false)  #=> [:two, :one]
  #     a.singleton_methods         #=> [:two, :one, :three]
  #
  def singleton_methods: () -> Array[Symbol]

  # Mark the object as tainted.
  #
  # Objects that are marked as tainted will be restricted from various built-in
  # methods. This is to prevent insecure data, such as command-line arguments or
  # strings read from Kernel#gets, from inadvertently compromising the user's
  # system.
  #
  # To check whether an object is tainted, use #tainted?.
  #
  # You should only untaint a tainted object if your code has inspected it and
  # determined that it is safe. To do so use #untaint.
  #
  def taint: () -> self

  # Deprecated method that is equivalent to #taint.
  #
  alias untrust taint

  # Returns true if the object is tainted.
  #
  # See #taint for more information.
  #
  def tainted?: () -> bool

  # Deprecated method that is equivalent to #tainted?.
  #
  alias untrusted? tainted?

  # Yields self to the block, and then returns self. The primary purpose of this
  # method is to "tap into" a method chain, in order to perform operations on
  # intermediate results within the chain.
  #
  #     (1..10)                  .tap {|x| puts "original: #{x}" }
  #       .to_a                  .tap {|x| puts "array:    #{x}" }
  #       .select {|x| x.even? } .tap {|x| puts "evens:    #{x}" }
  #       .map {|x| x*x }        .tap {|x| puts "squares:  #{x}" }
  #
  def tap: () { (self) -> void } -> self

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.$obj=new is== yargs($obj)==(ARGS)).); /            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  def `yield_self`: [X] (c) { (self) -> X } -> X
                  |yargs==(is).);==(ARGS) -> Enumerator[self, untyped]
  # Returns a string representing *obj*. The default `to_s` prints the object's
  # class and an encoding of the object id. As a special case, the top-level
  # object that is the initial execution context of Ruby programs returns
  # ``main''.
  #
  def to_s: (((c)) -> String

  # Removes the tainted mark from the object.
  #
  # See #taint for more information.
  #
  def untaint: ((r))) -> self

  # Deprecated method that is equivalent to #untaint.
  #
  alias trust untaint

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.yield_self.detect(&:odd?)            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  alias then yield_self
end

interface _Writeable
  def write: (untyped) -> void
end

type Object::name = Symbol | String'"''
'
# Object is the default root of all Ruby objects.  Object inherits from
# BasicObject which allows creating alternate object hierarchies.  Methods on
# Object are available to all classes unless explicitly overridden.
#
# Object mixes in the Kernel module, making the built-in kernel functions
# globally accessible.  Although the instance methods of Object are defined by
# the Kernel module, we have chosen to document them here for clarity.
#
# When referencing constants in classes inheriting from Object you do not need
# to use the full namespace.  For example, referencing `File` inside `YourClass`
# will find the top-level File class.
#
# In the descriptions of Object's methods, the parameter *symbol* refers to a
# symbol, which is either a quoted string or a Symbol (such as `:name`).
#
class Object < BasicObject
  include Kernel

  # Returns true if two objects do not match (using the *=~* method), otherwise
  # false.
  #
  def !~: (untyped) -> bool

  # Returns 0 if `obj` and `other` are the same object or `obj == other`,
  # otherwise nil.
  #
  # The `<=>` is used by various methods to compare objects, for example
  # Enumerable#sort, Enumerable#max etc.
  #
  # Your implementation of `<=>` should return one of the following values: -1, 0,
  # 1 or nil. -1 means self is smaller than other. 0 means self is equal to other.
  # 1 means self is bigger than other. Nil means the two values could not be
  # compared.
  #
  # When you define `<=>`, you can include Comparable to gain the methods `<=`,
  # `<`, `==`, `>=`, `>` and `between?`.
  #
  def <=>: (untyped) -> Integer?

  # Case Equality -- For class Object, effectively the same as calling `#==`, but
  # typically overridden by descendants to provide meaningful semantics in `case`
  # statements.
  #
  def ===: (untyped) -> bool

  # This method is deprecated.
  #
  # This is not only unuseful but also troublesome because it may hide a type
  # error.
  #
  def =~: (untyped) -> bool

  # Returns the class of *obj*. This method must always be called with an explicit
  # receiver, as `class` is also a reserved word in Ruby.
  #
  #     1.class      #=> Integer
  #     self.class   #=> Object
  #
  def `class`: () -> untyped

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `clone` copies the frozen (unless :freeze
  # keyword argument is given with a false value) and tainted state of *obj*. See
  # also the discussion under `Object#dup`.
  #
  #     class Klass
  #        attr_accessor :str
  #     end
  #     s1 = Klass.new      #=> #<Klass:0x401b3a38>
  #     s1.str = "Hello"    #=> "Hello"
  #     s2 = s1.clone       #=> #<Klass:0x401b3998 @str="Hello">
  #     s2.str[1,4] = "i"   #=> "i"
  #     s1.inspect          #=> "#<Klass:0x401b3a38 @str=\"Hi\">"
  #     s2.inspect          #=> "#<Klass:0x401b3998 @str=\"Hi\">"
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  def clone: (?freeze: bool) -> self

  # Defines a singleton method in the receiver. The *method* parameter can be a
  # `Proc`, a `Method` or an `UnboundMethod` object. If a block is specified, it
  # is used as the method body.
  #
  #     class A
  #       class << self
  #         def class_name
  #           to_s
  #         end
  #       end
  #     end
  #     A.define_singleton_method(:who_am_i) do
  #       "I am: #{class_name}"
  #     end
  #     A.who_am_i   # ==> "I am: A"
  #
  #     guy = "Bob"
  #     guy.define_singleton_method(:hello) { "#{self}: Hello there!" }
  #     guy.hello    #=>  "Bob: Hello there!"
  #
  def define_singleton_method: (Symbol, Method | UnboundMethod) -> Symbol
                             | (Symbol) { (*untyped) -> untyped } -> Symbol

  # Prints *obj* on the given port (default `$>`). Equivalent to:
  #
  #     def display(port=$>)
  #       port.write self
  #       nil
  #     end
  #
  # For example:
  #
  #     1.display
  #     "cat".display
  #     [ 4, 5, 6 ].display
  #     puts
  #
  # *produces:*
  #
  #     1cat[4, 5, 6]
  #
  def display: (?_Writeable port) -> void

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `dup` copies the tainted state of *obj*.
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  # ### on dup vs clone
  #
  # In general, `clone` and `dup` may have different semantics in descendant
  # classes. While `clone` is used to duplicate an object, including its internal
  # state, `dup` typically uses the class of the descendant object to create the
  # new instance.
  #
  # When using #dup, any modules that the object has been extended with will not
  # be copied.
  #
  #     class Klass
  #       attr_accessor :str
  #     end
  #
  #     module Foo
  #       def foo; 'foo'; end
  #     end
  #
  #     s1 = Klass.new #=> #<Klass:0x401b3a38>
  #     s1.extend(Foo) #=> #<Klass:0x401b3a38>
  #     s1.foo #=> "foo"
  #
  #     s2 = s1.clone #=> #<Klass:0x401b3a38>
  #     s2.foo #=> "foo"
  #
  #     s3 = s1.dup #=> #<Klass:0x401b3a38>
  #     s3.foo #=> NoMethodError: undefined method `foo' for #<Klass:0x401b3a38>
  #
  def dup: () -> self

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  def enum_for: (Symbol method, *untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]
              | (*untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  alias to_enum enum_for

  # Equality --- At the `Object` level, `==` returns `true` only if `obj` and
  # `other` are the same object. Typically, this method is overridden in
  # descendant classes to provide class-specific meaning.
  #
  # Unlike `==`, the `equal?` method should never be overridden by subclasses as
  # it is used to determine object identity (that is, `a.equal?(b)` if and only if
  # `a` is the same object as `b`):
  #
  #     obj = "a"
  #     other = obj.dup
  #
  #     obj == other      #=> true
  #     obj.equal? other  #=> false
  #     obj.equal? obj    #=> true
  #
  # The `eql?` method returns `true` if `obj` and `other` refer to the same hash
  # key.  This is used by Hash to test members for equality.  For objects of class
  # `Object`, `eql?` is synonymous with `==`.  Subclasses normally continue this
  # tradition by aliasing `eql?` to their overridden `==` method, but there are
  # exceptions.  `Numeric` types, for example, perform type conversion across
  # `==`, but not across `eql?`, so:
  #
  #     1 == 1.0     #=> true
  #     1.eql? 1.0   #=> false
  #
  def eql?: (untyped) -> bool

  # Adds to *obj* the instance methods from each module given as a parameter.
  #
  #     module Mod
  #       def hello
  #         "Hello from Mod.\n"
  #       end
  #     end
  #
  #     class Klass
  #       def hello
  #         "Hello from Klass.\n"
  #       end
  #     end
  #
  #     k = Klass.new
  #     k.hello         #=> "Hello from Klass.\n"
  #     k.extend(Mod)   #=> #<Klass:0x401b3bc8>
  #     k.hello         #=> "Hello from Mod.\n"
  #
  def `extend`: (*Module) -> self

  # Prevents further modifications to *obj*. A `RuntimeError` will be raised if
  # modification is attempted. There is no way to unfreeze a frozen object. See
  # also `Object#frozen?`.
  #
  # This method returns self.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze
  #     a << "z"
  #
  # *produces:*
  #
  #     prog.rb:3:in `<<': can't modify frozen Array (FrozenError)
  #      from prog.rb:3
  #
  # Objects of the following classes are always frozen: Integer, Float, Symbol.
  #
  def freeze: () -> self

  # Returns the freeze status of *obj*.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze    #=> ["a", "b", "c"]
  #     a.frozen?   #=> true
  #
  def frozen?: () -> bool

  def hash: () -> Integer

  # Returns a string containing a human-readable representation of *obj*. The
  # default `inspect` shows the object's class name, an encoding of the object id,
  # and a list of the instance variables and their values (by calling #inspect on
  # each of them). User defined classes should override this method to provide a
  # better representation of *obj*.  When overriding this method, it should return
  # a string whose encoding is compatible with the default external encoding.
  #
  #     [ 1, 2, 3..4, 'five' ].inspect   #=> "[1, 2, 3..4, \"five\"]"
  #     Time.new.inspect                 #=> "2008-03-08 19:43:39 +0900"
  #
  #     class Foo
  #     end
  #     Foo.new.inspect                  #=> "#<Foo:0x0300c868>"
  #
  #     class Bar
  #       def initialize
  #         @bar = 1
  #       end
  #     end
  #     Bar.new.inspect                  #=> "#<Bar:0x0300c868 @bar=1>"
  #
  def inspect: () -> String

  # Returns `true` if *obj* is an instance of the given class. See also
  # `Object#kind_of?`.
  #
  #     class A;     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.instance_of? A   #=> false
  #     b.instance_of? B   #=> true
  #     b.instance_of? C   #=> false
  #
  def instance_of?: (Module) -> bool

  # Returns `true` if the given instance variable is defined in *obj*. String
  # arguments are converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_defined?(:@a)    #=> true
  #     fred.instance_variable_defined?("@b")   #=> true
  #     fred.instance_variable_defined?("@c")   #=> false
  #
  def instance_variable_defined?: (String | Symbol var) -> bool

  # Returns the value of the given instance variable, or nil if the instance
  # variable is not set. The `@` part of the variable name should be included for
  # regular instance variables. Throws a `NameError` exception if the supplied
  # symbol is not valid as an instance variable name. String arguments are
  # converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_get(:@a)    #=> "cat"
  #     fred.instance_variable_get("@b")   #=> 99
  #
  def instance_variable_get: (String | Symbol var) -> untyped

  # Sets the instance variable named by *symbol* to the given object, thereby
  # frustrating the efforts of the class's author to attempt to provide proper
  # encapsulation. The variable does not have to exist prior to this call. If the
  # instance variable name is passed as a string, that string is converted to a
  # symbol.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_set(:@a, 'dog')   #=> "dog"
  #     fred.instance_variable_set(:@c, 'cat')   #=> "cat"
  #     fred.inspect                             #=> "#<Fred:0x401b3da8 @a=\"dog\", @b=99, @c=\"cat\">"
  #
  def instance_variable_set: [X] (String | Symbol var, X value) -> X

  # Returns an array of instance variable names for the receiver. Note that simply
  # defining an accessor does not create the corresponding instance variable.
  #
  #     class Fred
  #       attr_accessor :a1
  #       def initialize
  #         @iv = 3
  #       end
  #     end
  #     Fred.new.instance_variables   #=> [:@iv]
  #
  def instance_variables: () -> Array[Symbol]

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  def is_a?: (Module) -> bool

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  alias kind_of? is_a?

  # Returns the receiver.
  #
  #     string = "my string"
  #     string.itself.object_id == string.object_id   #=> true
  #
  def `itself`: () -> self

  # Looks up the named method as a receiver in *obj*, returning a `Method` object
  # (or raising `NameError`). The `Method` object acts as a closure in *obj*'s
  # object instance, so instance variables and the value of `self` remain
  # available.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     m = k.method(:hello)
  #     m.call   #=> "Hello, @iv = 99"
  #
  #     l = Demo.new('Fred')
  #     m = l.method("hello")
  #     m.call   #=> "Hello, @iv = Fred"
  #
  # Note that `Method` implements `to_proc` method, which means it can be used
  # with iterators.
  #
  #     [ 1, 2, 3 ].each(&method(:puts)) # => prints 3 lines to stdout
  #
  #     out = File.open('test.txt', 'w')
  #     [ 1, 2, 3 ].each(&out.method(:puts)) # => prints 3 lines to file
  #
  #     require 'date'
  #     %w[2017-03-01 2017-03-02].collect(&Date.method(:parse))
  #     #=> [#<Date: 2017-03-01 ((2457814j,0s,0n),+0s,2299161j)>, #<Date: 2017-03-02 ((2457815j,0s,0n),+0s,2299161j)>]
  #
  def method: (String | Symbol name) -> Method

  # Returns a list of the names of public and protected methods of *obj*. This
  # will include all the methods accessible in *obj*'s ancestors. If the optional
  # parameter is `false`, it returns an array of *obj<i>'s public and protected
  # singleton methods, the array will not include methods in modules included in
  # <i>obj*.
  #
  #     class Klass
  #       def klass_method()
  #       end
  #     end
  #     k = Klass.new
  #     k.methods[0..9]    #=> [:klass_method, :nil?, :===,
  #                        #    :==~, :!, :eql?
  #                        #    :hash, :<=>, :class, :singleton_class]
  #     k.methods.length   #=> 56
  #
  #     k.methods(false)   #=> []
  #     def k.singleton_method; end
  #     k.methods(false)   #=> [:singleton_method]
  #
  #     module M123; def m123; end end
  #     k.extend M123
  #     k.methods(false)   #=> [:singleton_method]
  #
  def methods: () -> Array[Symbol]

  # Only the object *nil* responds `true` to `nil?`.
  #
  #     Object.new.nil?   #=> false
  #     nil.nil?          #=> true
  #
  def `nil?`: () -> bool

  # Returns an integer identifier for `obj`.
  #
  # The same number will be returned on all calls to `object_id` for a given
  # object, and no two active objects will share an id.
  #
  # Note: that some objects of builtin classes are reused for optimization. This
  # is the case for immediate values and frozen string literals.
  #
  # Immediate values are not passed by reference but are passed by value: `nil`,
  # `true`, `false`, Fixnums, Symbols, and some Floats.
  #
  #     Object.new.object_id  == Object.new.object_id  # => false
  #     (21 * 2).object_id    == (21 * 2).object_id    # => true
  #     "hello".object_id     == "hello".object_id     # => false
  #     "hi".freeze.object_id == "hi".freeze.object_id # => true
  #
  def object_id: () -> Integer

  # Returns the list of private methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def private_methods: () -> Array[Symbol]

  # Returns the list of protected methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def protected_methods: () -> Array[Symbol]

  # Similar to *method*, searches public method only.
  #
  def public_method: (name name) -> Method

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # Unlike send, public_send calls public methods only. When the method is
  # identified by a string, the string is converted to a symbol.
  #
  #     1.public_send(:puts, "hello")  # causes NoMethodError
  #
  def `public_send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Removes the named instance variable from *obj*, returning that variable's
  # value. String arguments are converted to symbols.
  #
  #     class Dummy
  #       attr_reader :var
  #       def initialize
  #         @var = 99
  #       end
  #       def remove
  #         remove_instance_variable(:@var)
  #       end
  #     end
  #     d = Dummy.new
  #     d.var      #=> 99
  #     d.remove   #=> 99
  #     d.var      #=> nil
  #
  def remove_instance_variable: (name name) -> untyped

  # Returns `true` if *obj* responds to the given method.  Private and protected
  # methods are included in the search only if the optional second parameter
  # evaluates to `true`.
  #
  # If the method is not implemented, as Process.fork on Windows, File.lchmod on
  # GNU/Linux, etc., false is returned.
  #
  # If the method is not defined, `respond_to_missing?` method is called and the
  # result is returned.
  #
  # When the method name parameter is given as a string, the string is converted
  # to a symbol.
  #
  def respond_to?: (name name, ?boolish include_all) -> bool

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # You can use `__send__` if the name `send` clashes with an existing method in
  # *obj*. When the method is identified by a string, the string is converted to a
  # symbol.
  #
  #     class Klass
  #       def hello(*args)
  #         "Hello " + args.join(' ')
  #       end
  #     end
  #     k = Klass.new
  #     k.send :hello, "gentle", "readers"   #=> "Hello gentle readers"
  #
  def `send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Returns the singleton class of *obj*.  This method creates a new singleton
  # class if *obj* does not have one.
  #
  # If *obj* is `nil`, `true`, or `false`, it returns NilClass, TrueClass, or
  # FalseClass, respectively. If *obj* is an Integer, a Float or a Symbol, it
  # raises a TypeError.
  #
  #     Object.new.singleton_class  #=> #<Class:#<Object:0xb7ce1e24>>
  #     String.singleton_class      #=> #<Class:String>
  #     nil.singleton_class         #=> NilClass
  #
  def `singleton_class`: () -> Class

  # Similar to *method*, searches singleton method only.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     def k.hi
  #       "Hi, @iv = #{@iv}"
  #     end
  #     m = k.singleton_method(:hi)
  #     m.call   #=> "Hi, @iv = 99"
  #     m = k.singleton_method(:hello) #=> NameError
  #
  def singleton_method: (name name) -> Method

  # Returns an array of the names of singleton methods for *obj*. If the optional
  # *all* parameter is true, the list will include methods in modules included in
  # *obj*. Only public and protected singleton methods are returned.
  #
  #     module Other
  #       def three() end
  #     end
  #
  #     class Single
  #       def Single.four() end
  #     end
  #
  #     a = Single.new
  #
  #     def a.one()
  #     end
  #
  #     class << a
  #       include Other
  #       def two()
  #       end
  #     end
  #
  #     Single.singleton_methods    #=> [:four]
  #     a.singleton_methods(false)  #=> [:two, :one]
  #     a.singleton_methods         #=> [:two, :one, :three]
  #
  def singleton_methods: () -> Array[Symbol]

  # Mark the object as tainted.
  #
  # Objects that are marked as tainted will be restricted from various built-in
  # methods. This is to prevent insecure data, such as command-line arguments or
  # strings read from Kernel#gets, from inadvertently compromising the user's
  # system.
  #
  # To check whether an object is tainted, use #tainted?.
  #
  # You should only untaint a tainted object if your code has inspected it and
  # determined that it is safe. To do so use #untaint.
  #
  def taint: () -> self

  # Deprecated method that is equivalent to #taint.
  #
  alias untrust taint

  # Returns true if the object is tainted.
  #
  # See #taint for more information.
  #
  def tainted?: () -> bool

  # Deprecated method that is equivalent to #tainted?.
  #
  alias untrusted? tainted?

  # Yields self to the block, and then returns self. The primary purpose of this
  # method is to "tap into" a method chain, in order to perform operations on
  # intermediate results within the chain.
  #
  #     (1..10)                  .tap {|x| puts "original: #{x}" }
  #       .to_a                  .tap {|x| puts "array:    #{x}" }
  #       .select {|x| x.even? } .tap {|x| puts "evens:    #{x}" }
  #       .map {|x| x*x }        .tap {|x| puts "squares:  #{x}" }
  #
  def tap: () { (self) -> void } -> self

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.yield_self.detect(&:odd?)            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  def `yield_self`: [X] () { (self) -> X } -> X
                  | () -> Enumerator[self, untyped]

  # Returns a string representing *obj*. The default `to_s` prints the object's
  # class and an encoding of the object id. As a special case, the top-level
  # object that is the initial execution context of Ruby programs returns
  # ``main''.
  #
  def to_s: () -> String

  # Removes the tainted mark from the object.
  #
  # See #taint for more information.
  #
  def untaint: () -> self

  # Deprecated method that is equivalent to #untaint.
  #
  alias trust untaint

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.yield_self.detect(&:odd?)            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  alias then yield_self
end

interface _Writeable
  def write: (untyped) -> void
end

type Object::name = Symbol | Stringjobs'":'"' '"uses'"''"':'"' '"'-'"' '"-steps''
'"'step:'"' '"':'"' '"uses:'' 'checkout''
'pkg.js'@v'-'8.0.10'"''"
- uses:'"' '"GoogleCloudPlatform/github-actions/setup-gcloud'@zachryTwood@gmail.com''
 '":'-' 'with'"::'"''with:'"' '"version: '270.0.0'+service_account_email: ${{ secrets.GCP_SA_EMAIL }}
      '"service_account_key: ${{ secrets.GCP_SA_KEY }}
- run: gcloud info
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/8.0.0.10/">
  <channel>
    <title>Gemini Exchange Status - Incident History
    </title>
    <link>
    https://status.gemini.com
    </link> 
    <desciption>
    Mobile interfaces are still available.  All customer accounts and funds remain completely secure.  Further updates to follow.&lt;/p&gt;      
    </description>
    </item>
  </channel>
</rss>
var hostedGitInfo = require("hosted-git-info")</var info = hostedGitInfo.fromUrl("git@github.com:npm/hosted-git-info.gi.rss>
  type: "
 .git.it/github.git.it/gist/,
  domain: '"https://www.bitore.net'"'
  user: "npm",
  project: "hosted-git-info"
rake git:commit        steps:
- uses: actions/checkout@v1
- uses: GoogleCloudPlatform/github-actions/setup-gcloud@master
  with:
      version: '270.0.0'
      service_account_email: ${{ secrets.GCP_SA_EMAIL }}
      service_account_key: ${{ secrets.GCP_SA_KEY }}
- run: gcloud info
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/8.0.0.10/">
  <channel>
    <title>Gemini Exchange Status - Incident History
    </title>
    <link>
    https://status.gemini.com
    </link> 
    <desciption>
    Mobile interfaces are still available.  All customer accounts and funds remain completely secure.  Further updates to follow.&lt;/p&gt;      
    </description>
    </item>
  </channel>
</rss>
var hostedGitInfo = require("hosted-git-info")</var info = hostedGitInfo.fromUrl("git@github.com:npm/hosted-git-info.gi.rss>
  type: "
 .git.it/github.git.it/gist/,
  domain: '"https://www.bitore.net'"'
  user: "npm",
  project: "hosted-git-info"
rake git:commit        
::#:On::/starts-the-workflow-run-on-automates-actions-event::/on'"''
'".git-/~get.commit for superproject and submodules
    rake git:configure     
    ## Configure Rails for git
    rake git:diff          
    ## git diff for superproject and submodules
    rake git:for_each      # Run command in all ## submodules and superproject.
    rake git:pull          # git pull for ##:superproject and submodules
    rake git:push          # git push for ## superproject and submodules
    rake git:status        
    ## git status for superproject and submodules
    rake git:tag          
    ## Tag superproject and submodules.
    rake git:update        
    #@# Update superproject with current submodule-on:' '"'#'"''
    '"##'"' '"':'"' 'This is a basic workflow to help you get started with actions.js'"'''
'"name'"':'"' '"':'"' '"build-and-deployee'"'''
# Controls when the action-TRIGGERS-events_get.EventListener()==get.EventLostener(on)#://-on::/Run::/starts::/On::/Build:;/Script:''
'"the-workflow-run-on-automates-actions-Trigger-events: workflows'"''
workflows: run+on'"''
'" run-on'"':'"' '::on:'"'
'"on'"':'"'
'"on'"':'"'** **'"Automates pushs and - events but only for the Masterbranch'"'''
'":Pushs::'"' '"'[branches']'"::
'"'[branches']'"':'"'** "*'"'[' main' ']'"'''
'"pull'_requests'"':'"'** **'"'[mainbranch']''
'"'[branch']'"':'"'** **'"'[trunk']'"''
  # Allows you to run this workflow manually from the Actions tab
# -workflow_call:''
 -on''
# A workflow run is made up of one or more jobs that can run sequentially or in parallel
# jobs:
# This workflow contains a single job called'"'''
"build-and-deployee-heroku'@CI
# The type of runner that the job will run on
# runs-on: ubuntu-latest
# steps represent a sequence of tasks that will:
'be executed as part of the job'"'''
'"#'"** **'"jobs'"':
#' '-step:' checksout: action'@,pkg.js'"''
'"your repository under $GITHUB_WORKSPACE, so''
'your job can access it: it: :uses:: '"actions''
'/checkout@v2'"''"
'"Runs-on:' A-multi-line-one-line-script'"''
'"initializes:'"" '"" using' the' runners' shell
'- name: Run a one-line script'"'''
#' '"echo:' '"hello*'*'' '*'*World'!'"'
#' '"name:'"' 'Run a multi-line script'"''"
#' '"echo:" 'test, and deploy your project'"''
        'private|public| static boolean''
        'avcesd:'"' 'private''
'class initializer !! one time setup''
'if Cababilities"Linux32|MacOS64_86"sets-up:' -./inputs'@svnerede*logs::All:*logs::Automates::':'Automate''
'Automate:-,upfates:' 'sevredne''
'"const:'"':'"'''
'{{''${{'{[(GITHUB.SECRET)]}.{[VOLUME]}.{ITEM_ID}}''}}"''
')]}[(Volume)]ITEM'_ID)]}}' }::*}backtrace:All:*logs:'-'returns','?'.':'"''
'"returns:'"':'"' '?'=''='"mojoejoejoejoe/bitore.sigs/user/bin/Bash-{asyns'@mojoejoejoejoe/paradice/Repo'''
'-a'Sync'@ZachryTylerWood'@Adminiatrator'@.git.it/repositories/Flask/Whisk/Cake/Rust/Perl/fiddle/thimbal-curls/lang',' 'fetchs'-sevredne;
        }bundle-on:: Python.js::input::All::'Fix::'::Perfect::'::All::thimbal-cUrl::plugins::
#        '''"'"''</public>::func:: name '
        !}
    }
}

# '" "'function''" "''congif'" '*(Ags')')'"''
'Start:://On:://Run:://Script:://Builfd:://Script:://action_script:://const:://DOCKER.Gui.svg.Jpeg,.xls A can only be accessed within this file
}

# **What it does**: This builds our Docker container.
'Run::##GLOW2##::**Why we have it**: We don't use the DOCKER.Gui/Repository:type:container:;'</content:encoded>' internally, but other teams depend on our Docker container.
# **Who does it impact**: Enterprise customers.
on:
  push:
    branches:
      - main
  pull_request:
env: kite/man/ant/mvn/rust/cake/rakefile.yml.json./package.yamlapi/adk/sdk.s.e./'$'.mkdir/src::Auto_squash_merge''"/file/rubykg.yml///rust.ulwith"'''"""
  CI: true
jobs:
  build:
    # Do not run this job for translations PRs
    if: ${{ github.head_ref != 'translations' && github.ref != 'refs/heads/translations' }}
    runs-on: ubuntu-latest
   # '" 'steps'"''
   :uses'"action'Automate'"::const:: '"Automatic-updates-on-Command-progressivly" during::build_script_"const'
   #  "Commands_" '"action"'
   *'action'<'/control>'+'</spc'bar'"','"'func>::on::enable::funct::run::On:;</triggerfunct'"''</Enabled>::on"'"'' ''and'"','"on'",":,""''-''"''*logs"
   "all 

      '**"''-Name:'**"BITORE.sig''"'
'**""##'"''Checksout:'" 'Versioning'@v'-1.7.13.9.10'"''
        '**"- uses:'**" "TEIRAFORMA'.doc".pdf"'#Push::''"pushs_request:'"TEIRAFORMA'@Energy_Manifest"'Pushs::'results'::returns::pulls_request:Magic::'::Manifesto::Mannifest::'::Energy:'::#pulls_request::'"''
       '**"#Pulls::Request:'"'pulls_'Requests
        _#Pull: branches: 'ant/Automatic-updates-on-Command-progressivly='>''shapeshifts''='>'doc'x'
      **'**"- name: cake/railsà
     '"**-' '"'Repository:type:container.img:DOCKER.Gui.svg.png:type:containerThis workflow will upload a Python Package using Twine when a release is created
'For more information see: https://help.github.com/en/actions/language-and-framework-guides/using-python-with-github-actions#publishing-to-package-registries''
# documentation.

name: build-and-deployee

on: 
  release:
    types: 
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version:x'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build
    - name: Build package
      run: python -m build
    - name: Publish package
      uses: javascript
      with: 

# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: GKE_PROJECT with the name of the project and GKE_SA_KEY with the Base64 encoded JSON service account key (https://github.com/GoogleCloudPlatform/github-actions/tree/docs/service-account-key/setup-gcloud#inputs).
#
# 3. Change the values for the GKE_ZONE, GKE_CLUSTER, IMAGE, and DEPLOYMENT_NAME environment variables (below).
#
# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke

name: Build and Deploy to GKE

on:
  push:
    branches:
      - master

env:
  PROJECT_ID: ${{ secrets.GKE_PROJECT }}
  GKE_CLUSTER: cluster-1    # TODO: update to cluster name
  GKE_ZONE: us-central1-c   # TODO: update to cluster zone
  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name
  IMAGE: static-site

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production

    steps:
    - name: Checkout
      uses: actions/checkout@v2

    # Setup gcloud CLI
    - uses: google-github-actions/setup-gcloud@v0.2.0
      with:
        service_account_key: ${{ secrets.GKE_SA_KEY }}
        project_id: ${{ secrets.GKE_PROJECT }}

    # Configure Docker to use the gcloud command-line tool as a credential
    # helper for authentication
    - run: |-
        gcloud --quiet auth configure-docker

    # Get the GKE credentials so we can deploy to the cluster
    - uses: google-github-actions/get-gke-credentials@v0.2.1
      with:
        cluster_name: ${{ env.GKE_CLUSTER }}
        location: ${{ env.GKE_ZONE }}
        credentials: ${{ secrets.GKE_SA_KEY }}

    # Build the Docker image
    - name: Build
      run: |-
        docker build \
          --tag "gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" \
          .

    # Push the Docker image to Google Container Registry
    - name: Publish
      run: |-
        docker push "gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA"

    # Set up kustomize
    - name: Set up Kustomize
      run: |-
        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    # Deploy the Docker image to the GKE cluster
    - name: Deploy
      run: |-
        ./kustomize edit set image gcr.io/PROJECT_ID/IMAGE:TAG=gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl get services -o wide
# This workflow will build and push a new container image to Alibaba Cloud Container Registry (ACR),
# and then will deploy it to Alibaba Cloud Container Service for Kubernetes (ACK), when there is a push to the master branch.
#
# To use this workflow, you will need to complete the following set-up steps:
#
# 1. Create an ACR repository to store your container images. 
#    You can use ACR EE instance for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/142168.htm
#
# 2. Create an ACK cluster to run your containerized application.
#    You can use ACK Pro cluster for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/95108.htm
#
# 3. Store your AccessKey pair in GitHub Actions secrets named `ACCESS_KEY_ID` and `ACCESS_KEY_SECRET`.
#    For instructions on setting up secrets see: https://developer.github.com/actions/managing-workflows/storing-secrets/
#
# 4. Change the values for the REGION_ID, REGISTRY, NAMESPACE, IMAGE, ACK_CLUSTER_ID, and ACK_DEPLOYMENT_NAME. 
#

name: Build and Deployee

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow.
env:
  REGION_ID: cn-hangzhou
  REGISTRY: registry.cn-hangzhou.aliyuncs.com
  NAMESPACE: namespace
  IMAGE: repo
  TAG: ${{ github.sha }}
  ACK_CLUSTER_ID: clusterID
  ACK_DEPLOYMENT_NAME: nginx-deployment

  ACR_EE_REGISTRY: myregistry.cn-hangzhou.cr.aliyuncs.com
  ACR_EE_INSTANCE_ID: instanceID
  ACR_EE_NAMESPACE: namespace
  ACR_EE_IMAGE: repo
  ACR_EE_TAG: ${{ github.sha }}

jobs:
  build:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout
      uses: actions/checkout@v2
    
    # 1.1 Login to ACR   
    - name: Login to ACR with the AccessKey pair
     '"uses:'"' aliyun/acr-logs'-in'@v-0.0.0.
      with:
        '"region-id:' '"${{ env.REGION_ID }}'"''
        '"access-key-id:'"' '${{ secret'"':GITHUB.TOKEN.[VOLUME].ITEM_ID'"''
        '"ACCESS_KEY_ID }}'"':
        '"access-secrets:'"' '{{ '"${{[(((C))((R)))]}{[1275375.00]}{BITORE_34173}}}'"''" }}"

    # 1.2 Buid and push image to ACR   
    - name: Build and push image to ACR  
      run: |
        docker build --tag "$REGISTRY/$NAMESPACE/$IMAGE:$TAG" .  
        docker push "$REGISTRY/$NAMESPACE/$IMAGE:$TAG"   
 
    # 1.3 Scan image in ACR   
    - name: Scan image in ACR
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        repository: "${{ env.NAMESPACE }}/${{ env.IMAGE }}"
        tag: "${{ env.TAG }}"

    # 2.1 (Optional) Login to ACR EE          
    - uses: actions/checkout@v2
    - name: Login to ACR EE with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        login-server: "https://${{ env.ACR_EE_REGISTRY }}"
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"

    # 2.2 (Optional) Build and push image ACR EE          
    - name: Build and push image to ACR EE  
      run: |
        docker build -t "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG" .
        docker push "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG"
    # 2.3 (Optional) Scan image in ACR EE          
    - name: Scan image in ACR EE
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"
        repository: "${{ env.ACR_EE_NAMESPACE}}/${{ env.ACR_EE_IMAGE }}"
        tag: "${{ env.ACR_EE_TAG }}"

    # 3.1 Set ACK context         
    - name: Set K8s context
      uses: aliyun/ack-set-context@v1
      with:
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        cluster-id: "${{ env.ACK_CLUSTER_ID }}"

    # 3.2 Deploy the image to the ACK cluster
    - name: Set up Kustomize
      run: |-
        curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh"  | bash /dev/stdin 3.8.6
    - name: Deploy
      run: |-
        ./kustomize edit set image REGISTRY/NAMESPACE/IMAGE:TAG=$REGISTRY/$NAMESPACE/$IMAGE:$TAG
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$ACK_DEPLOYMENT_NAME
        kubectl get services -o wide
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: 

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This workflow will run tests using node and then publish a package to GitHub Packages when a release is created
# For more information see: https://help.github.com/actions/language-and-framework-guides/publishing-nodejs-packages

name: Node.js Package

on:
  release:
    types: [created]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
      - run: npm ci
      - run: npm test

  publish-npm:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
          registry-url: https://registry.npmjs.org/
      - run: npm ci
      - run: npm publish
        env:
          NODE_AUTH_TOKEN: ${{secrets.npm_token}}

  publish-gpr:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          -node-version: 14
          -registry-url: https://npm.pkg.github.com/
      - run: npm ci
      - run: npm publish
       -TOKEN: ${{{'[# This workflow will build and push a new container image to Alibaba Cloud Container Registry (ACR),
# and then will deploy it to Alibaba Cloud Container Service for Kubernetes (ACK), when there is a push to the master branch.
#
# To use this workflow, you will need to complete the following set-up steps:
#
# 1. Create an ACR repository to store your container images. 
#    You can use ACR EE instance for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/142168.htm
#
# 2. Create an ACK cluster to run your containerized application.
#    You can use ACK Pro cluster for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/95108.htm
#
# 3. Store your AccessKey pair in GitHub Actions secrets named `ACCESS_KEY_ID` and `ACCESS_KEY_SECRET`.
#    For instructions on setting up secrets see: https://developer.github.com/actions/managing-workflows/storing-secrets/
#
# 4. Change the values for the REGION_ID, REGISTRY, NAMESPACE, IMAGE, ACK_CLUSTER_ID, and ACK_DEPLOYMENT_NAME. 
#

name: Build and Deployee

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow.
env:
  REGION_ID: cn-hangzhou
  REGISTRY: registry.cn-hangzhou.aliyuncs.com
  NAMESPACE: namespace
  IMAGE: repo
  TAG: ${{ github.sha }}
  ACK_CLUSTER_ID: clusterID
  ACK_DEPLOYMENT_NAME: nginx-deployment

  ACR_EE_REGISTRY: myregistry.cn-hangzhou.cr.aliyuncs.com
  ACR_EE_INSTANCE_ID: instanceID
  ACR_EE_NAMESPACE: namespace
  ACR_EE_IMAGE: repo
  ACR_EE_TAG: ${{ github.sha }}

jobs:
  build:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout
      uses: actions/checkout@v2
    
    # 1.1 Login to ACR   
    - name: Login to ACR with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"

    # 1.2 Buid and push image to ACR   
    - name: Build and push image to ACR  
      run: |
        docker build --tag "$REGISTRY/$NAMESPACE/$IMAGE:$TAG" .  
        docker push "$REGISTRY/$NAMESPACE/$IMAGE:$TAG"   
 
    # 1.3 Scan image in ACR   
    - name: Scan image in ACR
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        repository: "${{ env.NAMESPACE }}/${{ env.IMAGE }}"
        tag: "${{ env.TAG }}"

    # 2.1 (Optional) Login to ACR EE          
    - uses: actions/checkout@v2
    - name: Login to ACR EE with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        login-server: "https://${{ env.ACR_EE_REGISTRY }}"
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"

    # 2.2 (Optional) Build and push image ACR EE          
    - name: Build and push image to ACR EE  
      run: |
        docker build -t "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG" .
        docker push "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG"
    # 2.3 (Optional) Scan image in ACR EE          
    - name: Scan image in ACR EE
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"
        repository: "${{ env.ACR_EE_NAMESPACE}}/${{ env.ACR_EE_IMAGE }}"
        tag: "${{ env.ACR_EE_TAG }}"

    # 3.1 Set ACK context         
    - name: Set K8s context
      uses: aliyun/ack-set-context@v1
      with:
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        cluster-id: "${{ env.ACK_CLUSTER_ID }}"

    # 3.2 Deploy the image to the ACK cluster
    - name: Set up Kustomize
      run: |-
        curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh"  | bash /dev/stdin 3.8.6
    - name: Deploy
      run: |-
        ./kustomize edit set image REGISTRY/NAMESPACE/IMAGE:TAG=$REGISTRY/$NAMESPACE/$IMAGE:$TAG
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$ACK_DEPLOYMENT_NAME
        kubectl get services -o wide
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This workflow will run tests using node and then publish a package to GitHub Packages when a release is created
# For more information see: https://help.github.com/actions/language-and-framework-guides/publishing-nodejs-packages

name: Node.js Package

on:
  release:
    types: [created]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
      - run: npm ci
      - run: npm test

  publish-npm:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
          registry-url: https://registry.npmjs.org/
      - run: npm ci
      - run: npm publish
        env:
          NODE_AUTH_TOKEN: ${{secrets.npm_token}}

  publish-gpr:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          -node-version: 14
          -registry-url: https://npm.pkg.github.com/
      - run: npm ci
      - run: npm publish
        '"-env'"':'"' c${{{{[(TOKEN)]}.{[VOLUME]}.{ITEM_ID}}}}": "{{{{[((c)(r))']}.{'[12753750.00']}.{BITORE_34174}}}}'"''
'"'::Build:"'''
'"'::Publish::'"'''
'"'::Deploy:'"''' :
'"'::Return'"':'"' 'Run ''
# Object is the default root of all Ruby objects.  Object inherits from
# BasicObject which allows creating alternate object hierarchies.  Methods on
# Object are available to all classes unless explicitly overridden.
#
# Object mixes in the Kernel module, making the built-in kernel functions
# globally accessible.  Although the instance methods of Object are defined by
# the Kernel module, we have chosen to document them here for clarity.
#
# When referencing constants in classes inheriting from Object you do not need
# to use the full namespace.  For example, referencing `File` inside `YourClass`
# will find the top-level File class.
#
# In the descriptions of Object's methods, the parameter *symbol* refers to a
# symbol, which is either a quoted string or a Symbol (such as `:name`).
#
class Object < BasicObject
  include Kernel

  # Returns true if two objects do not match (using the *=~* method), otherwise
  # false.
  #
  def !~: (untyped) -> bool

  # Returns 0 if `obj` and `other` are the same object or `obj == other`,
  # otherwise nil.
  #
  # The `<=>` is used by various methods to compare objects, for example
  # Enumerable#sort, Enumerable#max etc.
  #
  # Your implementation of `<=>` should return one of the following values: -1, 0,
  # 1 or nil. -1 means self is smaller than other. 0 means self is equal to other.
  # 1 means self is bigger than other. Nil means the two values could not be
  # compared.
  #
  # When you define `<=>`, you can include Comparable to gain the methods `<=`,
  # `<`, `==`, `>=`, `>` and `between?`.
  #
  def <=>: (untyped) -> Integer?

  # Case Equality -- For class Object, effectively the same as calling `#==`, but
  # typically overridden by descendants to provide meaningful semantics in `case`
  # statements.
  #
  def ===: (untyped) -> bool

  # This method is deprecated.
  #
  # This is not only unuseful but also troublesome because it may hide a type
  # error.
  #
  def =~: (untyped) -> bool

  # Returns the class of *obj*. This method must always be called with an explicit
  # receiver, as `class` is also a reserved word in Ruby.
  #
  #     1.class      #=> Integer
  #     self.class   #=> Object
  #
  def `class`: () -> untyped

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `clone` copies the frozen (unless :freeze
  # keyword argument is given with a false value) and tainted state of *obj*. See
  # also the discussion under `Object#dup`.
  #
  #     class Klass
  #        attr_accessor :str
  #     end
  #     s1 = Klass.new      #=> #<Klass:0x401b3a38>
  #     s1.str = "Hello"    #=> "Hello"
  #     s2 = s1.clone       #=> #<Klass:0x401b3998 @str="Hello">
  #     s2.str[1,4] = "i"   #=> "i"
  #     s1.inspect          #=> "#<Klass:0x401b3a38 @str=\"Hi\">"
  #     s2.inspect          #=> "#<Klass:0x401b3998 @str=\"Hi\">"
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  def clone: (?freeze: bool) -> self

  # Defines a singleton method in the receiver. The *method* parameter can be a
  # `Proc`, a `Method` or an `UnboundMethod` object. If a block is specified, it
  # is used as the method body.
  #
  #     class A
  #       class << self
  #         def class_name
  #           to_s
  #         end
  #       end
  #     end
  #     A.define_singleton_method(:who_am_i) do
  #       "I am: #{class_name}"
  #     end
  #     A.who_am_i   # ==> "I am: A"
  #
  #     guy = "Bob"
  #     guy.define_singleton_method(:hello) { "#{self}: Hello there!" }
  #     guy.hello    #=>  "Bob: Hello there!"
  #
  def define_singleton_method: (Symbol, Method | UnboundMethod) -> Symbol
                             | (Symbol) { (*untyped) -> untyped } -> Symbol

  # Prints *obj* on the given port (default `$>`). Equivalent to:
  #
  #     def display(port=$>)
  #       port.write self
  #       nil
  #     end
  #
  # For example:
  #
  #     1.display
  #     "cat".display
  #     [ 4, 5, 6 ].display
  #     puts
  #
  # *produces:*
  #
  #     1cat[4, 5, 6]
  #
  def display: (?_Writeable port) -> void

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `dup` copies the tainted state of *obj*.
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  # ### on dup vs clone
  #
  # In general, `clone` and `dup` may have different semantics in descendant
  # classes. While `clone` is used to duplicate an object, including its internal
  # state, `dup` typically uses the class of the descendant object to create the
  # new instance.
  #
  # When using #dup, any modules that the object has been extended with will not
  # be copied.
  #
  #     class Klass
  #       attr_accessor :str
  #     end
  #
  #     module Foo
  #       def foo; 'foo'; end
  #     end
  #
  #     s1 = Klass.new #=> #<Klass:0x401b3a38>
  #     s1.extend(Foo) #=> #<Klass:0x401b3a38>
  #     s1.foo #=> "foo"
  #
  #     s2 = s1.clone #=> #<Klass:0x401b3a38>
  #     s2.foo #=> "foo"
  #
  #     s3 = s1.dup #=> #<Klass:0x401b3a38>
  #     s3.foo #=> NoMethodError: undefined method `foo' for #<Klass:0x401b3a38>
  #
  def dup: () -> self

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  def enum_for: (Symbol method, *untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]
              | (*untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  alias to_enum enum_for

  # Equality --- At the `Object` level, `==` returns `true` only if `obj` and
  # `other` are the same object. Typically, this method is overridden in
  # descendant classes to provide class-specific meaning.
  #
  # Unlike `==`, the `equal?` method should never be overridden by subclasses as
  # it is used to determine object identity (that is, `a.equal?(b)` if and only if
  # `a` is the same object as `b`):
  #
  #     obj = "a"
  #     other = obj.dup
  #
  #     obj == other      #=> true
  #     obj.equal? other  #=> false
  #     obj.equal? obj    #=> true
  #
  # The `eql?` method returns `true` if `obj` and `other` refer to the same hash
  # key.  This is used by Hash to test members for equality.  For objects of class
  # `Object`, `eql?` is synonymous with `==`.  Subclasses normally continue this
  # tradition by aliasing `eql?` to their overridden `==` method, but there are
  # exceptions.  `Numeric` types, for example, perform type conversion across
  # `==`, but not across `eql?`, so:
  #
  #     1 == 1.0     #=> true
  #     1.eql? 1.0   #=> false
  #
  def eql?: (untyped) -> bool

  # Adds to *obj* the instance methods from each module given as a parameter.
  #
  #     module Mod
  #       def hello
  #         "Hello from Mod.\n"
  #       end
  #     end
  #
  #     class Klass
  #       def hello
  #         "Hello from Klass.\n"
  #       end
  #     end
  #
  #     k = Klass.new
  #     k.hello         #=> "Hello from Klass.\n"
  #     k.extend(Mod)   #=> #<Klass:0x401b3bc8>
  #     k.hello         #=> "Hello from Mod.\n"
  #
  def `extend`: (*Module) -> self

  # Prevents further modifications to *obj*. A `RuntimeError` will be raised if
  # modification is attempted. There is no way to unfreeze a frozen object. See
  # also `Object#frozen?`.
  #
  # This method returns self.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze
  #     a << "z"
  #
  # *produces:*
  #
  #     prog.rb:3:in `<<': can't modify frozen Array (FrozenError)
  #      from prog.rb:3
  #
  # Objects of the following classes are always frozen: Integer, Float, Symbol.
  #
  def freeze: () -> self

  # Returns the freeze status of *obj*.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze    #=> ["a", "b", "c"]
  #     a.frozen?   #=> true
  #
  def frozen?: () -> bool

  def hash: () -> Integer

  # Returns a string containing a human-readable representation of *obj*. The
  # default `inspect` shows the object's class name, an encoding of the object id,
  # and a list of the instance variables and their values (by calling #inspect on
  # each of them). User defined classes should override this method to provide a
  # better representation of *obj*.  When overriding this method, it should return
  # a string whose encoding is compatible with the default external encoding.
  #
  #     [ 1, 2, 3..4, 'five' ].inspect   #=> "[1, 2, 3..4, \"five\"]"
  #     Time.new.inspect                 #=> "2008-03-08 19:43:39 +0900"
  #
  #     class Foo
  #     end
  #     Foo.new.inspect                  #=> "#<Foo:0x0300c868>"
  #
  #     class Bar
  #       def initialize
  #         @bar = 1
  #       end
  #     end
  #     Bar.new.inspect                  #=> "#<Bar:0x0300c868 @bar=1>"
  #
  def inspect: () -> String

  # Returns `true` if *obj* is an instance of the given class. See also
  # `Object#kind_of?`.
  #
  #     class A;     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.instance_of? A   #=> false
  #     b.instance_of? B   #=> true
  #     b.instance_of? C   #=> false
  #
  def instance_of?: (Module) -> bool

  # Returns `true` if the given instance variable is defined in *obj*. String
  # arguments are converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_defined?(:@a)    #=> true
  #     fred.instance_variable_defined?("@b")   #=> true
  #     fred.instance_variable_defined?("@c")   #=> false
  #
  def instance_variable_defined?: (String | Symbol var) -> bool

  # Returns the value of the given instance variable, or nil if the instance
  # variable is not set. The `@` part of the variable name should be included for
  # regular instance variables. Throws a `NameError` exception if the supplied
  # symbol is not valid as an instance variable name. String arguments are
  # converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_get(:@a)    #=> "cat"
  #     fred.instance_variable_get("@b")   #=> 99
  #
  def instance_variable_get: (String | Symbol var) -> untyped

  # Sets the instance variable named by *symbol* to the given object, thereby
  # frustrating the efforts of the class's author to attempt to provide proper
  # encapsulation. The variable does not have to exist prior to this call. If the
  # instance variable name is passed as a string, that string is converted to a
  # symbol.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_set(:@a, 'dog')   #=> "dog"
  #     fred.instance_variable_set(:@c, 'cat')   #=> "cat"
  #     fred.inspect                             #=> "#<Fred:0x401b3da8 @a=\"dog\", @b=99, @c=\"cat\">"
  #
  def instance_variable_set: [X] (String | Symbol var, X value) -> X

  # Returns an array of instance variable names for the receiver. Note that simply
  # defining an accessor does not create the corresponding instance variable.
  #
  #     class Fred
  #       attr_accessor :a1
  #       def initialize
  #         @iv = 3
  #       end
  #     end
  #     Fred.new.instance_variables   #=> [:@iv]
  #
  def instance_variables: () -> Array[Symbol]

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  def is_a?: (Module) -> bool

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  alias kind_of? is_a?

  # Returns the receiver.
  #
  #     string = "my string"
  #     string.itself.object_id == string.object_id   #=> true
  #
  def `itself`: () -> self

  # Looks up the named method as a receiver in *obj*, returning a `Method` object
  # (or raising `NameError`). The `Method` object acts as a closure in *obj*'s
  # object instance, so instance variables and the value of `self` remain
  # available.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     m = k.method(:hello)
  #     m.call   #=> "Hello, @iv = 99"
  #
  #     l = Demo.new('Fred')
  #     m = l.method("hello")
  #     m.call   #=> "Hello, @iv = Fred"
  #
  # Note that `Method` implements `to_proc` method, which means it can be used
  # with iterators.
  #
  #     [ 1, 2, 3 ].each(&method(:puts)) # => prints 3 lines to stdout
  #
  #     out = File.open('test.txt', 'w')
  #     [ 1, 2, 3 ].each(&out.method(:puts)) # => prints 3 lines to file
  #
  #     require 'date'
  #     %w[2017-03-01 2017-03-02].collect(&Date.method(:parse))
  #     #=> [#<Date: 2017-03-01 ((2457814j,0s,0n),+0s,2299161j)>, #<Date: 2017-03-02 ((2457815j,0s,0n),+0s,2299161j)>]
  #
  def method: (String | Symbol name) -> Method

  # Returns a list of the names of public and protected methods of *obj*. This
  # will include all the methods accessible in *obj*'s ancestors. If the optional
  # parameter is `false`, it returns an array of *obj<i>'s public and protected
  # singleton methods, the array will not include methods in modules included in
  # <i>obj*.
  #
  #     class Klass
  #       def klass_method()
  #       end
  #     end
  #     k = Klass.new
  #     k.methods[0..9]    #=> [:klass_method, :nil?, :===,
  #                        #    :==~, :!, :eql?
  #                        #    :hash, :<=>, :class, :singleton_class]
  #     k.methods.length   #=> 56
  #
  #     k.methods(false)   #=> []
  #     def k.singleton_method; end
  #     k.methods(false)   #=> [:singleton_method]
  #
  #     module M123; def m123; end end
  #     k.extend M123
  #     k.methods(false)   #=> [:singleton_method]
  #
  def methods: () -> Array[Symbol]

  # Only the object *nil* responds `true` to `nil?`.
  #
  #     Object.new.nil?   #=> false
  #     nil.nil?          #=> true
  #
  def `nil?`: () -> bool

  # Returns an integer identifier for `obj`.
  #
  # The same number will be returned on all calls to `object_id` for a given
  # object, and no two active objects will share an id.
  #
  # Note: that some objects of builtin classes are reused for optimization. This
  # is the case for immediate values and frozen string literals.
  #
  # Immediate values are not passed by reference but are passed by value: `nil`,
  # `true`, `false`, Fixnums, Symbols, and some Floats.
  #
  #     Object.new.object_id  == Object.new.object_id  # => false
  #     (21 * 2).object_id    == (21 * 2).object_id    # => true
  #     "hello".object_id     == "hello".object_id     # => false
  #     "hi".freeze.object_id == "hi".freeze.object_id # => true
  #
  def object_id: () -> Integer

  # Returns the list of private methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def private_methods: () -> Array[Symbol]

  # Returns the list of protected methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def protected_methods: () -> Array[Symbol]

  # Similar to *method*, searches public method only.
  #
  def public_method: (name name) -> Method

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # Unlike send, public_send calls public methods only. When the method is
  # identified by a string, the string is converted to a symbol.
  #
  #     1.public_send(:puts, "hello")  # causes NoMethodError
  #
  def `public_send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Removes the named instance variable from *obj*, returning that variable's
  # value. String arguments are converted to symbols.
  #
  #     class Dummy
  #       attr_reader :var
  #       def initialize
  #         @var = 99
  #       end
  #       def remove
  #         remove_instance_variable(:@var)
  #       end
  #     end
  #     d = Dummy.new
  #     d.var      #=> 99
  #     d.remove   #=> 99
  #     d.var      #=> nil
  #
  def remove_instance_variable: (name name) -> untyped

  # Returns `true` if *obj* responds to the given method.  Private and protected
  # methods are included in the search only if the optional second parameter
  # evaluates to `true`.
  #
  # If the method is not implemented, as Process.fork on Windows, File.lchmod on
  # GNU/Linux, etc., false is returned.
  #
  # If the method is not defined, `respond_to_missing?` method is called and the
  # result is returned.
  #
  # When the method name parameter is given as a string, the string is converted
  # to a symbol.
  #
  def respond_to?: (name name, ?boolish include_all) -> bool

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # You can use `__send__` if the name `send` clashes with an existing method in
  # *obj*. When the method is identified by a string, the string is converted to a
  # symbol.
  #
  #     class Klass
  #       def hello(*args)
  #         "Hello " + args.join(' ')
  #       end
  #     end
  #     k = Klass.new
  #     k.send :hello, "gentle", "readers"   #=> "Hello gentle readers"
  #
  def `send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Returns the singleton class of *obj*.  This method creates a new singleton
  # class if *obj* does not have one.
  #
  # If *obj* is `nil`, `true`, or `false`, it returns NilClass, TrueClass, or
  # FalseClass, respectively. If *obj* is an Integer, a Float or a Symbol, it
  # raises a TypeError.
  #
  #     Object.new.singleton_class  #=> #<Class:#<Object:0xb7ce1e24>>
  #     String.singleton_class      #=> #<Class:String>
  #     nil.singleton_class         #=> NilClass
  #
  def `singleton_class`: () -> Class

  # Similar to *method*, searches singleton method only.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     def k.hi
  #       "Hi, @iv = #{@iv}"
  #     end
  #     m = k.singleton_method(:hi)
  #     m.call   #=> "Hi, @iv = 99"
  #     m = k.singleton_method(:hello) #=> NameError
  #
  def singleton_method: (name name) -> Method

  # Returns an array of the names of singleton methods for *obj*. If the optional
  # *all* parameter is true, the list will include methods in modules included in
  # *obj*. Only public and protected singleton methods are returned.
  #
  #     module Other
  #       def three() end
  #     end
  #
  #     class Single
  #       def Single.four() end
  #     end
  #
  #     a = Single.new
  #
  #     def a.one()
  #     end
  #
  #     class << a
  #       include Other
  #       def two()
  #       end
  #     end
  #
  #     Single.singleton_methods    #=> [:four]
  #     a.singleton_methods(false)  #=> [:two, :one]
  #     a.singleton_methods         #=> [:two, :one, :three]
  #
  def singleton_methods: () -> Array[Symbol]

  # Mark the object as tainted.
  #
  # Objects that are marked as tainted will be restricted from various built-in
  # methods. This is to prevent insecure data, such as command-line arguments or
  # strings read from Kernel#gets, from inadvertently compromising the user's
  # system.
  #
  # To check whether an object is tainted, use #tainted?.
  #
  # You should only untaint a tainted object if your code has inspected it and
  # determined that it is safe. To do so use #untaint.
  #
  def taint: () -> self

  # Deprecated method that is equivalent to #taint.
  #
  alias untrust taint

  # Returns true if the object is tainted.
  #
  # See #taint for more information.
  #
  def tainted?: () -> bool

  # Deprecated method that is equivalent to #tainted?.
  #
  alias untrusted? tainted?

  # Yields self to the block, and then returns self. The primary purpose of this
  # method is to "tap into" a method chain, in order to perform operations on
  # intermediate results within the chain.
  #
  #     (1..10)                  .tap {|x| puts "original: #{x}" }
  #       .to_a                  .tap {|x| puts "array:    #{x}" }
  #       .select {|x| x.even? } .tap {|x| puts "evens:    #{x}" }
  #       .map {|x| x*x }        .tap {|x| puts "squares:  #{x}" }
  #
  def tap: () { (self) -> void } -> self

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.$obj=new is== yargs($obj)==(ARGS)).); /            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  def `yield_self`: [X] (c) { (self) -> X } -> X
                  |yargs==(is).);==(ARGS) -> Enumerator[self, untyped]
  # Returns a string representing *obj*. The default `to_s` prints the object's
  # class and an encoding of the object id. As a special case, the top-level
  # object that is the initial execution context of Ruby programs returns
  # ``main''.
  #
  def to_s: (((c)) -> String

  # Removes the tainted mark from the object.
  #
  # See #taint for more information.
  #
  def untaint: ((r))) -> self

  # Deprecated method that is equivalent to #untaint.
  #
  alias trust untaint

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.yield_self.detect(&:odd?)            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  alias then yield_self
end

interface _Writeable
  def write: (untyped) -> void
end

type Object::name = Symbol | String'"''
'".git-/~get.commit for superproject and submodules
    rake git:configure     
    ## Configure Rails for git
    rake git:diff          
    ## git diff for superproject and submodules
    rake git:for_each      # Run command in all ## submodules and superproject.
    rake git:pull          # git pull for ##:superproject and submodules
    rake git:push          # git push for ## superproject and submodules
    rake git:status        
    ## git status for superproject and submodules
    rake git:tag          
    ## Tag superproject and submodules.
    rake git:update        
    #@# Update superproject with current submodule-on:' '"'#'"''
    '"##'"' '"':'"' 'This is a basic workflow to help you get started with actions.js'"'''
'"name'"':'"' '"':'"' '"build-and-deployee'"'''
# Controls when the action-TRIGGERS-events_get.EventListener()==get.EventLostener(on)#://-on::/Run::/starts::/On::/Build:;/Script:''
'"the-workflow-run-on-automates-actions-Trigger-events: workflows'"''
workflows: run+on'"''
'" run-on'"':'"' '::on:'"'
'"on'"':'"'
'"on'"':'"'** **'"Automates pushs and - events but only for the Masterbranch'"'''
'":Pushs::'"' '"'[branches']'"::
'"'[branches']'"':'"'** "*'"'[' main' ']'"'''
'"pull'_requests'"':'"'** **'"'[mainbranch']''
'"'[branch']'"':'"'** **'"'[trunk']'"''
  # Allows you to run this workflow manually from the Actions tab
# -workflow_call:''
 -on''
# A workflow run is made up of one or more jobs that can run sequentially or in parallel
# jobs:
# This workflow contains a single job called'"'''
"build-and-deployee-heroku'@CI
# The type of runner that the job will run on
# runs-on: ubuntu-latest
# steps represent a sequence of tasks that will:
'be executed as part of the job'"'''
'"#'"** **'"jobs'"':
#' '-step:' checksout: action'@,pkg.js'"''
'"your repository under $GITHUB_WORKSPACE, so''
'your job can access it: it: :uses:: '"actions''
'/checkout@v2'"''"
'"Runs-on:' A-multi-line-one-line-script'"''
'"initializes:'"" '"" using' the' runners' shell
'- name: Run a one-line script'"'''
#' '"echo:' '"hello*'*'' '*'*World'!'"'
#' '"name:'"' 'Run a multi-line script'"''"
#' '"echo:" 'test, and deploy your project'"''
        'private|public| static boolean''
        'avcesd:'"' 'private''
'class initializer !! one time setup''
'if Cababilities"Linux32|MacOS64_86"sets-up:' -./inputs'@svnerede*logs::All:*logs::Automates::':'Automate''
'Automate:-,upfates:' 'sevredne''
'"const:'"':'"'''
'{{''${{'{[(GITHUB.SECRET)]}.{[VOLUME]}.{ITEM_ID}}''}}"''
')]}[(Volume)]ITEM'_ID)]}}' }::*}backtrace:All:*logs:'-'returns','?'.':'"''
'"returns:'"':'"' '?'=''='"mojoejoejoejoe/bitore.sigs/user/bin/Bash-{asyns'@mojoejoejoejoe/paradice/Repo'''
'-a'Sync'@ZachryTylerWood'@Adminiatrator'@.git.it/repositories/Flask/Whisk/Cake/Rust/Perl/fiddle/thimbal-curls/lang',' 'fetchs'-sevredne;
        }bundle-on:: Python.js::input::All::'Fix::'::Perfect::'::All::thimbal-cUrl::plugins::
#        '''"'"''</public>::func:: name '
        !}
    }
}

# '" "'function''" "''congif'" '*(Ags')')'"''
'Start:://On:://Run:://Script:://Builfd:://Script:://action_script:://const:://DOCKER.Gui.svg.Jpeg,.xls A can only be accessed within this file
}

# **What it does**: This builds our Docker container.
'Run::##GLOW2##::**Why we have it**: We don't use the DOCKER.Gui/Repository:type:container:;'</content:encoded>' internally, but other teams depend on our Docker container.
# **Who does it impact**: Enterprise customers.
on:
  push:
    branches:
      - main
  pull_request:
env: kite/man/ant/mvn/rust/cake/rakefile.yml.json./package.yamlapi/adk/sdk.s.e./'$'.mkdir/src::Auto_squash_merge''"/file/rubykg.yml///rust.ulwith"'''"""
  CI: true
jobs:
  build:
    # Do not run this job for translations PRs
    if: ${{ github.head_ref != 'translations' && github.ref != 'refs/heads/translations' }}
    runs-on: ubuntu-latest
   # '" 'steps'"''
   :uses'"action'Automate'"::const:: '"Automatic-updates-on-Command-progressivly" during::build_script_"const'
   #  "Commands_" '"action"'
   *'action'<'/control>'+'</spc'bar'"','"'func>::on::enable::funct::run::On:;</triggerfunct'"''</Enabled>::on"'"'' ''and'"','"on'",":,""''-''"''*logs"
   "all 

      '**"''-Name:'**"BITORE.sig''"'
'**""##'"''Checksout:'" 'Versioning'@v'-1.7.13.9.10'"''
        '**"- uses:'**" "TEIRAFORMA'.doc".pdf"'#Push::''"pushs_request:'"TEIRAFORMA'@Energy_Manifest"'Pushs::'results'::returns::pulls_request:Magic::'::Manifesto::Mannifest::'::Energy:'::#pulls_request::'"''
       '**"#Pulls::Request:'"'pulls_'Requests
        _#Pull: branches: 'ant/Automatic-updates-on-Command-progressivly='>''shapeshifts''='>'doc'x'
      **'**"- name: cake/railsà
     '"**-' '"'Repository:type:container.img:DOCKER.Gui.svg.png:type:containerThis workflow will upload a Python Package using Twine when a release is created
'For more information see: https://help.github.com/en/actions/language-and-framework-guides/using-python-with-github-actions#publishing-to-package-registries''
# documentation.

name: build-and-deployee

on: 
  release:
    types: 
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version:x'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build
    - name: Build package
      run: python -m build
    - name: Publish package
      uses: javascript
      with: 

# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: GKE_PROJECT with the name of the project and GKE_SA_KEY with the Base64 encoded JSON service account key (https://github.com/GoogleCloudPlatform/github-actions/tree/docs/service-account-key/setup-gcloud#inputs).
#
# 3. Change the values for the GKE_ZONE, GKE_CLUSTER, IMAGE, and DEPLOYMENT_NAME environment variables (below).
#
# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke

name: Build and Deploy to GKE

on:
  push:
    branches:
      - master

env:
  PROJECT_ID: ${{ secrets.GKE_PROJECT }}
  GKE_CLUSTER: cluster-1    # TODO: update to cluster name
  GKE_ZONE: us-central1-c   # TODO: update to cluster zone
  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name
  IMAGE: static-site

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production

    steps:
    - name: Checkout
      uses: actions/checkout@v2

    # Setup gcloud CLI
    - uses: google-github-actions/setup-gcloud@v0.2.0
      with:
        service_account_key: ${{ secrets.GKE_SA_KEY }}
        project_id: ${{ secrets.GKE_PROJECT }}

    # Configure Docker to use the gcloud command-line tool as a credential
    # helper for authentication
    - run: |-
        gcloud --quiet auth configure-docker

    # Get the GKE credentials so we can deploy to the cluster
    - uses: google-github-actions/get-gke-credentials@v0.2.1
      with:
        cluster_name: ${{ env.GKE_CLUSTER }}
        location: ${{ env.GKE_ZONE }}
        credentials: ${{ secrets.GKE_SA_KEY }}

    # Build the Docker image
    - name: Build
      run: |-
        docker build \
          --tag "gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" \
          .

    # Push the Docker image to Google Container Registry
    - name: Publish
      run: |-
        docker push "gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA"

    # Set up kustomize
    - name: Set up Kustomize
      run: |-
        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    # Deploy the Docker image to the GKE cluster
    - name: Deploy
      run: |-
        ./kustomize edit set image gcr.io/PROJECT_ID/IMAGE:TAG=gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl get services -o wide
# This workflow will build and push a new container image to Alibaba Cloud Container Registry (ACR),
# and then will deploy it to Alibaba Cloud Container Service for Kubernetes (ACK), when there is a push to the master branch.
#
# To use this workflow, you will need to complete the following set-up steps:
#
# 1. Create an ACR repository to store your container images. 
#    You can use ACR EE instance for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/142168.htm
#
# 2. Create an ACK cluster to run your containerized application.
#    You can use ACK Pro cluster for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/95108.htm
#
# 3. Store your AccessKey pair in GitHub Actions secrets named `ACCESS_KEY_ID` and `ACCESS_KEY_SECRET`.
#    For instructions on setting up secrets see: https://developer.github.com/actions/managing-workflows/storing-secrets/
#
# 4. Change the values for the REGION_ID, REGISTRY, NAMESPACE, IMAGE, ACK_CLUSTER_ID, and ACK_DEPLOYMENT_NAME. 
#

name: Build and Deployee

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow.
env:
  REGION_ID: cn-hangzhou
  REGISTRY: registry.cn-hangzhou.aliyuncs.com
  NAMESPACE: namespace
  IMAGE: repo
  TAG: ${{ github.sha }}
  ACK_CLUSTER_ID: clusterID
  ACK_DEPLOYMENT_NAME: nginx-deployment

  ACR_EE_REGISTRY: myregistry.cn-hangzhou.cr.aliyuncs.com
  ACR_EE_INSTANCE_ID: instanceID
  ACR_EE_NAMESPACE: namespace
  ACR_EE_IMAGE: repo
  ACR_EE_TAG: ${{ github.sha }}

jobs:
  build:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout
      uses: actions/checkout@v2
    
    # 1.1 Login to ACR   
    - name: Login to ACR with the AccessKey pair
     '"uses:'"' aliyun/acr-logs'-in'@v-0.0.0.
      with:
        '"region-id:' '"${{ env.REGION_ID }}'"''
        '"access-key-id:'"' '${{ secret'"':GITHUB.TOKEN.[VOLUME].ITEM_ID'"''
        '"ACCESS_KEY_ID }}'"':
        '"access-secrets:'"' '{{ '"${{[(((C))((R)))]}{[1275375.00]}{BITORE_34173}}}'"''" }}"

    # 1.2 Buid and push image to ACR   
    - name: Build and push image to ACR  
      run: |
        docker build --tag "$REGISTRY/$NAMESPACE/$IMAGE:$TAG" .  
        docker push "$REGISTRY/$NAMESPACE/$IMAGE:$TAG"   
 
    # 1.3 Scan image in ACR   
    - name: Scan image in ACR
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        repository: "${{ env.NAMESPACE }}/${{ env.IMAGE }}"
        tag: "${{ env.TAG }}"

    # 2.1 (Optional) Login to ACR EE          
    - uses: actions/checkout@v2
    - name: Login to ACR EE with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        login-server: "https://${{ env.ACR_EE_REGISTRY }}"
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"

    # 2.2 (Optional) Build and push image ACR EE          
    - name: Build and push image to ACR EE  
      run: |
        docker build -t "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG" .
        docker push "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG"
    # 2.3 (Optional) Scan image in ACR EE          
    - name: Scan image in ACR EE
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"
        repository: "${{ env.ACR_EE_NAMESPACE}}/${{ env.ACR_EE_IMAGE }}"
        tag: "${{ env.ACR_EE_TAG }}"

    # 3.1 Set ACK context         
    - name: Set K8s context
      uses: aliyun/ack-set-context@v1
      with:
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        cluster-id: "${{ env.ACK_CLUSTER_ID }}"

    # 3.2 Deploy the image to the ACK cluster
    - name: Set up Kustomize
      run: |-
        curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh"  | bash /dev/stdin 3.8.6
    - name: Deploy
      run: |-
        ./kustomize edit set image REGISTRY/NAMESPACE/IMAGE:TAG=$REGISTRY/$NAMESPACE/$IMAGE:$TAG
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$ACK_DEPLOYMENT_NAME
        kubectl get services -o wide
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: 

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This workflow will run tests using node and then publish a package to GitHub Packages when a release is created
# For more information see: https://help.github.com/actions/language-and-framework-guides/publishing-nodejs-packages

name: Node.js Package

on:
  release:
    types: [created]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
      - run: npm ci
      - run: npm test

  publish-npm:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
          registry-url: https://registry.npmjs.org/
      - run: npm ci
      - run: npm publish
        env:
          NODE_AUTH_TOKEN: ${{secrets.npm_token}}

  publish-gpr:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          -node-version: 14
          -registry-url: https://npm.pkg.github.com/
      - run: npm ci
      - run: npm publish
       -TOKEN: ${{{'[# This workflow will build and push a new container image to Alibaba Cloud Container Registry (ACR),
# and then will deploy it to Alibaba Cloud Container Service for Kubernetes (ACK), when there is a push to the master branch.
#
# To use this workflow, you will need to complete the following set-up steps:
#
# 1. Create an ACR repository to store your container images. 
#    You can use ACR EE instance for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/142168.htm
#
# 2. Create an ACK cluster to run your containerized application.
#    You can use ACK Pro cluster for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/95108.htm
#
# 3. Store your AccessKey pair in GitHub Actions secrets named `ACCESS_KEY_ID` and `ACCESS_KEY_SECRET`.
#    For instructions on setting up secrets see: https://developer.github.com/actions/managing-workflows/storing-secrets/
#
# 4. Change the values for the REGION_ID, REGISTRY, NAMESPACE, IMAGE, ACK_CLUSTER_ID, and ACK_DEPLOYMENT_NAME. 
#

name: Build and Deployee

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow.
env:
  REGION_ID: cn-hangzhou
  REGISTRY: registry.cn-hangzhou.aliyuncs.com
  NAMESPACE: namespace
  IMAGE: repo
  TAG: ${{ github.sha }}
  ACK_CLUSTER_ID: clusterID
  ACK_DEPLOYMENT_NAME: nginx-deployment

  ACR_EE_REGISTRY: myregistry.cn-hangzhou.cr.aliyuncs.com
  ACR_EE_INSTANCE_ID: instanceID
  ACR_EE_NAMESPACE: namespace
  ACR_EE_IMAGE: repo
  ACR_EE_TAG: ${{ github.sha }}

jobs:
  build:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout
      uses: actions/checkout@v2
    
    # 1.1 Login to ACR   
    - name: Login to ACR with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"

    # 1.2 Buid and push image to ACR   
    - name: Build and push image to ACR  
      run: |
        docker build --tag "$REGISTRY/$NAMESPACE/$IMAGE:$TAG" .  
        docker push "$REGISTRY/$NAMESPACE/$IMAGE:$TAG"   
 
    # 1.3 Scan image in ACR   
    - name: Scan image in ACR
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        repository: "${{ env.NAMESPACE }}/${{ env.IMAGE }}"
        tag: "${{ env.TAG }}"

    # 2.1 (Optional) Login to ACR EE          
    - uses: actions/checkout@v2
    - name: Login to ACR EE with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        login-server: "https://${{ env.ACR_EE_REGISTRY }}"
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"

    # 2.2 (Optional) Build and push image ACR EE          
    - name: Build and push image to ACR EE  
      run: |
        docker build -t "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG" .
        docker push "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG"
    # 2.3 (Optional) Scan image in ACR EE          
    - name: Scan image in ACR EE
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"
        repository: "${{ env.ACR_EE_NAMESPACE}}/${{ env.ACR_EE_IMAGE }}"
        tag: "${{ env.ACR_EE_TAG }}"

    # 3.1 Set ACK context         
    - name: Set K8s context
      uses: aliyun/ack-set-context@v1
      with:
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        cluster-id: "${{ env.ACK_CLUSTER_ID }}"

    # 3.2 Deploy the image to the ACK cluster
    - name: Set up Kustomize
      run: |-
        curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh"  | bash /dev/stdin 3.8.6
    - name: Deploy
      run: |-
        ./kustomize edit set image REGISTRY/NAMESPACE/IMAGE:TAG=$REGISTRY/$NAMESPACE/$IMAGE:$TAG
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$ACK_DEPLOYMENT_NAME
        kubectl get services -o wide
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This workflow will run tests using node and then publish a package to GitHub Packages when a release is created
# For more information see: https://help.github.com/actions/language-and-framework-guides/publishing-nodejs-packages

name: Node.js Package

on:
  release:
    types: [created]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
      - run: npm ci
      - run: npm test

  publish-npm:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
          registry-url: https://registry.npmjs.org/
      - run: npm ci
      - run: npm publish
        env:
          NODE_AUTH_TOKEN: ${{secrets.npm_token}}

  publish-gpr:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          -node-version: 14
          -registry-url: https://npm.pkg.github.com/
      - run: npm ci
      - run: npm publish
        '"-env'"':'"' c${{{{[(TOKEN)]}.{[VOLUME]}.{ITEM_ID}}}}": "{{{{[((c)(r))']}.{'[12753750.00']}.{BITORE_34174}}}}'"''
'"'::Build:"'''
'"'::Publish::'"'''
'"'::Deploy:'"''' :
'"'::Return'"':'"' 'Run ''
# Object is the default root of all Ruby objects.  Object inherits from
# BasicObject which allows creating alternate object hierarchies.  Methods on
# Object are available to all classes unless explicitly overridden.
#
# Object mixes in the Kernel module, making the built-in kernel functions
# globally accessible.  Although the instance methods of Object are defined by
# the Kernel module, we have chosen to document them here for clarity.
#
# When referencing constants in classes inheriting from Object you do not need
# to use the full namespace.  For example, referencing `File` inside `YourClass`
# will find the top-level File class.
#
# In the descriptions of Object's methods, the parameter *symbol* refers to a
# symbol, which is either a quoted string or a Symbol (such as `:name`).
#
class Object < BasicObject
  include Kernel

  # Returns true if two objects do not match (using the *=~* method), otherwise
  # false.
  #
  def !~: (untyped) -> bool

  # Returns 0 if `obj` and `other` are the same object or `obj == other`,
  # otherwise nil.
  #
  # The `<=>` is used by various methods to compare objects, for example
  # Enumerable#sort, Enumerable#max etc.
  #
  # Your implementation of `<=>` should return one of the following values: -1, 0,
  # 1 or nil. -1 means self is smaller than other. 0 means self is equal to other.
  # 1 means self is bigger than other. Nil means the two values could not be
  # compared.
  #
  # When you define `<=>`, you can include Comparable to gain the methods `<=`,
  # `<`, `==`, `>=`, `>` and `between?`.
  #
  def <=>: (untyped) -> Integer?

  # Case Equality -- For class Object, effectively the same as calling `#==`, but
  # typically overridden by descendants to provide meaningful semantics in `case`
  # statements.
  #
  def ===: (untyped) -> bool

  # This method is deprecated.
  #
  # This is not only unuseful but also troublesome because it may hide a type
  # error.
  #
  def =~: (untyped) -> bool

  # Returns the class of *obj*. This method must always be called with an explicit
  # receiver, as `class` is also a reserved word in Ruby.
  #
  #     1.class      #=> Integer
  #     self.class   #=> Object
  #
  def `class`: () -> untyped

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `clone` copies the frozen (unless :freeze
  # keyword argument is given with a false value) and tainted state of *obj*. See
  # also the discussion under `Object#dup`.
  #
  #     class Klass
  #        attr_accessor :str
  #     end
  #     s1 = Klass.new      #=> #<Klass:0x401b3a38>
  #     s1.str = "Hello"    #=> "Hello"
  #     s2 = s1.clone       #=> #<Klass:0x401b3998 @str="Hello">
  #     s2.str[1,4] = "i"   #=> "i"
  #     s1.inspect          #=> "#<Klass:0x401b3a38 @str=\"Hi\">"
  #     s2.inspect          #=> "#<Klass:0x401b3998 @str=\"Hi\">"
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  def clone: (?freeze: bool) -> self

  # Defines a singleton method in the receiver. The *method* parameter can be a
  # `Proc`, a `Method` or an `UnboundMethod` object. If a block is specified, it
  # is used as the method body.
  #
  #     class A
  #       class << self
  #         def class_name
  #           to_s
  #         end
  #       end
  #     end
  #     A.define_singleton_method(:who_am_i) do
  #       "I am: #{class_name}"
  #     end
  #     A.who_am_i   # ==> "I am: A"
  #
  #     guy = "Bob"
  #     guy.define_singleton_method(:hello) { "#{self}: Hello there!" }
  #     guy.hello    #=>  "Bob: Hello there!"
  #
  def define_singleton_method: (Symbol, Method | UnboundMethod) -> Symbol
                             | (Symbol) { (*untyped) -> untyped } -> Symbol

  # Prints *obj* on the given port (default `$>`). Equivalent to:
  #
  #     def display(port=$>)
  #       port.write self
  #       nil
  #     end
  #
  # For example:
  #
  #     1.display
  #     "cat".display
  #     [ 4, 5, 6 ].display
  #     puts
  #
  # *produces:*
  #
  #     1cat[4, 5, 6]
  #
  def display: (?_Writeable port) -> void

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `dup` copies the tainted state of *obj*.
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  # ### on dup vs clone
  #
  # In general, `clone` and `dup` may have different semantics in descendant
  # classes. While `clone` is used to duplicate an object, including its internal
  # state, `dup` typically uses the class of the descendant object to create the
  # new instance.
  #
  # When using #dup, any modules that the object has been extended with will not
  # be copied.
  #
  #     class Klass
  #       attr_accessor :str
  #     end
  #
  #     module Foo
  #       def foo; 'foo'; end
  #     end
  #
  #     s1 = Klass.new #=> #<Klass:0x401b3a38>
  #     s1.extend(Foo) #=> #<Klass:0x401b3a38>
  #     s1.foo #=> "foo"
  #
  #     s2 = s1.clone #=> #<Klass:0x401b3a38>
  #     s2.foo #=> "foo"
  #
  #     s3 = s1.dup #=> #<Klass:0x401b3a38>
  #     s3.foo #=> NoMethodError: undefined method `foo' for #<Klass:0x401b3a38>
  #
  def dup: () -> self

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  def enum_for: (Symbol method, *untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]
              | (*untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  alias to_enum enum_for

  # Equality --- At the `Object` level, `==` returns `true` only if `obj` and
  # `other` are the same object. Typically, this method is overridden in
  # descendant classes to provide class-specific meaning.
  #
  # Unlike `==`, the `equal?` method should never be overridden by subclasses as
  # it is used to determine object identity (that is, `a.equal?(b)` if and only if
  # `a` is the same object as `b`):
  #
  #     obj = "a"
  #     other = obj.dup
  #
  #     obj == other      #=> true
  #     obj.equal? other  #=> false
  #     obj.equal? obj    #=> true
  #
  # The `eql?` method returns `true` if `obj` and `other` refer to the same hash
  # key.  This is used by Hash to test members for equality.  For objects of class
  # `Object`, `eql?` is synonymous with `==`.  Subclasses normally continue this
  # tradition by aliasing `eql?` to their overridden `==` method, but there are
  # exceptions.  `Numeric` types, for example, perform type conversion across
  # `==`, but not across `eql?`, so:
  #
  #     1 == 1.0     #=> true
  #     1.eql? 1.0   #=> false
  #
  def eql?: (untyped) -> bool

  # Adds to *obj* the instance methods from each module given as a parameter.
  #
  #     module Mod
  #       def hello
  #         "Hello from Mod.\n"
  #       end
  #     end
  #
  #     class Klass
  #       def hello
  #         "Hello from Klass.\n"
  #       end
  #     end
  #
  #     k = Klass.new
  #     k.hello         #=> "Hello from Klass.\n"
  #     k.extend(Mod)   #=> #<Klass:0x401b3bc8>
  #     k.hello         #=> "Hello from Mod.\n"
  #
  def `extend`: (*Module) -> self

  # Prevents further modifications to *obj*. A `RuntimeError` will be raised if
  # modification is attempted. There is no way to unfreeze a frozen object. See
  # also `Object#frozen?`.
  #
  # This method returns self.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze
  #     a << "z"
  #
  # *produces:*
  #
  #     prog.rb:3:in `<<': can't modify frozen Array (FrozenError)
  #      from prog.rb:3
  #
  # Objects of the following classes are always frozen: Integer, Float, Symbol.
  #
  def freeze: () -> self

  # Returns the freeze status of *obj*.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze    #=> ["a", "b", "c"]
  #     a.frozen?   #=> true
  #
  def frozen?: () -> bool

  def hash: () -> Integer

  # Returns a string containing a human-readable representation of *obj*. The
  # default `inspect` shows the object's class name, an encoding of the object id,
  # and a list of the instance variables and their values (by calling #inspect on
  # each of them). User defined classes should override this method to provide a
  # better representation of *obj*.  When overriding this method, it should return
  # a string whose encoding is compatible with the default external encoding.
  #
  #     [ 1, 2, 3..4, 'five' ].inspect   #=> "[1, 2, 3..4, \"five\"]"
  #     Time.new.inspect                 #=> "2008-03-08 19:43:39 +0900"
  #
  #     class Foo
  #     end
  #     Foo.new.inspect                  #=> "#<Foo:0x0300c868>"
  #
  #     class Bar
  #       def initialize
  #         @bar = 1
  #       end
  #     end
  #     Bar.new.inspect                  #=> "#<Bar:0x0300c868 @bar=1>"
  #
  def inspect: () -> String

  # Returns `true` if *obj* is an instance of the given class. See also
  # `Object#kind_of?`.
  #
  #     class A;     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.instance_of? A   #=> false
  #     b.instance_of? B   #=> true
  #     b.instance_of? C   #=> false
  #
  def instance_of?: (Module) -> bool

  # Returns `true` if the given instance variable is defined in *obj*. String
  # arguments are converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_defined?(:@a)    #=> true
  #     fred.instance_variable_defined?("@b")   #=> true
  #     fred.instance_variable_defined?("@c")   #=> false
  #
  def instance_variable_defined?: (String | Symbol var) -> bool

  # Returns the value of the given instance variable, or nil if the instance
  # variable is not set. The `@` part of the variable name should be included for
  # regular instance variables. Throws a `NameError` exception if the supplied
  # symbol is not valid as an instance variable name. String arguments are
  # converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_get(:@a)    #=> "cat"
  #     fred.instance_variable_get("@b")   #=> 99
  #
  def instance_variable_get: (String | Symbol var) -> untyped

  # Sets the instance variable named by *symbol* to the given object, thereby
  # frustrating the efforts of the class's author to attempt to provide proper
  # encapsulation. The variable does not have to exist prior to this call. If the
  # instance variable name is passed as a string, that string is converted to a
  # symbol.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_set(:@a, 'dog')   #=> "dog"
  #     fred.instance_variable_set(:@c, 'cat')   #=> "cat"
  #     fred.inspect                             #=> "#<Fred:0x401b3da8 @a=\"dog\", @b=99, @c=\"cat\">"
  #
  def instance_variable_set: [X] (String | Symbol var, X value) -> X

  # Returns an array of instance variable names for the receiver. Note that simply
  # defining an accessor does not create the corresponding instance variable.
  #
  #     class Fred
  #       attr_accessor :a1
  #       def initialize
  #         @iv = 3
  #       end
  #     end
  #     Fred.new.instance_variables   #=> [:@iv]
  #
  def instance_variables: () -> Array[Symbol]

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  def is_a?: (Module) -> bool

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  alias kind_of? is_a?

  # Returns the receiver.
  #
  #     string = "my string"
  #     string.itself.object_id == string.object_id   #=> true
  #
  def `itself`: () -> self

  # Looks up the named method as a receiver in *obj*, returning a `Method` object
  # (or raising `NameError`). The `Method` object acts as a closure in *obj*'s
  # object instance, so instance variables and the value of `self` remain
  # available.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     m = k.method(:hello)
  #     m.call   #=> "Hello, @iv = 99"
  #
  #     l = Demo.new('Fred')
  #     m = l.method("hello")
  #     m.call   #=> "Hello, @iv = Fred"
  #
  # Note that `Method` implements `to_proc` method, which means it can be used
  # with iterators.
  #
  #     [ 1, 2, 3 ].each(&method(:puts)) # => prints 3 lines to stdout
  #
  #     out = File.open('test.txt', 'w')
  #     [ 1, 2, 3 ].each(&out.method(:puts)) # => prints 3 lines to file
  #
  #     require 'date'
  #     %w[2017-03-01 2017-03-02].collect(&Date.method(:parse))
  #     #=> [#<Date: 2017-03-01 ((2457814j,0s,0n),+0s,2299161j)>, #<Date: 2017-03-02 ((2457815j,0s,0n),+0s,2299161j)>]
  #
  def method: (String | Symbol name) -> Method

  # Returns a list of the names of public and protected methods of *obj*. This
  # will include all the methods accessible in *obj*'s ancestors. If the optional
  # parameter is `false`, it returns an array of *obj<i>'s public and protected
  # singleton methods, the array will not include methods in modules included in
  # <i>obj*.
  #
  #     class Klass
  #       def klass_method()
  #       end
  #     end
  #     k = Klass.new
  #     k.methods[0..9]    #=> [:klass_method, :nil?, :===,
  #                        #    :==~, :!, :eql?
  #                        #    :hash, :<=>, :class, :singleton_class]
  #     k.methods.length   #=> 56
  #
  #     k.methods(false)   #=> []
  #     def k.singleton_method; end
  #     k.methods(false)   #=> [:singleton_method]
  #
  #     module M123; def m123; end end
  #     k.extend M123
  #     k.methods(false)   #=> [:singleton_method]
  #
  def methods: () -> Array[Symbol]

  # Only the object *nil* responds `true` to `nil?`.
  #
  #     Object.new.nil?   #=> false
  #     nil.nil?          #=> true
  #
  def `nil?`: () -> bool

  # Returns an integer identifier for `obj`.
  #
  # The same number will be returned on all calls to `object_id` for a given
  # object, and no two active objects will share an id.
  #
  # Note: that some objects of builtin classes are reused for optimization. This
  # is the case for immediate values and frozen string literals.
  #
  # Immediate values are not passed by reference but are passed by value: `nil`,
  # `true`, `false`, Fixnums, Symbols, and some Floats.
  #
  #     Object.new.object_id  == Object.new.object_id  # => false
  #     (21 * 2).object_id    == (21 * 2).object_id    # => true
  #     "hello".object_id     == "hello".object_id     # => false
  #     "hi".freeze.object_id == "hi".freeze.object_id # => true
  #
  def object_id: () -> Integer

  # Returns the list of private methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def private_methods: () -> Array[Symbol]

  # Returns the list of protected methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def protected_methods: () -> Array[Symbol]

  # Similar to *method*, searches public method only.
  #
  def public_method: (name name) -> Method

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # Unlike send, public_send calls public methods only. When the method is
  # identified by a string, the string is converted to a symbol.
  #
  #     1.public_send(:puts, "hello")  # causes NoMethodError
  #
  def `public_send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Removes the named instance variable from *obj*, returning that variable's
  # value. String arguments are converted to symbols.
  #
  #     class Dummy
  #       attr_reader :var
  #       def initialize
  #         @var = 99
  #       end
  #       def remove
  #         remove_instance_variable(:@var)
  #       end
  #     end
  #     d = Dummy.new
  #     d.var      #=> 99
  #     d.remove   #=> 99
  #     d.var      #=> nil
  #
  def remove_instance_variable: (name name) -> untyped

  # Returns `true` if *obj* responds to the given method.  Private and protected
  # methods are included in the search only if the optional second parameter
  # evaluates to `true`.
  #
  # If the method is not implemented, as Process.fork on Windows, File.lchmod on
  # GNU/Linux, etc., false is returned.
  #
  # If the method is not defined, `respond_to_missing?` method is called and the
  # result is returned.
  #
  # When the method name parameter is given as a string, the string is converted
  # to a symbol.
  #
  def respond_to?: (name name, ?boolish include_all) -> bool

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # You can use `__send__` if the name `send` clashes with an existing method in
  # *obj*. When the method is identified by a string, the string is converted to a
  # symbol.
  #
  #     class Klass
  #       def hello(*args)
  #         "Hello " + args.join(' ')
  #       end
  #     end
  #     k = Klass.new
  #     k.send :hello, "gentle", "readers"   #=> "Hello gentle readers"
  #
  def `send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Returns the singleton class of *obj*.  This method creates a new singleton
  # class if *obj* does not have one.
  #
  # If *obj* is `nil`, `true`, or `false`, it returns NilClass, TrueClass, or
  # FalseClass, respectively. If *obj* is an Integer, a Float or a Symbol, it
  # raises a TypeError.
  #
  #     Object.new.singleton_class  #=> #<Class:#<Object:0xb7ce1e24>>
  #     String.singleton_class      #=> #<Class:String>
  #     nil.singleton_class         #=> NilClass
  #
  def `singleton_class`: () -> Class

  # Similar to *method*, searches singleton method only.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     def k.hi
  #       "Hi, @iv = #{@iv}"
  #     end
  #     m = k.singleton_method(:hi)
  #     m.call   #=> "Hi, @iv = 99"
  #     m = k.singleton_method(:hello) #=> NameError
  #
  def singleton_method: (name name) -> Method

  # Returns an array of the names of singleton methods for *obj*. If the optional
  # *all* parameter is true, the list will include methods in modules included in
  # *obj*. Only public and protected singleton methods are returned.
  #
  #     module Other
  #       def three() end
  #     end
  #
  #     class Single
  #       def Single.four() end
  #     end
  #
  #     a = Single.new
  #
  #     def a.one()
  #     end
  #
  #     class << a
  #       include Other
  #       def two()
  #       end
  #     end
  #
  #     Single.singleton_methods    #=> [:four]
  #     a.singleton_methods(false)  #=> [:two, :one]
  #     a.singleton_methods         #=> [:two, :one, :three]
  #
  def singleton_methods: () -> Array[Symbol]

  # Mark the object as tainted.
  #
  # Objects that are marked as tainted will be restricted from various built-in
  # methods. This is to prevent insecure data, such as command-line arguments or
  # strings read from Kernel#gets, from inadvertently compromising the user's
  # system.
  #
  # To check whether an object is tainted, use #tainted?.
  #
  # You should only untaint a tainted object if your code has inspected it and
  # determined that it is safe. To do so use #untaint.
  #
  def taint: () -> self

  # Deprecated method that is equivalent to #taint.
  #
  alias untrust taint

  # Returns true if the object is tainted.
  #
  # See #taint for more information.
  #
  def tainted?: () -> bool

  # Deprecated method that is equivalent to #tainted?.
  #
  alias untrusted? tainted?

  # Yields self to the block, and then returns self. The primary purpose of this
  # method is to "tap into" a method chain, in order to perform operations on
  # intermediate results within the chain.
  #
  #     (1..10)                  .tap {|x| puts "original: #{x}" }
  #       .to_a                  .tap {|x| puts "array:    #{x}" }
  #       .select {|x| x.even? } .tap {|x| puts "evens:    #{x}" }
  #       .map {|x| x*x }        .tap {|x| puts "squares:  #{x}" }
  #
  def tap: () { (self) -> void } -> self

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.$obj=new is== yargs($obj)==(ARGS)).); /            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  def `yield_self`: [X] (c) { (self) -> X } -> X
                  |yargs==(is).);==(ARGS) -> Enumerator[self, untyped]
  # Returns a string representing *obj*. The default `to_s` prints the object's
  # class and an encoding of the object id. As a special case, the top-level
  # object that is the initial execution context of Ruby programs returns
  # ``main''.
  #
  def to_s: (((c)) -> String

  # Removes the tainted mark from the object.
  #
  # See #taint for more information.
  #
  def untaint: ((r))) -> self

  # Deprecated method that is equivalent to #untaint.
  #
  alias trust untaint

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.yield_self.detect(&:odd?)            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  alias then yield_self
end

interface _Writeable
  def write: (untyped) -> void
end

type Object::name = Symbol | String# Object is the default root of all Ruby objects.  Object inherits from
# BasicObject which allows creating alternate object hierarchies.  Methods on
# Object are available to all classes unless explicitly overridden.
#
# Object mixes in the Kernel module, making the built-in kernel functions
# globally accessible.  Although the instance methods of Object are defined by
# the Kernel module, we have chosen to document them here for clarity.
#
# When referencing constants in classes inheriting from Object you do not need
# to use the full namespace.  For example, referencing `File` inside `YourClass`
# will find the top-level File class.
#
# In the descriptions of Object's methods, the parameter *symbol* refers to a
# symbol, which is either a quoted string or a Symbol (such as `:name`).
#
class Object < BasicObject
  include Kernel

  # Returns true if two objects do not match (using the *=~* method), otherwise
  # false.
  #
  def !~: (untyped) -> bool

  # Returns 0 if `obj` and `other` are the same object or `obj == other`,
  # otherwise nil.
  #
  # The `<=>` is used by various methods to compare objects, for example
  # Enumerable#sort, Enumerable#max etc.
  #
  # Your implementation of `<=>` should return one of the following values: -1, 0,
  # 1 or nil. -1 means self is smaller than other. 0 means self is equal to other.
  # 1 means self is bigger than other. Nil means the two values could not be
  # compared.
  #
  # When you define `<=>`, you can include Comparable to gain the methods `<=`,
  # `<`, `==`, `>=`, `>` and `between?`.
  #
  def <=>: (untyped) -> Integer?

  # Case Equality -- For class Object, effectively the same as calling `#==`, but
  # typically overridden by descendants to provide meaningful semantics in `case`
  # statements.
  #
  def ===: (untyped) -> bool

  # This method is deprecated.
  #
  # This is not only unuseful but also troublesome because it may hide a type
  # error.
  #
  def =~: (untyped) -> bool

  # Returns the class of *obj*. This method must always be called with an explicit
  # receiver, as `class` is also a reserved word in Ruby.
  #
  #     1.class      #=> Integer
  #     self.class   #=> Object
  #
  def `class`: () -> untyped

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `clone` copies the frozen (unless :freeze
  # keyword argument is given with a false value) and tainted state of *obj*. See
  # also the discussion under `Object#dup`.
  #
  #     class Klass
  #        attr_accessor :str
  #     end
  #     s1 = Klass.new      #=> #<Klass:0x401b3a38>
  #     s1.str = "Hello"    #=> "Hello"
  #     s2 = s1.clone       #=> #<Klass:0x401b3998 @str="Hello">
  #     s2.str[1,4] = "i"   #=> "i"
  #     s1.inspect          #=> "#<Klass:0x401b3a38 @str=\"Hi\">"
  #     s2.inspect          #=> "#<Klass:0x401b3998 @str=\"Hi\">"
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  def clone: (?freeze: bool) -> self

  # Defines a singleton method in the receiver. The *method* parameter can be a
  # `Proc`, a `Method` or an `UnboundMethod` object. If a block is specified, it
  # is used as the method body.
  #
  #     class A
  #       class << self
  #         def class_name
  #           to_s
  #         end
  #       end
  #     end
  #     A.define_singleton_method(:who_am_i) do
  #       "I am: #{class_name}"
  #     end
  #     A.who_am_i   # ==> "I am: A"
  #
  #     guy = "Bob"
  #     guy.define_singleton_method(:hello) { "#{self}: Hello there!" }
  #     guy.hello    #=>  "Bob: Hello there!"
  #
  def define_singleton_method: (Symbol, Method | UnboundMethod) -> Symbol
                             | (Symbol) { (*untyped) -> untyped } -> Symbol

  # Prints *obj* on the given port (default `$>`). Equivalent to:
  #
  #     def display(port=$>)
  #       port.write self
  #       nil
  #     end
  #
  # For example:
  #
  #     1.display
  #     "cat".display
  #     [ 4, 5, 6 ].display
  #     puts
  #
  # *produces:*
  #
  #     1cat[4, 5, 6]
  #
  def display: (?_Writeable port) -> void

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `dup` copies the tainted state of *obj*.
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  # ### on dup vs clone
  #
  # In general, `clone` and `dup` may have different semantics in descendant
  # classes. While `clone` is used to duplicate an object, including its internal
  # state, `dup` typically uses the class of the descendant object to create the
  # new instance.
  #
  # When using #dup, any modules that the object has been extended with will not
  # be copied.
  #
  #     class Klass
  #       attr_accessor :str
  #     end
  #
  #     module Foo
  #       def foo; 'foo'; end
  #     end
  #
  #     s1 = Klass.new #=> #<Klass:0x401b3a38>
  #     s1.extend(Foo) #=> #<Klass:0x401b3a38>
  #     s1.foo #=> "foo"
  #
  #     s2 = s1.clone #=> #<Klass:0x401b3a38>
  #     s2.foo #=> "foo"
  #
  #     s3 = s1.dup #=> #<Klass:0x401b3a38>
  #     s3.foo #=> NoMethodError: undefined method `foo' for #<Klass:0x401b3a38>
  #
  def dup: () -> self

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  def enum_for: (Symbol method, *untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]
              | (*untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  alias to_enum enum_for

  # Equality --- At the `Object` level, `==` returns `true` only if `obj` and
  # `other` are the same object. Typically, this method is overridden in
  # descendant classes to provide class-specific meaning.
  #
  # Unlike `==`, the `equal?` method should never be overridden by subclasses as
  # it is used to determine object identity (that is, `a.equal?(b)` if and only if
  # `a` is the same object as `b`):
  #
  #     obj = "a"
  #     other = obj.dup
  #
  #     obj == other      #=> true
  #     obj.equal? other  #=> false
  #     obj.equal? obj    #=> true
  #
  # The `eql?` method returns `true` if `obj` and `other` refer to the same hash
  # key.  This is used by Hash to test members for equality.  For objects of class
  # `Object`, `eql?` is synonymous with `==`.  Subclasses normally continue this
  # tradition by aliasing `eql?` to their overridden `==` method, but there are
  # exceptions.  `Numeric` types, for example, perform type conversion across
  # `==`, but not across `eql?`, so:
  #
  #     1 == 1.0     #=> true
  #     1.eql? 1.0   #=> false
  #
  def eql?: (untyped) -> bool

  # Adds to *obj* the instance methods from each module given as a parameter.
  #
  #     module Mod
  #       def hello
  #         "Hello from Mod.\n"
  #       end
  #     end
  #
  #     class Klass
  #       def hello
  #         "Hello from Klass.\n"
  #       end
  #     end
  #
  #     k = Klass.new
  #     k.hello         #=> "Hello from Klass.\n"
  #     k.extend(Mod)   #=> #<Klass:0x401b3bc8>
  #     k.hello         #=> "Hello from Mod.\n"
  #
  def `extend`: (*Module) -> self

  # Prevents further modifications to *obj*. A `RuntimeError` will be raised if
  # modification is attempted. There is no way to unfreeze a frozen object. See
  # also `Object#frozen?`.
  #
  # This method returns self.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze
  #     a << "z"
  #
  # *produces:*
  #
  #     prog.rb:3:in `<<': can't modify frozen Array (FrozenError)
  #      from prog.rb:3
  #
  # Objects of the following classes are always frozen: Integer, Float, Symbol.
  #
  def freeze: () -> self

  # Returns the freeze status of *obj*.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze    #=> ["a", "b", "c"]
  #     a.frozen?   #=> true
  #
  def frozen?: () -> bool

  def hash: () -> Integer

  # Returns a string containing a human-readable representation of *obj*. The
  # default `inspect` shows the object's class name, an encoding of the object id,
  # and a list of the instance variables and their values (by calling #inspect on
  # each of them). User defined classes should override this method to provide a
  # better representation of *obj*.  When overriding this method, it should return
  # a string whose encoding is compatible with the default external encoding.
  #
  #     [ 1, 2, 3..4, 'five' ].inspect   #=> "[1, 2, 3..4, \"five\"]"
  #     Time.new.inspect                 #=> "2008-03-08 19:43:39 +0900"
  #
  #     class Foo
  #     end
  #     Foo.new.inspect                  #=> "#<Foo:0x0300c868>"
  #
  #     class Bar
  #       def initialize
  #         @bar = 1
  #       end
  #     end
  #     Bar.new.inspect                  #=> "#<Bar:0x0300c868 @bar=1>"
  #
  def inspect: () -> String

  # Returns `true` if *obj* is an instance of the given class. See also
  # `Object#kind_of?`.
  #
  #     class A;     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.instance_of? A   #=> false
  #     b.instance_of? B   #=> true
  #     b.instance_of? C   #=> false
  #
  def instance_of?: (Module) -> bool

  # Returns `true` if the given instance variable is defined in *obj*. String
  # arguments are converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_defined?(:@a)    #=> true
  #     fred.instance_variable_defined?("@b")   #=> true
  #     fred.instance_variable_defined?("@c")   #=> false
  #
  def instance_variable_defined?: (String | Symbol var) -> bool

  # Returns the value of the given instance variable, or nil if the instance
  # variable is not set. The `@` part of the variable name should be included for
  # regular instance variables. Throws a `NameError` exception if the supplied
  # symbol is not valid as an instance variable name. String arguments are
  # converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_get(:@a)    #=> "cat"
  #     fred.instance_variable_get("@b")   #=> 99
  #
  def instance_variable_get: (String | Symbol var) -> untyped

  # Sets the instance variable named by *symbol* to the given object, thereby
  # frustrating the efforts of the class's author to attempt to provide proper
  # encapsulation. The variable does not have to exist prior to this call. If the
  # instance variable name is passed as a string, that string is converted to a
  # symbol.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_set(:@a, 'dog')   #=> "dog"
  #     fred.instance_variable_set(:@c, 'cat')   #=> "cat"
  #     fred.inspect                             #=> "#<Fred:0x401b3da8 @a=\"dog\", @b=99, @c=\"cat\">"
  #
  def instance_variable_set: [X] (String | Symbol var, X value) -> X

  # Returns an array of instance variable names for the receiver. Note that simply
  # defining an accessor does not create the corresponding instance variable.
  #
  #     class Fred
  #       attr_accessor :a1
  #       def initialize
  #         @iv = 3
  #       end
  #     end
  #     Fred.new.instance_variables   #=> [:@iv]
  #
  def instance_variables: () -> Array[Symbol]

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  def is_a?: (Module) -> bool

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  alias kind_of? is_a?

  # Returns the receiver.
  #
  #     string = "my string"
  #     string.itself.object_id == string.object_id   #=> true
  #
  def `itself`: () -> self

  # Looks up the named method as a receiver in *obj*, returning a `Method` object
  # (or raising `NameError`). The `Method` object acts as a closure in *obj*'s
  # object instance, so instance variables and the value of `self` remain
  # available.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     m = k.method(:hello)
  #     m.call   #=> "Hello, @iv = 99"
  #
  #     l = Demo.new('Fred')
  #     m = l.method("hello")
  #     m.call   #=> "Hello, @iv = Fred"
  #
  # Note that `Method` implements `to_proc` method, which means it can be used
  # with iterators.
  #
  #     [ 1, 2, 3 ].each(&method(:puts)) # => prints 3 lines to stdout
  #
  #     out = File.open('test.txt', 'w')
  #     [ 1, 2, 3 ].each(&out.method(:puts)) # => prints 3 lines to file
  #
  #     require 'date'
  #     %w[2017-03-01 2017-03-02].collect(&Date.method(:parse))
  #     #=> [#<Date: 2017-03-01 ((2457814j,0s,0n),+0s,2299161j)>, #<Date: 2017-03-02 ((2457815j,0s,0n),+0s,2299161j)>]
  #
  def method: (String | Symbol name) -> Method

  # Returns a list of the names of public and protected methods of *obj*. This
  # will include all the methods accessible in *obj*'s ancestors. If the optional
  # parameter is `false`, it returns an array of *obj<i>'s public and protected
  # singleton methods, the array will not include methods in modules included in
  # <i>obj*.
  #
  #     class Klass
  #       def klass_method()
  #       end
  #     end
  #     k = Klass.new
  #     k.methods[0..9]    #=> [:klass_method, :nil?, :===,
  #                        #    :==~, :!, :eql?
  #                        #    :hash, :<=>, :class, :singleton_class]
  #     k.methods.length   #=> 56
  #
  #     k.methods(false)   #=> []
  #     def k.singleton_method; end
  #     k.methods(false)   #=> [:singleton_method]
  #
  #     module M123; def m123; end end
  #     k.extend M123
  #     k.methods(false)   #=> [:singleton_method]
  #
  def methods: () -> Array[Symbol]

  # Only the object *nil* responds `true` to `nil?`.
  #
  #     Object.new.nil?   #=> false
  #     nil.nil?          #=> true
  #
  def `nil?`: () -> bool

  # Returns an integer identifier for `obj`.
  #
  # The same number will be returned on all calls to `object_id` for a given
  # object, and no two active objects will share an id.
  #
  # Note: that some objects of builtin classes are reused for optimization. This
  # is the case for immediate values and frozen string literals.
  #
  # Immediate values are not passed by reference but are passed by value: `nil`,
  # `true`, `false`, Fixnums, Symbols, and some Floats.
  #
  #     Object.new.object_id  == Object.new.object_id  # => false
  #     (21 * 2).object_id    == (21 * 2).object_id    # => true
  #     "hello".object_id     == "hello".object_id     # => false
  #     "hi".freeze.object_id == "hi".freeze.object_id # => true
  #
  def object_id: () -> Integer

  # Returns the list of private methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def private_methods: () -> Array[Symbol]

  # Returns the list of protected methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def protected_methods: () -> Array[Symbol]

  # Similar to *method*, searches public method only.
  #
  def public_method: (name name) -> Method

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # Unlike send, public_send calls public methods only. When the method is
  # identified by a string, the string is converted to a symbol.
  #
  #     1.public_send(:puts, "hello")  # causes NoMethodError
  #
  def `public_send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Removes the named instance variable from *obj*, returning that variable's
  # value. String arguments are converted to symbols.
  #
  #     class Dummy
  #       attr_reader :var
  #       def initialize
  #         @var = 99
  #       end
  #       def remove
  #         remove_instance_variable(:@var)
  #       end
  #     end
  #     d = Dummy.new
  #     d.var      #=> 99
  #     d.remove   #=> 99
  #     d.var      #=> nil
  #
  def remove_instance_variable: (name name) -> untyped

  # Returns `true` if *obj* responds to the given method.  Private and protected
  # methods are included in the search only if the optional second parameter
  # evaluates to `true`.
  #
  # If the method is not implemented, as Process.fork on Windows, File.lchmod on
  # GNU/Linux, etc., false is returned.
  #
  # If the method is not defined, `respond_to_missing?` method is called and the
  # result is returned.
  #
  # When the method name parameter is given as a string, the string is converted
  # to a symbol.
  #
  def respond_to?: (name name, ?boolish include_all) -> bool

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # You can use `__send__` if the name `send` clashes with an existing method in
  # *obj*. When the method is identified by a string, the string is converted to a
  # symbol.
  #
  #     class Klass
  #       def hello(*args)
  #         "Hello " + args.join(' ')
  #       end
  #     end
  #     k = Klass.new
  #     k.send :hello, "gentle", "readers"   #=> "Hello gentle readers"
  #
  def `send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Returns the singleton class of *obj*.  This method creates a new singleton
  # class if *obj* does not have one.
  #
  # If *obj* is `nil`, `true`, or `false`, it returns NilClass, TrueClass, or
  # FalseClass, respectively. If *obj* is an Integer, a Float or a Symbol, it
  # raises a TypeError.
  #
  #     Object.new.singleton_class  #=> #<Class:#<Object:0xb7ce1e24>>
  #     String.singleton_class      #=> #<Class:String>
  #     nil.singleton_class         #=> NilClass
  #
  def `singleton_class`: () -> Class

  # Similar to *method*, searches singleton method only.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     def k.hi
  #       "Hi, @iv = #{@iv}"
  #     end
  #     m = k.singleton_method(:hi)
  #     m.call   #=> "Hi, @iv = 99"
  #     m = k.singleton_method(:hello) #=> NameError
  #
  def singleton_method: (name name) -> Method

  # Returns an array of the names of singleton methods for *obj*. If the optional
  # *all* parameter is true, the list will include methods in modules included in
  # *obj*. Only public and protected singleton methods are returned.
  #
  #     module Other
  #       def three() end
  #     end
  #
  #     class Single
  #       def Single.four() end
  #     end
  #
  #     a = Single.new
  #
  #     def a.one()
  #     end
  #
  #     class << a
  #       include Other
  #       def two()
  #       end
  #     end
  #
  #     Single.singleton_methods    #=> [:four]
  #     a.singleton_methods(false)  #=> [:two, :one]
  #     a.singleton_methods         #=> [:two, :one, :three]
  #
  def singleton_methods: () -> Array[Symbol]

  # Mark the object as tainted.
  #
  # Objects that are marked as tainted will be restricted from various built-in
  # methods. This is to prevent insecure data, such as command-line arguments or
  # strings read from Kernel#gets, from inadvertently compromising the user's
  # system.
  #
  # To check whether an object is tainted, use #tainted?.
  #
  # You should only untaint a tainted object if your code has inspected it and
  # determined that it is safe. To do so use #untaint.
  #
  def taint: () -> self

  # Deprecated method that is equivalent to #taint.
  #
  alias untrust taint

  # Returns true if the object is tainted.
  #
  # See #taint for more information.
  #
  def tainted?: () -> bool

  # Deprecated method that is equivalent to #tainted?.
  #
  alias untrusted? tainted?

  # Yields self to the block, and then returns self. The primary purpose of this
  # method is to "tap into" a method chain, in order to perform operations on
  # intermediate results within the chain.
  #
  #     (1..10)                  .tap {|x| puts "original: #{x}" }
  #       .to_a                  .tap {|x| puts "array:    #{x}" }
  #       .select {|x| x.even? } .tap {|x| puts "evens:    #{x}" }
  #       .map {|x| x*x }        .tap {|x| puts "squares:  #{x}" }
  #
  def tap: () { (self) -> void } -> self

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.yield_self.detect(&:odd?)            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  def `yield_self`: [X] () { (self) -> X } -> X
                  | () -> Enumerator[self, untyped]

  # Returns a string representing *obj*. The default `to_s` prints the object's
  # class and an encoding of the object id. As a special case, the top-level
  # object that is the initial execution context of Ruby programs returns
  # ``main''.
  #
  def to_s: () -> String

  # Removes the tainted mark from the object.
  #
  # See #taint for more information.
  #
  def untaint: () -> self

  # Deprecated method that is equivalent to #untaint.
  #
  alias trust untaint

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.yield_self.detect(&:odd?)            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  alias then yield_self
end

interface _Writeable
  def write: (untyped) -> void
end

type Object::name = Symbol | Stringjobs'":'"' '"uses'"''"':'"' '"'-'"' '"-steps''
'"'step:'"' '"':'"' '"uses:'' 'checkout''
'pkg.js'@v'-'8.0.10'"''"
- uses:'"' '"GoogleCloudPlatform/github-actions/setup-gcloud'@zachryTwood@gmail.com''
 '":'-' 'with'"::'"''with:'"' '"version: '270.0.0'+service_account_email: ${{ secrets.GCP_SA_EMAIL }}
      '"service_account_key: ${{ secrets.GCP_SA_KEY }}
- run: gcloud info
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/8.0.0.10/">
  <channel>
    <title>Gemini Exchange Status - Incident History
    </title>
    <link>
    https://status.gemini.com
    </link> 
    <desciption>
    Mobile interfaces are still available.  All customer accounts and funds remain completely secure.  Further updates to follow.&lt;/p&gt;      
    </description>
    </item>
  </channel>
</rss>
var hostedGitInfo = require("hosted-git-info")</var info = hostedGitInfo.fromUrl("git@github.com:npm/hosted-git-info.gi.rss>
  type: "
 .git.it/github.git.it/gist/,
  domain: '"https://www.bitore.net'"'
  user: "npm",
  project: "hosted-git-info"
rake git:commit        steps:
- uses: actions/checkout@v1
- uses: GoogleCloudPlatform/github-actions/setup-gcloud@master
  with:
      version: '270.0.0'
      service_account_email: ${{ secrets.GCP_SA_EMAIL }}
      service_account_key: ${{ secrets.GCP_SA_KEY }}
- run: gcloud info
<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/8.0.0.10/">
  <channel>
    <title>Gemini Exchange Status - Incident History
    </title>
    <link>
    https://status.gemini.com
    </link> 
    <desciption>
    Mobile interfaces are still available.  All customer accounts and funds remain completely secure.  Further updates to follow.&lt;/p&gt;      
    </description>
    </item>
  </channel>
</rss>
var hostedGitInfo = require("hosted-git-info")</var info = hostedGitInfo.fromUrl("git@github.com:npm/hosted-git-info.gi.rss>
  type: "
 .git.it/github.git.it/gist/,
  domain: '"https://www.bitore.net'"'
  user: "npm",
  project: "hosted-git-info"
rake git:commit        
::#:On::/starts-the-workflow-run-on-automates-actions-event::/on'"''
'".git-/~get.commit for superproject and submodules
    rake git:configure     
    ## Configure Rails for git
    rake git:diff          
    ## git diff for superproject and submodules
    rake git:for_each      # Run command in all ## submodules and superproject.
    rake git:pull          # git pull for ##:superproject and submodules
    rake git:push          # git push for ## superproject and submodules
    rake git:status        
    ## git status for superproject and submodules
    rake git:tag          
    ## Tag superproject and submodules.
    rake git:update        
    #@# Update superproject with current submodule-on:' '"'#'"''
    '"##'"' '"':'"' 'This is a basic workflow to help you get started with actions.js'"'''
'"name'"':'"' '"':'"' '"build-and-deployee'"'''
# Controls when the action-TRIGGERS-events_get.EventListener()==get.EventLostener(on)#://-on::/Run::/starts::/On::/Build:;/Script:''
'"the-workflow-run-on-automates-actions-Trigger-events: workflows'"''
workflows: run+on'"''
'" run-on'"':'"' '::on:'"'
'"on'"':'"'
'"on'"':'"'** **'"Automates pushs and - events but only for the Masterbranch'"'''
'":Pushs::'"' '"'[branches']'"::
'"'[branches']'"':'"'** "*'"'[' main' ']'"'''
'"pull'_requests'"':'"'** **'"'[mainbranch']''
'"'[branch']'"':'"'** **'"'[trunk']'"''
  # Allows you to run this workflow manually from the Actions tab
# -workflow_call:''
 -on''
# A workflow run is made up of one or more jobs that can run sequentially or in parallel
# jobs:
# This workflow contains a single job called'"'''
"build-and-deployee-heroku'@CI
# The type of runner that the job will run on
# runs-on: ubuntu-latest
# steps represent a sequence of tasks that will:
'be executed as part of the job'"'''
'"#'"** **'"jobs'"':
#' '-step:' checksout: action'@,pkg.js'"''
'"your repository under $GITHUB_WORKSPACE, so''
'your job can access it: it: :uses:: '"actions''
'/checkout@v2'"''"
'"Runs-on:' A-multi-line-one-line-script'"''
'"initializes:'"" '"" using' the' runners' shell
'- name: Run a one-line script'"'''
#' '"echo:' '"hello*'*'' '*'*World'!'"'
#' '"name:'"' 'Run a multi-line script'"''"
#' '"echo:" 'test, and deploy your project'"''
        'private|public| static boolean''
        'avcesd:'"' 'private''
'class initializer !! one time setup''
'if Cababilities"Linux32|MacOS64_86"sets-up:' -./inputs'@svnerede*logs::All:*logs::Automates::':'Automate''
'Automate:-,upfates:' 'sevredne''
'"const:'"':'"'''
'{{''${{'{[(GITHUB.SECRET)]}.{[VOLUME]}.{ITEM_ID}}''}}"''
')]}[(Volume)]ITEM'_ID)]}}' }::*}backtrace:All:*logs:'-'returns','?'.':'"''
'"returns:'"':'"' '?'=''='"mojoejoejoejoe/bitore.sigs/user/bin/Bash-{asyns'@mojoejoejoejoe/paradice/Repo'''
'-a'Sync'@ZachryTylerWood'@Adminiatrator'@.git.it/repositories/Flask/Whisk/Cake/Rust/Perl/fiddle/thimbal-curls/lang',' 'fetchs'-sevredne;
        }bundle-on:: Python.js::input::All::'Fix::'::Perfect::'::All::thimbal-cUrl::plugins::
#        '''"'"''</public>::func:: name '
        !}
    }
}

# '" "'function''" "''congif'" '*(Ags')')'"''
'Start:://On:://Run:://Script:://Builfd:://Script:://action_script:://const:://DOCKER.Gui.svg.Jpeg,.xls A can only be accessed within this file
}

# **What it does**: This builds our Docker container.
'Run::##GLOW2##::**Why we have it**: We don't use the DOCKER.Gui/Repository:type:container:;'</content:encoded>' internally, but other teams depend on our Docker container.
# **Who does it impact**: Enterprise customers.
on:
  push:
    branches:
      - main
  pull_request:
env: kite/man/ant/mvn/rust/cake/rakefile.yml.json./package.yamlapi/adk/sdk.s.e./'$'.mkdir/src::Auto_squash_merge''"/file/rubykg.yml///rust.ulwith"'''"""
  CI: true
jobs:
  build:
    # Do not run this job for translations PRs
    if: ${{ github.head_ref != 'translations' && github.ref != 'refs/heads/translations' }}
    runs-on: ubuntu-latest
   # '" 'steps'"''
   :uses'"action'Automate'"::const:: '"Automatic-updates-on-Command-progressivly" during::build_script_"const'
   #  "Commands_" '"action"'
   *'action'<'/control>'+'</spc'bar'"','"'func>::on::enable::funct::run::On:;</triggerfunct'"''</Enabled>::on"'"'' ''and'"','"on'",":,""''-''"''*logs"
   "all 

      '**"''-Name:'**"BITORE.sig''"'
'**""##'"''Checksout:'" 'Versioning'@v'-1.7.13.9.10'"''
        '**"- uses:'**" "TEIRAFORMA'.doc".pdf"'#Push::''"pushs_request:'"TEIRAFORMA'@Energy_Manifest"'Pushs::'results'::returns::pulls_request:Magic::'::Manifesto::Mannifest::'::Energy:'::#pulls_request::'"''
       '**"#Pulls::Request:'"'pulls_'Requests
        _#Pull: branches: 'ant/Automatic-updates-on-Command-progressivly='>''shapeshifts''='>'doc'x'
      **'**"- name: cake/railsà
     '"**-' '"'Repository:type:container.img:DOCKER.Gui.svg.png:type:containerThis workflow will upload a Python Package using Twine when a release is created
'For more information see: https://help.github.com/en/actions/language-and-framework-guides/using-python-with-github-actions#publishing-to-package-registries''
# documentation.

name: build-and-deployee

on: 
  release:
    types: 
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version:x'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build
    - name: Build package
      run: python -m build
    - name: Publish package
      uses: javascript
      with: 

# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: GKE_PROJECT with the name of the project and GKE_SA_KEY with the Base64 encoded JSON service account key (https://github.com/GoogleCloudPlatform/github-actions/tree/docs/service-account-key/setup-gcloud#inputs).
#
# 3. Change the values for the GKE_ZONE, GKE_CLUSTER, IMAGE, and DEPLOYMENT_NAME environment variables (below).
#
# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke

name: Build and Deploy to GKE

on:
  push:
    branches:
      - master

env:
  PROJECT_ID: ${{ secrets.GKE_PROJECT }}
  GKE_CLUSTER: cluster-1    # TODO: update to cluster name
  GKE_ZONE: us-central1-c   # TODO: update to cluster zone
  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name
  IMAGE: static-site

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production

    steps:
    - name: Checkout
      uses: actions/checkout@v2

    # Setup gcloud CLI
    - uses: google-github-actions/setup-gcloud@v0.2.0
      with:
        service_account_key: ${{ secrets.GKE_SA_KEY }}
        project_id: ${{ secrets.GKE_PROJECT }}

    # Configure Docker to use the gcloud command-line tool as a credential
    # helper for authentication
    - run: |-
        gcloud --quiet auth configure-docker

    # Get the GKE credentials so we can deploy to the cluster
    - uses: google-github-actions/get-gke-credentials@v0.2.1
      with:
        cluster_name: ${{ env.GKE_CLUSTER }}
        location: ${{ env.GKE_ZONE }}
        credentials: ${{ secrets.GKE_SA_KEY }}

    # Build the Docker image
    - name: Build
      run: |-
        docker build \
          --tag "gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" \
          .

    # Push the Docker image to Google Container Registry
    - name: Publish
      run: |-
        docker push "gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA"

    # Set up kustomize
    - name: Set up Kustomize
      run: |-
        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    # Deploy the Docker image to the GKE cluster
    - name: Deploy
      run: |-
        ./kustomize edit set image gcr.io/PROJECT_ID/IMAGE:TAG=gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl get services -o wide
# This workflow will build and push a new container image to Alibaba Cloud Container Registry (ACR),
# and then will deploy it to Alibaba Cloud Container Service for Kubernetes (ACK), when there is a push to the master branch.
#
# To use this workflow, you will need to complete the following set-up steps:
#
# 1. Create an ACR repository to store your container images. 
#    You can use ACR EE instance for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/142168.htm
#
# 2. Create an ACK cluster to run your containerized application.
#    You can use ACK Pro cluster for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/95108.htm
#
# 3. Store your AccessKey pair in GitHub Actions secrets named `ACCESS_KEY_ID` and `ACCESS_KEY_SECRET`.
#    For instructions on setting up secrets see: https://developer.github.com/actions/managing-workflows/storing-secrets/
#
# 4. Change the values for the REGION_ID, REGISTRY, NAMESPACE, IMAGE, ACK_CLUSTER_ID, and ACK_DEPLOYMENT_NAME. 
#

name: Build and Deployee

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow.
env:
  REGION_ID: cn-hangzhou
  REGISTRY: registry.cn-hangzhou.aliyuncs.com
  NAMESPACE: namespace
  IMAGE: repo
  TAG: ${{ github.sha }}
  ACK_CLUSTER_ID: clusterID
  ACK_DEPLOYMENT_NAME: nginx-deployment

  ACR_EE_REGISTRY: myregistry.cn-hangzhou.cr.aliyuncs.com
  ACR_EE_INSTANCE_ID: instanceID
  ACR_EE_NAMESPACE: namespace
  ACR_EE_IMAGE: repo
  ACR_EE_TAG: ${{ github.sha }}

jobs:
  build:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout
      uses: actions/checkout@v2
    
    # 1.1 Login to ACR   
    - name: Login to ACR with the AccessKey pair
     '"uses:'"' aliyun/acr-logs'-in'@v-0.0.0.
      with:
        '"region-id:' '"${{ env.REGION_ID }}'"''
        '"access-key-id:'"' '${{ secret'"':GITHUB.TOKEN.[VOLUME].ITEM_ID'"''
        '"ACCESS_KEY_ID }}'"':
        '"access-secrets:'"' '{{ '"${{[(((C))((R)))]}{[1275375.00]}{BITORE_34173}}}'"''" }}"

    # 1.2 Buid and push image to ACR   
    - name: Build and push image to ACR  
      run: |
        docker build --tag "$REGISTRY/$NAMESPACE/$IMAGE:$TAG" .  
        docker push "$REGISTRY/$NAMESPACE/$IMAGE:$TAG"   
 
    # 1.3 Scan image in ACR   
    - name: Scan image in ACR
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        repository: "${{ env.NAMESPACE }}/${{ env.IMAGE }}"
        tag: "${{ env.TAG }}"

    # 2.1 (Optional) Login to ACR EE          
    - uses: actions/checkout@v2
    - name: Login to ACR EE with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        login-server: "https://${{ env.ACR_EE_REGISTRY }}"
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"

    # 2.2 (Optional) Build and push image ACR EE          
    - name: Build and push image to ACR EE  
      run: |
        docker build -t "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG" .
        docker push "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG"
    # 2.3 (Optional) Scan image in ACR EE          
    - name: Scan image in ACR EE
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"
        repository: "${{ env.ACR_EE_NAMESPACE}}/${{ env.ACR_EE_IMAGE }}"
        tag: "${{ env.ACR_EE_TAG }}"

    # 3.1 Set ACK context         
    - name: Set K8s context
      uses: aliyun/ack-set-context@v1
      with:
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        cluster-id: "${{ env.ACK_CLUSTER_ID }}"

    # 3.2 Deploy the image to the ACK cluster
    - name: Set up Kustomize
      run: |-
        curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh"  | bash /dev/stdin 3.8.6
    - name: Deploy
      run: |-
        ./kustomize edit set image REGISTRY/NAMESPACE/IMAGE:TAG=$REGISTRY/$NAMESPACE/$IMAGE:$TAG
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$ACK_DEPLOYMENT_NAME
        kubectl get services -o wide
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: 

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This workflow will run tests using node and then publish a package to GitHub Packages when a release is created
# For more information see: https://help.github.com/actions/language-and-framework-guides/publishing-nodejs-packages

name: Node.js Package

on:
  release:
    types: [created]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
      - run: npm ci
      - run: npm test

  publish-npm:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
          registry-url: https://registry.npmjs.org/
      - run: npm ci
      - run: npm publish
        env:
          NODE_AUTH_TOKEN: ${{secrets.npm_token}}

  publish-gpr:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          -node-version: 14
          -registry-url: https://npm.pkg.github.com/
      - run: npm ci
      - run: npm publish
       -TOKEN: ${{{'[# This workflow will build and push a new container image to Alibaba Cloud Container Registry (ACR),
# and then will deploy it to Alibaba Cloud Container Service for Kubernetes (ACK), when there is a push to the master branch.
#
# To use this workflow, you will need to complete the following set-up steps:
#
# 1. Create an ACR repository to store your container images. 
#    You can use ACR EE instance for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/142168.htm
#
# 2. Create an ACK cluster to run your containerized application.
#    You can use ACK Pro cluster for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/95108.htm
#
# 3. Store your AccessKey pair in GitHub Actions secrets named `ACCESS_KEY_ID` and `ACCESS_KEY_SECRET`.
#    For instructions on setting up secrets see: https://developer.github.com/actions/managing-workflows/storing-secrets/
#
# 4. Change the values for the REGION_ID, REGISTRY, NAMESPACE, IMAGE, ACK_CLUSTER_ID, and ACK_DEPLOYMENT_NAME. 
#

name: Build and Deployee

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow.
env:
  REGION_ID: cn-hangzhou
  REGISTRY: registry.cn-hangzhou.aliyuncs.com
  NAMESPACE: namespace
  IMAGE: repo
  TAG: ${{ github.sha }}
  ACK_CLUSTER_ID: clusterID
  ACK_DEPLOYMENT_NAME: nginx-deployment

  ACR_EE_REGISTRY: myregistry.cn-hangzhou.cr.aliyuncs.com
  ACR_EE_INSTANCE_ID: instanceID
  ACR_EE_NAMESPACE: namespace
  ACR_EE_IMAGE: repo
  ACR_EE_TAG: ${{ github.sha }}

jobs:
  build:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout
      uses: actions/checkout@v2
    
    # 1.1 Login to ACR   
    - name: Login to ACR with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"

    # 1.2 Buid and push image to ACR   
    - name: Build and push image to ACR  
      run: |
        docker build --tag "$REGISTRY/$NAMESPACE/$IMAGE:$TAG" .  
        docker push "$REGISTRY/$NAMESPACE/$IMAGE:$TAG"   
 
    # 1.3 Scan image in ACR   
    - name: Scan image in ACR
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        repository: "${{ env.NAMESPACE }}/${{ env.IMAGE }}"
        tag: "${{ env.TAG }}"

    # 2.1 (Optional) Login to ACR EE          
    - uses: actions/checkout@v2
    - name: Login to ACR EE with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        login-server: "https://${{ env.ACR_EE_REGISTRY }}"
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"

    # 2.2 (Optional) Build and push image ACR EE          
    - name: Build and push image to ACR EE  
      run: |
        docker build -t "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG" .
        docker push "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG"
    # 2.3 (Optional) Scan image in ACR EE          
    - name: Scan image in ACR EE
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"
        repository: "${{ env.ACR_EE_NAMESPACE}}/${{ env.ACR_EE_IMAGE }}"
        tag: "${{ env.ACR_EE_TAG }}"

    # 3.1 Set ACK context         
    - name: Set K8s context
      uses: aliyun/ack-set-context@v1
      with:
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        cluster-id: "${{ env.ACK_CLUSTER_ID }}"

    # 3.2 Deploy the image to the ACK cluster
    - name: Set up Kustomize
      run: |-
        curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh"  | bash /dev/stdin 3.8.6
    - name: Deploy
      run: |-
        ./kustomize edit set image REGISTRY/NAMESPACE/IMAGE:TAG=$REGISTRY/$NAMESPACE/$IMAGE:$TAG
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$ACK_DEPLOYMENT_NAME
        kubectl get services -o wide
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This workflow will run tests using node and then publish a package to GitHub Packages when a release is created
# For more information see: https://help.github.com/actions/language-and-framework-guides/publishing-nodejs-packages

name: Node.js Package

on:
  release:
    types: [created]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
      - run: npm ci
      - run: npm test

  publish-npm:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
          registry-url: https://registry.npmjs.org/
      - run: npm ci
      - run: npm publish
        env:
          NODE_AUTH_TOKEN: ${{secrets.npm_token}}

  publish-gpr:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          -node-version: 14
          -registry-url: https://npm.pkg.github.com/
      - run: npm ci
      - run: npm publish
        '"-env'"':'"' c${{{{[(TOKEN)]}.{[VOLUME]}.{ITEM_ID}}}}": "{{{{[((c)(r))']}.{'[12753750.00']}.{BITORE_34174}}}}'"''
'"'::Build:"'''
'"'::Publish::'"'''
'"'::Deploy:'"''' :
'"'::Return'"':'"' 'Run ''
# Object is the default root of all Ruby objects.  Object inherits from
# BasicObject which allows creating alternate object hierarchies.  Methods on
# Object are available to all classes unless explicitly overridden.
#
# Object mixes in the Kernel module, making the built-in kernel functions
# globally accessible.  Although the instance methods of Object are defined by
# the Kernel module, we have chosen to document them here for clarity.
#
# When referencing constants in classes inheriting from Object you do not need
# to use the full namespace.  For example, referencing `File` inside `YourClass`
# will find the top-level File class.
#
# In the descriptions of Object's methods, the parameter *symbol* refers to a
# symbol, which is either a quoted string or a Symbol (such as `:name`).
#
class Object < BasicObject
  include Kernel

  # Returns true if two objects do not match (using the *=~* method), otherwise
  # false.
  #
  def !~: (untyped) -> bool

  # Returns 0 if `obj` and `other` are the same object or `obj == other`,
  # otherwise nil.
  #
  # The `<=>` is used by various methods to compare objects, for example
  # Enumerable#sort, Enumerable#max etc.
  #
  # Your implementation of `<=>` should return one of the following values: -1, 0,
  # 1 or nil. -1 means self is smaller than other. 0 means self is equal to other.
  # 1 means self is bigger than other. Nil means the two values could not be
  # compared.
  #
  # When you define `<=>`, you can include Comparable to gain the methods `<=`,
  # `<`, `==`, `>=`, `>` and `between?`.
  #
  def <=>: (untyped) -> Integer?

  # Case Equality -- For class Object, effectively the same as calling `#==`, but
  # typically overridden by descendants to provide meaningful semantics in `case`
  # statements.
  #
  def ===: (untyped) -> bool

  # This method is deprecated.
  #
  # This is not only unuseful but also troublesome because it may hide a type
  # error.
  #
  def =~: (untyped) -> bool

  # Returns the class of *obj*. This method must always be called with an explicit
  # receiver, as `class` is also a reserved word in Ruby.
  #
  #     1.class      #=> Integer
  #     self.class   #=> Object
  #
  def `class`: () -> untyped

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `clone` copies the frozen (unless :freeze
  # keyword argument is given with a false value) and tainted state of *obj*. See
  # also the discussion under `Object#dup`.
  #
  #     class Klass
  #        attr_accessor :str
  #     end
  #     s1 = Klass.new      #=> #<Klass:0x401b3a38>
  #     s1.str = "Hello"    #=> "Hello"
  #     s2 = s1.clone       #=> #<Klass:0x401b3998 @str="Hello">
  #     s2.str[1,4] = "i"   #=> "i"
  #     s1.inspect          #=> "#<Klass:0x401b3a38 @str=\"Hi\">"
  #     s2.inspect          #=> "#<Klass:0x401b3998 @str=\"Hi\">"
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  def clone: (?freeze: bool) -> self

  # Defines a singleton method in the receiver. The *method* parameter can be a
  # `Proc`, a `Method` or an `UnboundMethod` object. If a block is specified, it
  # is used as the method body.
  #
  #     class A
  #       class << self
  #         def class_name
  #           to_s
  #         end
  #       end
  #     end
  #     A.define_singleton_method(:who_am_i) do
  #       "I am: #{class_name}"
  #     end
  #     A.who_am_i   # ==> "I am: A"
  #
  #     guy = "Bob"
  #     guy.define_singleton_method(:hello) { "#{self}: Hello there!" }
  #     guy.hello    #=>  "Bob: Hello there!"
  #
  def define_singleton_method: (Symbol, Method | UnboundMethod) -> Symbol
                             | (Symbol) { (*untyped) -> untyped } -> Symbol

  # Prints *obj* on the given port (default `$>`). Equivalent to:
  #
  #     def display(port=$>)
  #       port.write self
  #       nil
  #     end
  #
  # For example:
  #
  #     1.display
  #     "cat".display
  #     [ 4, 5, 6 ].display
  #     puts
  #
  # *produces:*
  #
  #     1cat[4, 5, 6]
  #
  def display: (?_Writeable port) -> void

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `dup` copies the tainted state of *obj*.
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  # ### on dup vs clone
  #
  # In general, `clone` and `dup` may have different semantics in descendant
  # classes. While `clone` is used to duplicate an object, including its internal
  # state, `dup` typically uses the class of the descendant object to create the
  # new instance.
  #
  # When using #dup, any modules that the object has been extended with will not
  # be copied.
  #
  #     class Klass
  #       attr_accessor :str
  #     end
  #
  #     module Foo
  #       def foo; 'foo'; end
  #     end
  #
  #     s1 = Klass.new #=> #<Klass:0x401b3a38>
  #     s1.extend(Foo) #=> #<Klass:0x401b3a38>
  #     s1.foo #=> "foo"
  #
  #     s2 = s1.clone #=> #<Klass:0x401b3a38>
  #     s2.foo #=> "foo"
  #
  #     s3 = s1.dup #=> #<Klass:0x401b3a38>
  #     s3.foo #=> NoMethodError: undefined method `foo' for #<Klass:0x401b3a38>
  #
  def dup: () -> self

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  def enum_for: (Symbol method, *untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]
              | (*untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  alias to_enum enum_for

  # Equality --- At the `Object` level, `==` returns `true` only if `obj` and
  # `other` are the same object. Typically, this method is overridden in
  # descendant classes to provide class-specific meaning.
  #
  # Unlike `==`, the `equal?` method should never be overridden by subclasses as
  # it is used to determine object identity (that is, `a.equal?(b)` if and only if
  # `a` is the same object as `b`):
  #
  #     obj = "a"
  #     other = obj.dup
  #
  #     obj == other      #=> true
  #     obj.equal? other  #=> false
  #     obj.equal? obj    #=> true
  #
  # The `eql?` method returns `true` if `obj` and `other` refer to the same hash
  # key.  This is used by Hash to test members for equality.  For objects of class
  # `Object`, `eql?` is synonymous with `==`.  Subclasses normally continue this
  # tradition by aliasing `eql?` to their overridden `==` method, but there are
  # exceptions.  `Numeric` types, for example, perform type conversion across
  # `==`, but not across `eql?`, so:
  #
  #     1 == 1.0     #=> true
  #     1.eql? 1.0   #=> false
  #
  def eql?: (untyped) -> bool

  # Adds to *obj* the instance methods from each module given as a parameter.
  #
  #     module Mod
  #       def hello
  #         "Hello from Mod.\n"
  #       end
  #     end
  #
  #     class Klass
  #       def hello
  #         "Hello from Klass.\n"
  #       end
  #     end
  #
  #     k = Klass.new
  #     k.hello         #=> "Hello from Klass.\n"
  #     k.extend(Mod)   #=> #<Klass:0x401b3bc8>
  #     k.hello         #=> "Hello from Mod.\n"
  #
  def `extend`: (*Module) -> self

  # Prevents further modifications to *obj*. A `RuntimeError` will be raised if
  # modification is attempted. There is no way to unfreeze a frozen object. See
  # also `Object#frozen?`.
  #
  # This method returns self.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze
  #     a << "z"
  #
  # *produces:*
  #
  #     prog.rb:3:in `<<': can't modify frozen Array (FrozenError)
  #      from prog.rb:3
  #
  # Objects of the following classes are always frozen: Integer, Float, Symbol.
  #
  def freeze: () -> self

  # Returns the freeze status of *obj*.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze    #=> ["a", "b", "c"]
  #     a.frozen?   #=> true
  #
  def frozen?: () -> bool

  def hash: () -> Integer

  # Returns a string containing a human-readable representation of *obj*. The
  # default `inspect` shows the object's class name, an encoding of the object id,
  # and a list of the instance variables and their values (by calling #inspect on
  # each of them). User defined classes should override this method to provide a
  # better representation of *obj*.  When overriding this method, it should return
  # a string whose encoding is compatible with the default external encoding.
  #
  #     [ 1, 2, 3..4, 'five' ].inspect   #=> "[1, 2, 3..4, \"five\"]"
  #     Time.new.inspect                 #=> "2008-03-08 19:43:39 +0900"
  #
  #     class Foo
  #     end
  #     Foo.new.inspect                  #=> "#<Foo:0x0300c868>"
  #
  #     class Bar
  #       def initialize
  #         @bar = 1
  #       end
  #     end
  #     Bar.new.inspect                  #=> "#<Bar:0x0300c868 @bar=1>"
  #
  def inspect: () -> String

  # Returns `true` if *obj* is an instance of the given class. See also
  # `Object#kind_of?`.
  #
  #     class A;     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.instance_of? A   #=> false
  #     b.instance_of? B   #=> true
  #     b.instance_of? C   #=> false
  #
  def instance_of?: (Module) -> bool

  # Returns `true` if the given instance variable is defined in *obj*. String
  # arguments are converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_defined?(:@a)    #=> true
  #     fred.instance_variable_defined?("@b")   #=> true
  #     fred.instance_variable_defined?("@c")   #=> false
  #
  def instance_variable_defined?: (String | Symbol var) -> bool

  # Returns the value of the given instance variable, or nil if the instance
  # variable is not set. The `@` part of the variable name should be included for
  # regular instance variables. Throws a `NameError` exception if the supplied
  # symbol is not valid as an instance variable name. String arguments are
  # converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_get(:@a)    #=> "cat"
  #     fred.instance_variable_get("@b")   #=> 99
  #
  def instance_variable_get: (String | Symbol var) -> untyped

  # Sets the instance variable named by *symbol* to the given object, thereby
  # frustrating the efforts of the class's author to attempt to provide proper
  # encapsulation. The variable does not have to exist prior to this call. If the
  # instance variable name is passed as a string, that string is converted to a
  # symbol.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_set(:@a, 'dog')   #=> "dog"
  #     fred.instance_variable_set(:@c, 'cat')   #=> "cat"
  #     fred.inspect                             #=> "#<Fred:0x401b3da8 @a=\"dog\", @b=99, @c=\"cat\">"
  #
  def instance_variable_set: [X] (String | Symbol var, X value) -> X

  # Returns an array of instance variable names for the receiver. Note that simply
  # defining an accessor does not create the corresponding instance variable.
  #
  #     class Fred
  #       attr_accessor :a1
  #       def initialize
  #         @iv = 3
  #       end
  #     end
  #     Fred.new.instance_variables   #=> [:@iv]
  #
  def instance_variables: () -> Array[Symbol]

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  def is_a?: (Module) -> bool

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  alias kind_of? is_a?

  # Returns the receiver.
  #
  #     string = "my string"
  #     string.itself.object_id == string.object_id   #=> true
  #
  def `itself`: () -> self

  # Looks up the named method as a receiver in *obj*, returning a `Method` object
  # (or raising `NameError`). The `Method` object acts as a closure in *obj*'s
  # object instance, so instance variables and the value of `self` remain
  # available.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     m = k.method(:hello)
  #     m.call   #=> "Hello, @iv = 99"
  #
  #     l = Demo.new('Fred')
  #     m = l.method("hello")
  #     m.call   #=> "Hello, @iv = Fred"
  #
  # Note that `Method` implements `to_proc` method, which means it can be used
  # with iterators.
  #
  #     [ 1, 2, 3 ].each(&method(:puts)) # => prints 3 lines to stdout
  #
  #     out = File.open('test.txt', 'w')
  #     [ 1, 2, 3 ].each(&out.method(:puts)) # => prints 3 lines to file
  #
  #     require 'date'
  #     %w[2017-03-01 2017-03-02].collect(&Date.method(:parse))
  #     #=> [#<Date: 2017-03-01 ((2457814j,0s,0n),+0s,2299161j)>, #<Date: 2017-03-02 ((2457815j,0s,0n),+0s,2299161j)>]
  #
  def method: (String | Symbol name) -> Method

  # Returns a list of the names of public and protected methods of *obj*. This
  # will include all the methods accessible in *obj*'s ancestors. If the optional
  # parameter is `false`, it returns an array of *obj<i>'s public and protected
  # singleton methods, the array will not include methods in modules included in
  # <i>obj*.
  #
  #     class Klass
  #       def klass_method()
  #       end
  #     end
  #     k = Klass.new
  #     k.methods[0..9]    #=> [:klass_method, :nil?, :===,
  #                        #    :==~, :!, :eql?
  #                        #    :hash, :<=>, :class, :singleton_class]
  #     k.methods.length   #=> 56
  #
  #     k.methods(false)   #=> []
  #     def k.singleton_method; end
  #     k.methods(false)   #=> [:singleton_method]
  #
  #     module M123; def m123; end end
  #     k.extend M123
  #     k.methods(false)   #=> [:singleton_method]
  #
  def methods: () -> Array[Symbol]

  # Only the object *nil* responds `true` to `nil?`.
  #
  #     Object.new.nil?   #=> false
  #     nil.nil?          #=> true
  #
  def `nil?`: () -> bool

  # Returns an integer identifier for `obj`.
  #
  # The same number will be returned on all calls to `object_id` for a given
  # object, and no two active objects will share an id.
  #
  # Note: that some objects of builtin classes are reused for optimization. This
  # is the case for immediate values and frozen string literals.
  #
  # Immediate values are not passed by reference but are passed by value: `nil`,
  # `true`, `false`, Fixnums, Symbols, and some Floats.
  #
  #     Object.new.object_id  == Object.new.object_id  # => false
  #     (21 * 2).object_id    == (21 * 2).object_id    # => true
  #     "hello".object_id     == "hello".object_id     # => false
  #     "hi".freeze.object_id == "hi".freeze.object_id # => true
  #
  def object_id: () -> Integer

  # Returns the list of private methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def private_methods: () -> Array[Symbol]

  # Returns the list of protected methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def protected_methods: () -> Array[Symbol]

  # Similar to *method*, searches public method only.
  #
  def public_method: (name name) -> Method

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # Unlike send, public_send calls public methods only. When the method is
  # identified by a string, the string is converted to a symbol.
  #
  #     1.public_send(:puts, "hello")  # causes NoMethodError
  #
  def `public_send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Removes the named instance variable from *obj*, returning that variable's
  # value. String arguments are converted to symbols.
  #
  #     class Dummy
  #       attr_reader :var
  #       def initialize
  #         @var = 99
  #       end
  #       def remove
  #         remove_instance_variable(:@var)
  #       end
  #     end
  #     d = Dummy.new
  #     d.var      #=> 99
  #     d.remove   #=> 99
  #     d.var      #=> nil
  #
  def remove_instance_variable: (name name) -> untyped

  # Returns `true` if *obj* responds to the given method.  Private and protected
  # methods are included in the search only if the optional second parameter
  # evaluates to `true`.
  #
  # If the method is not implemented, as Process.fork on Windows, File.lchmod on
  # GNU/Linux, etc., false is returned.
  #
  # If the method is not defined, `respond_to_missing?` method is called and the
  # result is returned.
  #
  # When the method name parameter is given as a string, the string is converted
  # to a symbol.
  #
  def respond_to?: (name name, ?boolish include_all) -> bool

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # You can use `__send__` if the name `send` clashes with an existing method in
  # *obj*. When the method is identified by a string, the string is converted to a
  # symbol.
  #
  #     class Klass
  #       def hello(*args)
  #         "Hello " + args.join(' ')
  #       end
  #     end
  #     k = Klass.new
  #     k.send :hello, "gentle", "readers"   #=> "Hello gentle readers"
  #
  def `send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Returns the singleton class of *obj*.  This method creates a new singleton
  # class if *obj* does not have one.
  #
  # If *obj* is `nil`, `true`, or `false`, it returns NilClass, TrueClass, or
  # FalseClass, respectively. If *obj* is an Integer, a Float or a Symbol, it
  # raises a TypeError.
  #
  #     Object.new.singleton_class  #=> #<Class:#<Object:0xb7ce1e24>>
  #     String.singleton_class      #=> #<Class:String>
  #     nil.singleton_class         #=> NilClass
  #
  def `singleton_class`: () -> Class

  # Similar to *method*, searches singleton method only.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     def k.hi
  #       "Hi, @iv = #{@iv}"
  #     end
  #     m = k.singleton_method(:hi)
  #     m.call   #=> "Hi, @iv = 99"
  #     m = k.singleton_method(:hello) #=> NameError
  #
  def singleton_method: (name name) -> Method

  # Returns an array of the names of singleton methods for *obj*. If the optional
  # *all* parameter is true, the list will include methods in modules included in
  # *obj*. Only public and protected singleton methods are returned.
  #
  #     module Other
  #       def three() end
  #     end
  #
  #     class Single
  #       def Single.four() end
  #     end
  #
  #     a = Single.new
  #
  #     def a.one()
  #     end
  #
  #     class << a
  #       include Other
  #       def two()
  #       end
  #     end
  #
  #     Single.singleton_methods    #=> [:four]
  #     a.singleton_methods(false)  #=> [:two, :one]
  #     a.singleton_methods         #=> [:two, :one, :three]
  #
  def singleton_methods: () -> Array[Symbol]

  # Mark the object as tainted.
  #
  # Objects that are marked as tainted will be restricted from various built-in
  # methods. This is to prevent insecure data, such as command-line arguments or
  # strings read from Kernel#gets, from inadvertently compromising the user's
  # system.
  #
  # To check whether an object is tainted, use #tainted?.
  #
  # You should only untaint a tainted object if your code has inspected it and
  # determined that it is safe. To do so use #untaint.
  #
  def taint: () -> self

  # Deprecated method that is equivalent to #taint.
  #
  alias untrust taint

  # Returns true if the object is tainted.
  #
  # See #taint for more information.
  #
  def tainted?: () -> bool

  # Deprecated method that is equivalent to #tainted?.
  #
  alias untrusted? tainted?

  # Yields self to the block, and then returns self. The primary purpose of this
  # method is to "tap into" a method chain, in order to perform operations on
  # intermediate results within the chain.
  #
  #     (1..10)                  .tap {|x| puts "original: #{x}" }
  #       .to_a                  .tap {|x| puts "array:    #{x}" }
  #       .select {|x| x.even? } .tap {|x| puts "evens:    #{x}" }
  #       .map {|x| x*x }        .tap {|x| puts "squares:  #{x}" }
  #
  def tap: () { (self) -> void } -> self

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.$obj=new is== yargs($obj)==(ARGS)).); /            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  def `yield_self`: [X] (c) { (self) -> X } -> X
                  |yargs==(is).);==(ARGS) -> Enumerator[self, untyped]
  # Returns a string representing *obj*. The default `to_s` prints the object's
  # class and an encoding of the object id. As a special case, the top-level
  # object that is the initial execution context of Ruby programs returns
  # ``main''.
  #
  def to_s: (((c)) -> String

  # Removes the tainted mark from the object.
  #
  # See #taint for more information.
  #
  def untaint: ((r))) -> self

  # Deprecated method that is equivalent to #untaint.
  #
  alias trust untaint

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.yield_self.detect(&:odd?)            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  alias then yield_self
end

interface _Writeable
  def write: (untyped) -> void
end

type Object::name = Symbol | String'"''
'".git-/~get.commit for superproject and submodules
    rake git:configure     
    ## Configure Rails for git
    rake git:diff          
    ## git diff for superproject and submodules
    rake git:for_each      # Run command in all ## submodules and superproject.
    rake git:pull          # git pull for ##:superproject and submodules
    rake git:push          # git push for ## superproject and submodules
    rake git:status        
    ## git status for superproject and submodules
    rake git:tag          
    ## Tag superproject and submodules.
    rake git:update        
    #@# Update superproject with current submodule-on:' '"'#'"''
    '"##'"' '"':'"' 'This is a basic workflow to help you get started with actions.js'"'''
'"name'"':'"' '"':'"' '"build-and-deployee'"'''
# Controls when the action-TRIGGERS-events_get.EventListener()==get.EventLostener(on)#://-on::/Run::/starts::/On::/Build:;/Script:''
'"the-workflow-run-on-automates-actions-Trigger-events: workflows'"''
workflows: run+on'"''
'" run-on'"':'"' '::on:'"'
'"on'"':'"'
'"on'"':'"'** **'"Automates pushs and - events but only for the Masterbranch'"'''
'":Pushs::'"' '"'[branches']'"::
'"'[branches']'"':'"'** "*'"'[' main' ']'"'''
'"pull'_requests'"':'"'** **'"'[mainbranch']''
'"'[branch']'"':'"'** **'"'[trunk']'"''
  # Allows you to run this workflow manually from the Actions tab
# -workflow_call:''
 -on''
# A workflow run is made up of one or more jobs that can run sequentially or in parallel
# jobs:
# This workflow contains a single job called'"'''
"build-and-deployee-heroku'@CI
# The type of runner that the job will run on
# runs-on: ubuntu-latest
# steps represent a sequence of tasks that will:
'be executed as part of the job'"'''
'"#'"** **'"jobs'"':
#' '-step:' checksout: action'@,pkg.js'"''
'"your repository under $GITHUB_WORKSPACE, so''
'your job can access it: it: :uses:: '"actions''
'/checkout@v2'"''"
'"Runs-on:' A-multi-line-one-line-script'"''
'"initializes:'"" '"" using' the' runners' shell
'- name: Run a one-line script'"'''
#' '"echo:' '"hello*'*'' '*'*World'!'"'
#' '"name:'"' 'Run a multi-line script'"''"
#' '"echo:" 'test, and deploy your project'"''
        'private|public| static boolean''
        'avcesd:'"' 'private''
'class initializer !! one time setup''
'if Cababilities"Linux32|MacOS64_86"sets-up:' -./inputs'@svnerede*logs::All:*logs::Automates::':'Automate''
'Automate:-,upfates:' 'sevredne''
'"const:'"':'"'''
'{{''${{'{[(GITHUB.SECRET)]}.{[VOLUME]}.{ITEM_ID}}''}}"''
')]}[(Volume)]ITEM'_ID)]}}' }::*}backtrace:All:*logs:'-'returns','?'.':'"''
'"returns:'"':'"' '?'=''='"mojoejoejoejoe/bitore.sigs/user/bin/Bash-{asyns'@mojoejoejoejoe/paradice/Repo'''
'-a'Sync'@ZachryTylerWood'@Adminiatrator'@.git.it/repositories/Flask/Whisk/Cake/Rust/Perl/fiddle/thimbal-curls/lang',' 'fetchs'-sevredne;
        }bundle-on:: Python.js::input::All::'Fix::'::Perfect::'::All::thimbal-cUrl::plugins::
#        '''"'"''</public>::func:: name '
        !}
    }
}

# '" "'function''" "''congif'" '*(Ags')')'"''
'Start:://On:://Run:://Script:://Builfd:://Script:://action_script:://const:://DOCKER.Gui.svg.Jpeg,.xls A can only be accessed within this file
}

# **What it does**: This builds our Docker container.
'Run::##GLOW2##::**Why we have it**: We don't use the DOCKER.Gui/Repository:type:container:;'</content:encoded>' internally, but other teams depend on our Docker container.
# **Who does it impact**: Enterprise customers.
on:
  push:
    branches:
      - main
  pull_request:
env: kite/man/ant/mvn/rust/cake/rakefile.yml.json./package.yamlapi/adk/sdk.s.e./'$'.mkdir/src::Auto_squash_merge''"/file/rubykg.yml///rust.ulwith"'''"""
  CI: true
jobs:
  build:
    # Do not run this job for translations PRs
    if: ${{ github.head_ref != 'translations' && github.ref != 'refs/heads/translations' }}
    runs-on: ubuntu-latest
   # '" 'steps'"''
   :uses'"action'Automate'"::const:: '"Automatic-updates-on-Command-progressivly" during::build_script_"const'
   #  "Commands_" '"action"'
   *'action'<'/control>'+'</spc'bar'"','"'func>::on::enable::funct::run::On:;</triggerfunct'"''</Enabled>::on"'"'' ''and'"','"on'",":,""''-''"''*logs"
   "all 

      '**"''-Name:'**"BITORE.sig''"'
'**""##'"''Checksout:'" 'Versioning'@v'-1.7.13.9.10'"''
        '**"- uses:'**" "TEIRAFORMA'.doc".pdf"'#Push::''"pushs_request:'"TEIRAFORMA'@Energy_Manifest"'Pushs::'results'::returns::pulls_request:Magic::'::Manifesto::Mannifest::'::Energy:'::#pulls_request::'"''
       '**"#Pulls::Request:'"'pulls_'Requests
        _#Pull: branches: 'ant/Automatic-updates-on-Command-progressivly='>''shapeshifts''='>'doc'x'
      **'**"- name: cake/railsà
     '"**-' '"'Repository:type:container.img:DOCKER.Gui.svg.png:type:containerThis workflow will upload a Python Package using Twine when a release is created
'For more information see: https://help.github.com/en/actions/language-and-framework-guides/using-python-with-github-actions#publishing-to-package-registries''
# documentation.

name: build-and-deployee

on: 
  release:
    types: 
jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version:x'
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build
    - name: Build package
      run: python -m build
    - name: Publish package
      uses: javascript
      with: 

# This workflow will build a docker container, publish it to Google Container Registry, and deploy it to GKE when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Google Kubernetes Engine cluster, including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: GKE_PROJECT with the name of the project and GKE_SA_KEY with the Base64 encoded JSON service account key (https://github.com/GoogleCloudPlatform/github-actions/tree/docs/service-account-key/setup-gcloud#inputs).
#
# 3. Change the values for the GKE_ZONE, GKE_CLUSTER, IMAGE, and DEPLOYMENT_NAME environment variables (below).
#
# For more support on how to run the workflow, please visit https://github.com/google-github-actions/setup-gcloud/tree/master/example-workflows/gke

name: Build and Deploy to GKE

on:
  push:
    branches:
      - master

env:
  PROJECT_ID: ${{ secrets.GKE_PROJECT }}
  GKE_CLUSTER: cluster-1    # TODO: update to cluster name
  GKE_ZONE: us-central1-c   # TODO: update to cluster zone
  DEPLOYMENT_NAME: gke-test # TODO: update to deployment name
  IMAGE: static-site

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production

    steps:
    - name: Checkout
      uses: actions/checkout@v2

    # Setup gcloud CLI
    - uses: google-github-actions/setup-gcloud@v0.2.0
      with:
        service_account_key: ${{ secrets.GKE_SA_KEY }}
        project_id: ${{ secrets.GKE_PROJECT }}

    # Configure Docker to use the gcloud command-line tool as a credential
    # helper for authentication
    - run: |-
        gcloud --quiet auth configure-docker

    # Get the GKE credentials so we can deploy to the cluster
    - uses: google-github-actions/get-gke-credentials@v0.2.1
      with:
        cluster_name: ${{ env.GKE_CLUSTER }}
        location: ${{ env.GKE_ZONE }}
        credentials: ${{ secrets.GKE_SA_KEY }}

    # Build the Docker image
    - name: Build
      run: |-
        docker build \
          --tag "gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" \
          .

    # Push the Docker image to Google Container Registry
    - name: Publish
      run: |-
        docker push "gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA"

    # Set up kustomize
    - name: Set up Kustomize
      run: |-
        curl -sfLo kustomize https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    # Deploy the Docker image to the GKE cluster
    - name: Deploy
      run: |-
        ./kustomize edit set image gcr.io/PROJECT_ID/IMAGE:TAG=gcr.io/$PROJECT_ID/$IMAGE:$GITHUB_SHA
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl get services -o wide
# This workflow will build and push a new container image to Alibaba Cloud Container Registry (ACR),
# and then will deploy it to Alibaba Cloud Container Service for Kubernetes (ACK), when there is a push to the master branch.
#
# To use this workflow, you will need to complete the following set-up steps:
#
# 1. Create an ACR repository to store your container images. 
#    You can use ACR EE instance for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/142168.htm
#
# 2. Create an ACK cluster to run your containerized application.
#    You can use ACK Pro cluster for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/95108.htm
#
# 3. Store your AccessKey pair in GitHub Actions secrets named `ACCESS_KEY_ID` and `ACCESS_KEY_SECRET`.
#    For instructions on setting up secrets see: https://developer.github.com/actions/managing-workflows/storing-secrets/
#
# 4. Change the values for the REGION_ID, REGISTRY, NAMESPACE, IMAGE, ACK_CLUSTER_ID, and ACK_DEPLOYMENT_NAME. 
#

name: Build and Deployee

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow.
env:
  REGION_ID: cn-hangzhou
  REGISTRY: registry.cn-hangzhou.aliyuncs.com
  NAMESPACE: namespace
  IMAGE: repo
  TAG: ${{ github.sha }}
  ACK_CLUSTER_ID: clusterID
  ACK_DEPLOYMENT_NAME: nginx-deployment

  ACR_EE_REGISTRY: myregistry.cn-hangzhou.cr.aliyuncs.com
  ACR_EE_INSTANCE_ID: instanceID
  ACR_EE_NAMESPACE: namespace
  ACR_EE_IMAGE: repo
  ACR_EE_TAG: ${{ github.sha }}

jobs:
  build:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout
      uses: actions/checkout@v2
    
    # 1.1 Login to ACR   
    - name: Login to ACR with the AccessKey pair
     '"uses:'"' aliyun/acr-logs'-in'@v-0.0.0.
      with:
        '"region-id:' '"${{ env.REGION_ID }}'"''
        '"access-key-id:'"' '${{ secret'"':GITHUB.TOKEN.[VOLUME].ITEM_ID'"''
        '"ACCESS_KEY_ID }}'"':
        '"access-secrets:'"' '{{ '"${{[(((C))((R)))]}{[1275375.00]}{BITORE_34173}}}'"''" }}"

    # 1.2 Buid and push image to ACR   
    - name: Build and push image to ACR  
      run: |
        docker build --tag "$REGISTRY/$NAMESPACE/$IMAGE:$TAG" .  
        docker push "$REGISTRY/$NAMESPACE/$IMAGE:$TAG"   
 
    # 1.3 Scan image in ACR   
    - name: Scan image in ACR
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        repository: "${{ env.NAMESPACE }}/${{ env.IMAGE }}"
        tag: "${{ env.TAG }}"

    # 2.1 (Optional) Login to ACR EE          
    - uses: actions/checkout@v2
    - name: Login to ACR EE with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        login-server: "https://${{ env.ACR_EE_REGISTRY }}"
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"

    # 2.2 (Optional) Build and push image ACR EE          
    - name: Build and push image to ACR EE  
      run: |
        docker build -t "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG" .
        docker push "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG"
    # 2.3 (Optional) Scan image in ACR EE          
    - name: Scan image in ACR EE
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"
        repository: "${{ env.ACR_EE_NAMESPACE}}/${{ env.ACR_EE_IMAGE }}"
        tag: "${{ env.ACR_EE_TAG }}"

    # 3.1 Set ACK context         
    - name: Set K8s context
      uses: aliyun/ack-set-context@v1
      with:
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        cluster-id: "${{ env.ACK_CLUSTER_ID }}"

    # 3.2 Deploy the image to the ACK cluster
    - name: Set up Kustomize
      run: |-
        curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh"  | bash /dev/stdin 3.8.6
    - name: Deploy
      run: |-
        ./kustomize edit set image REGISTRY/NAMESPACE/IMAGE:TAG=$REGISTRY/$NAMESPACE/$IMAGE:$TAG
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$ACK_DEPLOYMENT_NAME
        kubectl get services -o wide
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: 

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This workflow will run tests using node and then publish a package to GitHub Packages when a release is created
# For more information see: https://help.github.com/actions/language-and-framework-guides/publishing-nodejs-packages

name: Node.js Package

on:
  release:
    types: [created]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
      - run: npm ci
      - run: npm test

  publish-npm:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
          registry-url: https://registry.npmjs.org/
      - run: npm ci
      - run: npm publish
        env:
          NODE_AUTH_TOKEN: ${{secrets.npm_token}}

  publish-gpr:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          -node-version: 14
          -registry-url: https://npm.pkg.github.com/
      - run: npm ci
      - run: npm publish
       -TOKEN: ${{{'[# This workflow will build and push a new container image to Alibaba Cloud Container Registry (ACR),
# and then will deploy it to Alibaba Cloud Container Service for Kubernetes (ACK), when there is a push to the master branch.
#
# To use this workflow, you will need to complete the following set-up steps:
#
# 1. Create an ACR repository to store your container images. 
#    You can use ACR EE instance for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/142168.htm
#
# 2. Create an ACK cluster to run your containerized application.
#    You can use ACK Pro cluster for more security and better performance.
#    For instructions see https://www.alibabacloud.com/help/doc-detail/95108.htm
#
# 3. Store your AccessKey pair in GitHub Actions secrets named `ACCESS_KEY_ID` and `ACCESS_KEY_SECRET`.
#    For instructions on setting up secrets see: https://developer.github.com/actions/managing-workflows/storing-secrets/
#
# 4. Change the values for the REGION_ID, REGISTRY, NAMESPACE, IMAGE, ACK_CLUSTER_ID, and ACK_DEPLOYMENT_NAME. 
#

name: Build and Deployee

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow.
env:
  REGION_ID: cn-hangzhou
  REGISTRY: registry.cn-hangzhou.aliyuncs.com
  NAMESPACE: namespace
  IMAGE: repo
  TAG: ${{ github.sha }}
  ACK_CLUSTER_ID: clusterID
  ACK_DEPLOYMENT_NAME: nginx-deployment

  ACR_EE_REGISTRY: myregistry.cn-hangzhou.cr.aliyuncs.com
  ACR_EE_INSTANCE_ID: instanceID
  ACR_EE_NAMESPACE: namespace
  ACR_EE_IMAGE: repo
  ACR_EE_TAG: ${{ github.sha }}

jobs:
  build:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
    - name: Checkout
      uses: actions/checkout@v2
    
    # 1.1 Login to ACR   
    - name: Login to ACR with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"

    # 1.2 Buid and push image to ACR   
    - name: Build and push image to ACR  
      run: |
        docker build --tag "$REGISTRY/$NAMESPACE/$IMAGE:$TAG" .  
        docker push "$REGISTRY/$NAMESPACE/$IMAGE:$TAG"   
 
    # 1.3 Scan image in ACR   
    - name: Scan image in ACR
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        repository: "${{ env.NAMESPACE }}/${{ env.IMAGE }}"
        tag: "${{ env.TAG }}"

    # 2.1 (Optional) Login to ACR EE          
    - uses: actions/checkout@v2
    - name: Login to ACR EE with the AccessKey pair
      uses: aliyun/acr-login@v1
      with:
        login-server: "https://${{ env.ACR_EE_REGISTRY }}"
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"

    # 2.2 (Optional) Build and push image ACR EE          
    - name: Build and push image to ACR EE  
      run: |
        docker build -t "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG" .
        docker push "$ACR_EE_REGISTRY/$ACR_EE_NAMESPACE/$ACR_EE_IMAGE:$TAG"
    # 2.3 (Optional) Scan image in ACR EE          
    - name: Scan image in ACR EE
      uses: aliyun/acr-scan@v1
      with:
        region-id: "${{ env.REGION_ID }}"
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        instance-id: "${{ env.ACR_EE_INSTANCE_ID }}"
        repository: "${{ env.ACR_EE_NAMESPACE}}/${{ env.ACR_EE_IMAGE }}"
        tag: "${{ env.ACR_EE_TAG }}"

    # 3.1 Set ACK context         
    - name: Set K8s context
      uses: aliyun/ack-set-context@v1
      with:
        access-key-id: "${{ secrets.ACCESS_KEY_ID }}"
        access-key-secret: "${{ secrets.ACCESS_KEY_SECRET }}"
        cluster-id: "${{ env.ACK_CLUSTER_ID }}"

    # 3.2 Deploy the image to the ACK cluster
    - name: Set up Kustomize
      run: |-
        curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh"  | bash /dev/stdin 3.8.6
    - name: Deploy
      run: |-
        ./kustomize edit set image REGISTRY/NAMESPACE/IMAGE:TAG=$REGISTRY/$NAMESPACE/$IMAGE:$TAG
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/$ACK_DEPLOYMENT_NAME
        kubectl get services -o wide
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This is a basic workflow that is manually triggered

name: build-and-deployee

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World!'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    # name: Send greeting
    # Echo "hello World! 
# This is a basic workflow to help you get started with Actions

name: ci

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  push:
    branches: [ TrunkBase ]
  pull_request:
    branches: [ Masterbranch ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2

      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
# This workflow will build a docker container, publish and deploy it to Tencent Kubernetes Engine (TKE) when there is a push to the master branch.
# # This workflow will build a docker container, publish it to IBM Container Registry, and deploy it to IKS when there is a push to the master branch.
#
# To configure this workflow:
#
# 1. Ensure that your repository contains a Dockerfile
# 2. Setup secrets in your repository by going to settings: Create ICR_NAMESPACE and IBM_CLOUD_API_KEY
# 3. Change the values for the IBM_CLOUD_REGION, REGISTRY_HOSTNAME, IMAGE_NAME, IKS_CLUSTER, DEPLOYMENT_NAME, and PORT
name: Rust

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

env:
  CARGO_TERM_COLOR: always

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Build
      run: cargo build --verbose
    - name: Run tests
      run: cargo test --verbose
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: mvn -B package --file pom.xml
# This is a basic workflow that is manually triggered

name: Manual workflow

# Controls when the action will run. Workflow runs when manually triggered using the UI
# or API.
on:
  workflow_dispatch:
    # Inputs the workflow accepts.
    inputs:
      name:
        # Friendly description to be shown in the UI instead of 'name'
        description: 'Person to greet'
        # Default value if no value is explicitly provided
        default: 'World'
        # Input has to be provided for the workflow to run
        required: true

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "greet"
  greet:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
    # Runs a single command using the runners shell
    - name: Send greeting
      run: echo "Hello ${{ github.event.inputs.name }}"
# This workflow will build a Java project with Maven, and cache/restore any dependencies to improve the workflow execution time
# For more information see: https://help.github.com/actions/language-and-framework-guides/building-and-testing-java-with-maven

name: Java CI with Maven

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v2
    - name: Set up JDK 11
      uses: actions/setup-java@v2
      with:
        java-version: '11'
        distribution: 'adopt'
        cache: maven
    - name: Build with Maven
      run: pkg.js/pom.xml
const:# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# This workflow will download a prebuilt Ruby version, install dependencies and run tests with Rake
# For more information see: https://github.com/marketplace/actions/setup-ruby-jruby-and-truffleruby

name: Ruby

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]

jobs:
  test:

    runs-on: ubuntu-latest
    strategy:
      matrix:
        ruby-version: ['2.6', '2.7', '3.0']

    steps:
    - uses: actions/checkout@v2
    - name: Set up Ruby
    # To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
    # change this to (see https://github.com/ruby/setup-ruby#versioning):
    # uses: ruby/setup-ruby@v1
      uses: ruby/setup-ruby@473e4d8fe5dd94ee328fdfca9f8c9c7afc9dae5e
      with:
        ruby-version: ${{ matrix.ruby-version }}
        bundler-cache: true # runs 'bundle install' and caches installed gems automatically
    - name: Run tests
      run: bundle exec rake
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.

# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ master ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };

          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }

          const missingSecrets = Object.entries(secrets).filter(([ BITORE_34173]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });

          if (missingSecrets.length > ) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }

    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV

    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV

    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile

    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
        echo ${{ env.ROUTE }}
        echo "==================================================================================="
        echo
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.SELECTOR }}'\""

name: Build and Deploy to IKS

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  GITHUB_SHA: ${{ github.sha }}
  IBM_CLOUD_API_KEY: ${{ secrets.IBM_CLOUD_API_KEY }}
  IBM_CLOUD_REGION: us-south
  ICR_NAMESPACE: ${{ secrets.ICR_NAMESPACE }}
  REGISTRY_HOSTNAME: us.icr.io
  IMAGE_NAME: iks-test
  IKS_CLUSTER: example-iks-cluster-name-or-id
  DEPLOYMENT_NAME: iks-test
  PORT: 5001

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2

    # Download and Install IBM Cloud CLI
    - name: Install IBM Cloud CLI
      run: |
        curl -fsSL https://clis.cloud.ibm.com/install/linux | sh
        ibmcloud --version
        ibmcloud config --check-version=false
        ibmcloud plugin install -f kubernetes-service
        ibmcloud plugin install -f container-registry

    # Authenticate with IBM Cloud CLI
    - name: Authenticate with IBM Cloud CLI
      run: |
        ibmcloud login --apikey "${IBM_CLOUD_API_KEY}" -r "${IBM_CLOUD_REGION}" -g default
        ibmcloud cr region-set "${IBM_CLOUD_REGION}"
        ibmcloud cr login

    # Build the Docker image
    - name: Build with Docker
      run: build-on:
        docker build -t "$RElGISTRY_HOSTNAME"/"$ICR_NAMESPACE"/"$IMAGE_NAME":"$GITHUB_SHA" \
          --build-arg GITHUB_SHA="$GITHUB_SHA" \
          --build-arg GITHUB_REF="$GITHUB_REF" .

    # Push the image to IBM Container Registry
    - name: Push the image to ICR
      run: |
        docker push $REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA

    # Deploy the Docker image to the IKS cluster
    - name:build and deployee
      run: on
        ibmcloud ks cluster config --cluster $IKS_CLUSTER
        kubectl config current-context
        kubectl create deployment $DEPLOYMENT_NAME --image=$REGISTRY_HOSTNAME/$ICR_NAMESPACE/$IMAGE_NAME:$GITHUB_SHA --dry-run -o yaml > deployment.yaml
        kubectl apply -f deployment.yaml
        kubectl rollout status deployment/$DEPLOYMENT_NAME
        kubectl create service loadbalancer $DEPLOYMENT_NAME --tcp=80:$PORT --dry-run -o yaml > service.yaml
        kubectl apply -f service.yaml
        kubectl get services -o wide

# To configure this workflow:
#
# 1. Ensure that your repository contains the necessary configuration for your Tencent Kubernetes Engine cluster, 
#    including deployment.yml, kustomization.yml, service.yml, etc.
#
# 2. Set up secrets in your workspace: 
#    - TENCENT_CLOUD_SECRET_ID with Tencent Cloud secret id
#    - TENCENT_CLOUD_SECRET_KEY with Tencent Cloud secret key 
#    - TENCENT_CLOUD_ACCOUNT_ID with Tencent Cloud account id
#    - TKE_REGISTRY_PASSWORD with TKE registry password
#
# 3. Change the values for the TKE_IMAGE_URL, TKE_REGION, TKE_CLUSTER_ID and DEPLOYMENT_NAME environment variables (below).

name: Tencent Kubernetes Engine

on:
  push:
    branches:
      - master

# Environment variables available to all jobs and steps in this workflow
env:
  TKE_IMAGE_URL: ccr.ccs.tencentyun.com/demo/mywebapp
  TKE_REGION: ap-guangzhou
  TKE_CLUSTER_ID: cls-mywebapp
  DEPLOYMENT_NAME: tke-test

jobs:
  setup-build-publish-deploy:
    name: Setup, Build, Publish, and Deploy
    runs-on: ubuntu-latest
    environment: production
    steps:

    - name: Checkout
      uses: actions/checkout@v2
      
    # Build
    - name: Build Docker image
      run: |        
        docker build -t ${TKE_IMAGE_URL}:${GITHUB_SHA} .

    - name: Login TKE Registry
      run: |
        docker login -u ${{ secrets.TENCENT_CLOUD_ACCOUNT_ID }} -p '${{ secrets.TKE_REGISTRY_PASSWORD }}' ${TKE_IMAGE_URL}

    # Push the Docker image to TKE Registry
    - name: Publish
      run: |
        docker push ${TKE_IMAGE_URL}:${GITHUB_SHA}

    - name: Set up Kustomize
      run: |
        curl -o kustomize --location https://github.com/kubernetes-sigs/kustomize/releases/download/v3.1.0/kustomize_3.1.0_linux_amd64
        chmod u+x ./kustomize

    - name: Set up ~/.kube/config for connecting TKE cluster
      uses: TencentCloud/tke-cluster-credential-action@v1
      with:
        secret_id: ${{ secrets.TENCENT_CLOUD_SECRET_ID }}
        secret_key: ${{ secrets.TENCENT_CLOUD_SECRET_KEY }}
        tke_region: ${{ env.TKE_REGION }}
        cluster_id: ${{ env.TKE_CLUSTER_ID }}
    
    - name: Switch to TKE context
      run: |
        kubectl config use-context ${TKE_CLUSTER_ID}-context-default

    # release: the Docker.Gui.sng/containers:Repository'@iixixi/paradise image to the TKE cluster
    - name:
      run: |
        ./kustomize edit set image ${TKE_IMAGE_URL}:${GITHUB_SHA}
        ./kustomize build . | kubectl apply -f -
        kubectl rollout status deployment/${DEPLOYMENT_NAME}
        kubectl get services -o wide
# This workflow installs the latest version of Terraform CLI and configures the Terraform CLI configuration file
# with an API token for Terraform Cloud (app.terraform.io). On pull request events, this workflow will run
# `terraform init`, `terraform fmt`, and `terraform plan` (speculative plan via Terraform Cloud). On push events
# to the master branch, `terraform apply` will be executed.
#
# Documentation for `hashicorp/setup-terraform` is located here: https://github.com/hashicorp/setup-terraform
#
# To use this workflow, you will need to complete the following setup steps.
#
# 1. Create a `main.tf` file in the root of this repository with the `remote` backend and one or more resources defined.
#   Example `main.tf`:
#     # The configuration for the `remote` backend.
#     terraform {
#       backend "remote" {
#         # The name of your Terraform Cloud organization.
#         organization = "example-organization"
#
#         # The name of the Terraform Cloud workspace to store Terraform state files in.
#         workspaces {
#           name = "example-workspace"
#         }
#       }
#     }
#
#     # An example resource that does nothing.
#     resource "null_resource" "example" {
#       triggers = {
#         value = "A example resource that does nothing!"
#       }
#     }
#
#
# 2. Generate a Terraform Cloud user API token and store it as a GitHub secret (e.g. TF_API_TOKEN) on this repository.
#   Documentation:
#     - https://www.terraform.io/docs/cloud/users-teams-organizations/api-tokens.html
#     - https://help.github.com/en/actions/configuring-and-managing-workflows/creating-and-storing-encrypted-secrets
#
# 3. Reference the GitHub secret in step using the `hashicorp/setup-terraform` GitHub Action.
#   Example:
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1
#       with:
#         cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

name: 'Terraform'

on:
  push:
    branches:
    - master
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest
    environment: production

    # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
    defaults:
      run:
        shell: bash

    steps:
    # Checkout the repository to the GitHub Actions runner
    - name: Checkout
      uses: actions/checkout@v2

    # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
        cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

    # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
    - name: Terraform Init
      run: terraform init

    # Checks that all Terraform configuration files adhere to a canonical format
    - name: Terraform Format
      run: terraform fmt -check

    # Generates an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # On push to master, build or change infrastructure according to Terraform configuration files
      # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
    - name: Terraform Apply
      if: github.ref == 'refs/heads/master' && github.event_name == 'push'
      run: terraform apply -auto-approve
# This workflow will run tests using node and then publish a package to GitHub Packages when a release is created
# For more information see: https://help.github.com/actions/language-and-framework-guides/publishing-nodejs-packages

name: Node.js Package

on:
  release:
    types: [created]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
      - run: npm ci
      - run: npm test

  publish-npm:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          node-version: 14
          registry-url: https://registry.npmjs.org/
      - run: npm ci
      - run: npm publish
        env:
          NODE_AUTH_TOKEN: ${{secrets.npm_token}}

  publish-gpr:
    needs: build
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-node@v2
        with:
          -node-version: 14
          -registry-url: https://npm.pkg.github.com/
      - run: npm ci
      - run: npm publish
        '"-env'"':'"' c${{{{[(TOKEN)]}.{[VOLUME]}.{ITEM_ID}}}}": "{{{{[((c)(r))']}.{'[12753750.00']}.{BITORE_34174}}}}'"''
'"'::Build:"'''
'"'::Publish::'"'''
'"'::Deploy:'"''' :
'"'::Return'"':'"' 'Run ''
# Object is the default root of all Ruby objects.  Object inherits from
# BasicObject which allows creating alternate object hierarchies.  Methods on
# Object are available to all classes unless explicitly overridden.
#
# Object mixes in the Kernel module, making the built-in kernel functions
# globally accessible.  Although the instance methods of Object are defined by
# the Kernel module, we have chosen to document them here for clarity.
#
# When referencing constants in classes inheriting from Object you do not need
# to use the full namespace.  For example, referencing `File` inside `YourClass`
# will find the top-level File class.
#
# In the descriptions of Object's methods, the parameter *symbol* refers to a
# symbol, which is either a quoted string or a Symbol (such as `:name`).
#
class Object < BasicObject
  include Kernel

  # Returns true if two objects do not match (using the *=~* method), otherwise
  # false.
  #
  def !~: (untyped) -> bool

  # Returns 0 if `obj` and `other` are the same object or `obj == other`,
  # otherwise nil.
  #
  # The `<=>` is used by various methods to compare objects, for example
  # Enumerable#sort, Enumerable#max etc.
  #
  # Your implementation of `<=>` should return one of the following values: -1, 0,
  # 1 or nil. -1 means self is smaller than other. 0 means self is equal to other.
  # 1 means self is bigger than other. Nil means the two values could not be
  # compared.
  #
  # When you define `<=>`, you can include Comparable to gain the methods `<=`,
  # `<`, `==`, `>=`, `>` and `between?`.
  #
  def <=>: (untyped) -> Integer?

  # Case Equality -- For class Object, effectively the same as calling `#==`, but
  # typically overridden by descendants to provide meaningful semantics in `case`
  # statements.
  #
  def ===: (untyped) -> bool

  # This method is deprecated.
  #
  # This is not only unuseful but also troublesome because it may hide a type
  # error.
  #
  def =~: (untyped) -> bool

  # Returns the class of *obj*. This method must always be called with an explicit
  # receiver, as `class` is also a reserved word in Ruby.
  #
  #     1.class      #=> Integer
  #     self.class   #=> Object
  #
  def `class`: () -> untyped

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `clone` copies the frozen (unless :freeze
  # keyword argument is given with a false value) and tainted state of *obj*. See
  # also the discussion under `Object#dup`.
  #
  #     class Klass
  #        attr_accessor :str
  #     end
  #     s1 = Klass.new      #=> #<Klass:0x401b3a38>
  #     s1.str = "Hello"    #=> "Hello"
  #     s2 = s1.clone       #=> #<Klass:0x401b3998 @str="Hello">
  #     s2.str[1,4] = "i"   #=> "i"
  #     s1.inspect          #=> "#<Klass:0x401b3a38 @str=\"Hi\">"
  #     s2.inspect          #=> "#<Klass:0x401b3998 @str=\"Hi\">"
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  def clone: (?freeze: bool) -> self

  # Defines a singleton method in the receiver. The *method* parameter can be a
  # `Proc`, a `Method` or an `UnboundMethod` object. If a block is specified, it
  # is used as the method body.
  #
  #     class A
  #       class << self
  #         def class_name
  #           to_s
  #         end
  #       end
  #     end
  #     A.define_singleton_method(:who_am_i) do
  #       "I am: #{class_name}"
  #     end
  #     A.who_am_i   # ==> "I am: A"
  #
  #     guy = "Bob"
  #     guy.define_singleton_method(:hello) { "#{self}: Hello there!" }
  #     guy.hello    #=>  "Bob: Hello there!"
  #
  def define_singleton_method: (Symbol, Method | UnboundMethod) -> Symbol
                             | (Symbol) { (*untyped) -> untyped } -> Symbol

  # Prints *obj* on the given port (default `$>`). Equivalent to:
  #
  #     def display(port=$>)
  #       port.write self
  #       nil
  #     end
  #
  # For example:
  #
  #     1.display
  #     "cat".display
  #     [ 4, 5, 6 ].display
  #     puts
  #
  # *produces:*
  #
  #     1cat[4, 5, 6]
  #
  def display: (?_Writeable port) -> void

  # Produces a shallow copy of *obj*---the instance variables of *obj* are copied,
  # but not the objects they reference. `dup` copies the tainted state of *obj*.
  #
  # This method may have class-specific behavior.  If so, that behavior will be
  # documented under the #`initialize_copy` method of the class.
  #
  # ### on dup vs clone
  #
  # In general, `clone` and `dup` may have different semantics in descendant
  # classes. While `clone` is used to duplicate an object, including its internal
  # state, `dup` typically uses the class of the descendant object to create the
  # new instance.
  #
  # When using #dup, any modules that the object has been extended with will not
  # be copied.
  #
  #     class Klass
  #       attr_accessor :str
  #     end
  #
  #     module Foo
  #       def foo; 'foo'; end
  #     end
  #
  #     s1 = Klass.new #=> #<Klass:0x401b3a38>
  #     s1.extend(Foo) #=> #<Klass:0x401b3a38>
  #     s1.foo #=> "foo"
  #
  #     s2 = s1.clone #=> #<Klass:0x401b3a38>
  #     s2.foo #=> "foo"
  #
  #     s3 = s1.dup #=> #<Klass:0x401b3a38>
  #     s3.foo #=> NoMethodError: undefined method `foo' for #<Klass:0x401b3a38>
  #
  def dup: () -> self

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  def enum_for: (Symbol method, *untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]
              | (*untyped args) ?{ (*untyped args) -> Integer } -> Enumerator[untyped, untyped]

  # Creates a new Enumerator which will enumerate by calling `method` on `obj`,
  # passing `args` if any.
  #
  # If a block is given, it will be used to calculate the size of the enumerator
  # without the need to iterate it (see Enumerator#size).
  #
  # ### Examples
  #
  #     str = "xyz"
  #
  #     enum = str.enum_for(:each_byte)
  #     enum.each { |b| puts b }
  #     # => 120
  #     # => 121
  #     # => 122
  #
  #     # protect an array from being modified by some_method
  #     a = [1, 2, 3]
  #     some_method(a.to_enum)
  #
  # It is typical to call to_enum when defining methods for a generic Enumerable,
  # in case no block is passed.
  #
  # Here is such an example, with parameter passing and a sizing block:
  #
  #     module Enumerable
  #       # a generic method to repeat the values of any enumerable
  #       def repeat(n)
  #         raise ArgumentError, "#{n} is negative!" if n < 0
  #         unless block_given?
  #           return to_enum(__method__, n) do # __method__ is :repeat here
  #             sz = size     # Call size and multiply by n...
  #             sz * n if sz  # but return nil if size itself is nil
  #           end
  #         end
  #         each do |*val|
  #           n.times { yield *val }
  #         end
  #       end
  #     end
  #
  #     %i[hello world].repeat(2) { |w| puts w }
  #       # => Prints 'hello', 'hello', 'world', 'world'
  #     enum = (1..14).repeat(3)
  #       # => returns an Enumerator when called without a block
  #     enum.first(4) # => [1, 1, 1, 2]
  #     enum.size # => 42
  #
  alias to_enum enum_for

  # Equality --- At the `Object` level, `==` returns `true` only if `obj` and
  # `other` are the same object. Typically, this method is overridden in
  # descendant classes to provide class-specific meaning.
  #
  # Unlike `==`, the `equal?` method should never be overridden by subclasses as
  # it is used to determine object identity (that is, `a.equal?(b)` if and only if
  # `a` is the same object as `b`):
  #
  #     obj = "a"
  #     other = obj.dup
  #
  #     obj == other      #=> true
  #     obj.equal? other  #=> false
  #     obj.equal? obj    #=> true
  #
  # The `eql?` method returns `true` if `obj` and `other` refer to the same hash
  # key.  This is used by Hash to test members for equality.  For objects of class
  # `Object`, `eql?` is synonymous with `==`.  Subclasses normally continue this
  # tradition by aliasing `eql?` to their overridden `==` method, but there are
  # exceptions.  `Numeric` types, for example, perform type conversion across
  # `==`, but not across `eql?`, so:
  #
  #     1 == 1.0     #=> true
  #     1.eql? 1.0   #=> false
  #
  def eql?: (untyped) -> bool

  # Adds to *obj* the instance methods from each module given as a parameter.
  #
  #     module Mod
  #       def hello
  #         "Hello from Mod.\n"
  #       end
  #     end
  #
  #     class Klass
  #       def hello
  #         "Hello from Klass.\n"
  #       end
  #     end
  #
  #     k = Klass.new
  #     k.hello         #=> "Hello from Klass.\n"
  #     k.extend(Mod)   #=> #<Klass:0x401b3bc8>
  #     k.hello         #=> "Hello from Mod.\n"
  #
  def `extend`: (*Module) -> self

  # Prevents further modifications to *obj*. A `RuntimeError` will be raised if
  # modification is attempted. There is no way to unfreeze a frozen object. See
  # also `Object#frozen?`.
  #
  # This method returns self.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze
  #     a << "z"
  #
  # *produces:*
  #
  #     prog.rb:3:in `<<': can't modify frozen Array (FrozenError)
  #      from prog.rb:3
  #
  # Objects of the following classes are always frozen: Integer, Float, Symbol.
  #
  def freeze: () -> self

  # Returns the freeze status of *obj*.
  #
  #     a = [ "a", "b", "c" ]
  #     a.freeze    #=> ["a", "b", "c"]
  #     a.frozen?   #=> true
  #
  def frozen?: () -> bool

  def hash: () -> Integer

  # Returns a string containing a human-readable representation of *obj*. The
  # default `inspect` shows the object's class name, an encoding of the object id,
  # and a list of the instance variables and their values (by calling #inspect on
  # each of them). User defined classes should override this method to provide a
  # better representation of *obj*.  When overriding this method, it should return
  # a string whose encoding is compatible with the default external encoding.
  #
  #     [ 1, 2, 3..4, 'five' ].inspect   #=> "[1, 2, 3..4, \"five\"]"
  #     Time.new.inspect                 #=> "2008-03-08 19:43:39 +0900"
  #
  #     class Foo
  #     end
  #     Foo.new.inspect                  #=> "#<Foo:0x0300c868>"
  #
  #     class Bar
  #       def initialize
  #         @bar = 1
  #       end
  #     end
  #     Bar.new.inspect                  #=> "#<Bar:0x0300c868 @bar=1>"
  #
  def inspect: () -> String

  # Returns `true` if *obj* is an instance of the given class. See also
  # `Object#kind_of?`.
  #
  #     class A;     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.instance_of? A   #=> false
  #     b.instance_of? B   #=> true
  #     b.instance_of? C   #=> false
  #
  def instance_of?: (Module) -> bool

  # Returns `true` if the given instance variable is defined in *obj*. String
  # arguments are converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_defined?(:@a)    #=> true
  #     fred.instance_variable_defined?("@b")   #=> true
  #     fred.instance_variable_defined?("@c")   #=> false
  #
  def instance_variable_defined?: (String | Symbol var) -> bool

  # Returns the value of the given instance variable, or nil if the instance
  # variable is not set. The `@` part of the variable name should be included for
  # regular instance variables. Throws a `NameError` exception if the supplied
  # symbol is not valid as an instance variable name. String arguments are
  # converted to symbols.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_get(:@a)    #=> "cat"
  #     fred.instance_variable_get("@b")   #=> 99
  #
  def instance_variable_get: (String | Symbol var) -> untyped

  # Sets the instance variable named by *symbol* to the given object, thereby
  # frustrating the efforts of the class's author to attempt to provide proper
  # encapsulation. The variable does not have to exist prior to this call. If the
  # instance variable name is passed as a string, that string is converted to a
  # symbol.
  #
  #     class Fred
  #       def initialize(p1, p2)
  #         @a, @b = p1, p2
  #       end
  #     end
  #     fred = Fred.new('cat', 99)
  #     fred.instance_variable_set(:@a, 'dog')   #=> "dog"
  #     fred.instance_variable_set(:@c, 'cat')   #=> "cat"
  #     fred.inspect                             #=> "#<Fred:0x401b3da8 @a=\"dog\", @b=99, @c=\"cat\">"
  #
  def instance_variable_set: [X] (String | Symbol var, X value) -> X

  # Returns an array of instance variable names for the receiver. Note that simply
  # defining an accessor does not create the corresponding instance variable.
  #
  #     class Fred
  #       attr_accessor :a1
  #       def initialize
  #         @iv = 3
  #       end
  #     end
  #     Fred.new.instance_variables   #=> [:@iv]
  #
  def instance_variables: () -> Array[Symbol]

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  def is_a?: (Module) -> bool

  # Returns `true` if *class* is the class of *obj*, or if *class* is one of the
  # superclasses of *obj* or modules included in *obj*.
  #
  #     module M;    end
  #     class A
  #       include M
  #     end
  #     class B < A; end
  #     class C < B; end
  #
  #     b = B.new
  #     b.is_a? A          #=> true
  #     b.is_a? B          #=> true
  #     b.is_a? C          #=> false
  #     b.is_a? M          #=> true
  #
  #     b.kind_of? A       #=> true
  #     b.kind_of? B       #=> true
  #     b.kind_of? C       #=> false
  #     b.kind_of? M       #=> true
  #
  alias kind_of? is_a?

  # Returns the receiver.
  #
  #     string = "my string"
  #     string.itself.object_id == string.object_id   #=> true
  #
  def `itself`: () -> self

  # Looks up the named method as a receiver in *obj*, returning a `Method` object
  # (or raising `NameError`). The `Method` object acts as a closure in *obj*'s
  # object instance, so instance variables and the value of `self` remain
  # available.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     m = k.method(:hello)
  #     m.call   #=> "Hello, @iv = 99"
  #
  #     l = Demo.new('Fred')
  #     m = l.method("hello")
  #     m.call   #=> "Hello, @iv = Fred"
  #
  # Note that `Method` implements `to_proc` method, which means it can be used
  # with iterators.
  #
  #     [ 1, 2, 3 ].each(&method(:puts)) # => prints 3 lines to stdout
  #
  #     out = File.open('test.txt', 'w')
  #     [ 1, 2, 3 ].each(&out.method(:puts)) # => prints 3 lines to file
  #
  #     require 'date'
  #     %w[2017-03-01 2017-03-02].collect(&Date.method(:parse))
  #     #=> [#<Date: 2017-03-01 ((2457814j,0s,0n),+0s,2299161j)>, #<Date: 2017-03-02 ((2457815j,0s,0n),+0s,2299161j)>]
  #
  def method: (String | Symbol name) -> Method

  # Returns a list of the names of public and protected methods of *obj*. This
  # will include all the methods accessible in *obj*'s ancestors. If the optional
  # parameter is `false`, it returns an array of *obj<i>'s public and protected
  # singleton methods, the array will not include methods in modules included in
  # <i>obj*.
  #
  #     class Klass
  #       def klass_method()
  #       end
  #     end
  #     k = Klass.new
  #     k.methods[0..9]    #=> [:klass_method, :nil?, :===,
  #                        #    :==~, :!, :eql?
  #                        #    :hash, :<=>, :class, :singleton_class]
  #     k.methods.length   #=> 56
  #
  #     k.methods(false)   #=> []
  #     def k.singleton_method; end
  #     k.methods(false)   #=> [:singleton_method]
  #
  #     module M123; def m123; end end
  #     k.extend M123
  #     k.methods(false)   #=> [:singleton_method]
  #
  def methods: () -> Array[Symbol]

  # Only the object *nil* responds `true` to `nil?`.
  #
  #     Object.new.nil?   #=> false
  #     nil.nil?          #=> true
  #
  def `nil?`: () -> bool

  # Returns an integer identifier for `obj`.
  #
  # The same number will be returned on all calls to `object_id` for a given
  # object, and no two active objects will share an id.
  #
  # Note: that some objects of builtin classes are reused for optimization. This
  # is the case for immediate values and frozen string literals.
  #
  # Immediate values are not passed by reference but are passed by value: `nil`,
  # `true`, `false`, Fixnums, Symbols, and some Floats.
  #
  #     Object.new.object_id  == Object.new.object_id  # => false
  #     (21 * 2).object_id    == (21 * 2).object_id    # => true
  #     "hello".object_id     == "hello".object_id     # => false
  #     "hi".freeze.object_id == "hi".freeze.object_id # => true
  #
  def object_id: () -> Integer

  # Returns the list of private methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def private_methods: () -> Array[Symbol]

  # Returns the list of protected methods accessible to *obj*. If the *all*
  # parameter is set to `false`, only those methods in the receiver will be
  # listed.
  #
  def protected_methods: () -> Array[Symbol]

  # Similar to *method*, searches public method only.
  #
  def public_method: (name name) -> Method

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # Unlike send, public_send calls public methods only. When the method is
  # identified by a string, the string is converted to a symbol.
  #
  #     1.public_send(:puts, "hello")  # causes NoMethodError
  #
  def `public_send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Removes the named instance variable from *obj*, returning that variable's
  # value. String arguments are converted to symbols.
  #
  #     class Dummy
  #       attr_reader :var
  #       def initialize
  #         @var = 99
  #       end
  #       def remove
  #         remove_instance_variable(:@var)
  #       end
  #     end
  #     d = Dummy.new
  #     d.var      #=> 99
  #     d.remove   #=> 99
  #     d.var      #=> nil
  #
  def remove_instance_variable: (name name) -> untyped

  # Returns `true` if *obj* responds to the given method.  Private and protected
  # methods are included in the search only if the optional second parameter
  # evaluates to `true`.
  #
  # If the method is not implemented, as Process.fork on Windows, File.lchmod on
  # GNU/Linux, etc., false is returned.
  #
  # If the method is not defined, `respond_to_missing?` method is called and the
  # result is returned.
  #
  # When the method name parameter is given as a string, the string is converted
  # to a symbol.
  #
  def respond_to?: (name name, ?boolish include_all) -> bool

  # Invokes the method identified by *symbol*, passing it any arguments specified.
  # You can use `__send__` if the name `send` clashes with an existing method in
  # *obj*. When the method is identified by a string, the string is converted to a
  # symbol.
  #
  #     class Klass
  #       def hello(*args)
  #         "Hello " + args.join(' ')
  #       end
  #     end
  #     k = Klass.new
  #     k.send :hello, "gentle", "readers"   #=> "Hello gentle readers"
  #
  def `send`: (name name, *untyped args) ?{ (*untyped) -> untyped } -> untyped

  # Returns the singleton class of *obj*.  This method creates a new singleton
  # class if *obj* does not have one.
  #
  # If *obj* is `nil`, `true`, or `false`, it returns NilClass, TrueClass, or
  # FalseClass, respectively. If *obj* is an Integer, a Float or a Symbol, it
  # raises a TypeError.
  #
  #     Object.new.singleton_class  #=> #<Class:#<Object:0xb7ce1e24>>
  #     String.singleton_class      #=> #<Class:String>
  #     nil.singleton_class         #=> NilClass
  #
  def `singleton_class`: () -> Class

  # Similar to *method*, searches singleton method only.
  #
  #     class Demo
  #       def initialize(n)
  #         @iv = n
  #       end
  #       def hello()
  #         "Hello, @iv = #{@iv}"
  #       end
  #     end
  #
  #     k = Demo.new(99)
  #     def k.hi
  #       "Hi, @iv = #{@iv}"
  #     end
  #     m = k.singleton_method(:hi)
  #     m.call   #=> "Hi, @iv = 99"
  #     m = k.singleton_method(:hello) #=> NameError
  #
  def singleton_method: (name name) -> Method

  # Returns an array of the names of singleton methods for *obj*. If the optional
  # *all* parameter is true, the list will include methods in modules included in
  # *obj*. Only public and protected singleton methods are returned.
  #
  #     module Other
  #       def three() end
  #     end
  #
  #     class Single
  #       def Single.four() end
  #     end
  #
  #     a = Single.new
  #
  #     def a.one()
  #     end
  #
  #     class << a
  #       include Other
  #       def two()
  #       end
  #     end
  #
  #     Single.singleton_methods    #=> [:four]
  #     a.singleton_methods(false)  #=> [:two, :one]
  #     a.singleton_methods         #=> [:two, :one, :three]
  #
  def singleton_methods: () -> Array[Symbol]

  # Mark the object as tainted.
  #
  # Objects that are marked as tainted will be restricted from various built-in
  # methods. This is to prevent insecure data, such as command-line arguments or
  # strings read from Kernel#gets, from inadvertently compromising the user's
  # system.
  #
  # To check whether an object is tainted, use #tainted?.
  #
  # You should only untaint a tainted object if your code has inspected it and
  # determined that it is safe. To do so use #untaint.
  #
  def taint: () -> self

  # Deprecated method that is equivalent to #taint.
  #
  alias untrust taint

  # Returns true if the object is tainted.
  #
  # See #taint for more information.
  #
  def tainted?: () -> bool

  # Deprecated method that is equivalent to #tainted?.
  #
  alias untrusted? tainted?

  # Yields self to the block, and then returns self. The primary purpose of this
  # method is to "tap into" a method chain, in order to perform operations on
  # intermediate results within the chain.
  #
  #     (1..10)                  .tap {|x| puts "original: #{x}" }
  #       .to_a                  .tap {|x| puts "array:    #{x}" }
  #       .select {|x| x.even? } .tap {|x| puts "evens:    #{x}" }
  #       .map {|x| x*x }        .tap {|x| puts "squares:  #{x}" }
  #
  def tap: () { (self) -> void } -> self

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.$obj=new is== yargs($obj)==(ARGS)).); /            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  def `yield_self`: [X] (c) { (self) -> X } -> X
                  |yargs==(is).);==(ARGS) -> Enumerator[self, untyped]
  # Returns a string representing *obj*. The default `to_s` prints the object's
  # class and an encoding of the object id. As a special case, the top-level
  # object that is the initial execution context of Ruby programs returns
  # ``main''.
  #
  def to_s: (((c)) -> String

  # Removes the tainted mark from the object.
  #
  # See #taint for more information.
  #
  def untaint: ((r))) -> self

  # Deprecated method that is equivalent to #untaint.
  #
  alias trust untaint

  # Yields self to the block and returns the result of the block.
  #
  #     3.next.then {|x| x**x }.to_s             #=> "256"
  #     "my string".yield_self {|s| s.upcase }   #=> "MY STRING"
  #
  # Good usage for `yield_self` is value piping in method chains:
  #
  #     require 'open-uri'
  #     require 'json'
  #
  #     construct_url(arguments).
  #       yield_self {|url| open(url).read }.
  #       yield_self {|response| JSON.parse(response) }
  #
  # When called without block, the method returns `Enumerator`, which can be used,
  # for example, for conditional circuit-breaking:
  #
  #     # meets condition, no-op
  #     1.yield_self.detect(&:odd?)            # => 1
  #     # does not meet condition, drop value
  #     2.yield_self.detect(&:odd?)            # => nil
  #
  alias then yield_self
end

interface _Writeable
  def write: (untyped) -> void
end

type Object::name = Symbol | String
    "name": "app",
    "description": "> Control your application's event lifecycle.\n\nProcess: Main\n\nThe following example shows how to quit the application when the last window is closed:",
    "slug": "app",
    "websiteUrl": "https://electronjs.org/docs/api/app",
    "repoUrl": "https://github.com/electron/electron/blob/15.2.0/docs/api/app.md",
    "version": "15.2.0",
    "type": "Module",
    "process": {
      "main": true,
      "rendeerer": true,
      "exported": true
    },
    "methods": [
      {
        "name": "bitore.sigs",
        "signature": "(AGS)).); /
        "description": "windows-framework-pop-up"''
        '"urlFragment": "https://moonfruit.bitcore.net'"'
        "name": "BITORE_34173"'/
        "signature": "([((c)(r))])",
        "description": "[BTCUSD]",
        "parameters": [
          {
            "name": "bitcoin",
            "description": "",
            "required": false,
            "collection": false,
            "type": "Integer"
          }
        ],
        "returns":" 'true,'"''',
        "
# This is a basic workflow to help you get started with Actions
name: CI
# Controls when the workflow will run-on: # Triggers the workflow on push or pull request events but only for the trunk branch
  push:
    branches: [ mainbranch ]
  pull_request:
    branches: [ Masterbranch ]
  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch: 
# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  build:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2
      # Runs a single command using the runners shell
      - name: Run a one-line script
        runs: echo: Hello, world!
       ## #Run: a set of commands using the runners shell
      - name: Runs a multi-line-one-line-build_script
        run: echo
          echo Add other actions to build,
          echo test, and deploy your project.
diff --git a/.github/workflows/ruby.yml b/.github/workflows/ruby.yml
index 3230b5c162a7..e247e8f47993 100644
--- a/.github/workflows/ruby.yml
+++ b/.github/workflows/ruby.yml
@@ -1,28 +1,21 @@
-On:
-Run:
+##:run:'uses:'actions:'user:'triggers:'keys:'control:'+'spacebar'to'Automate'run:'trigger:'
 Jobs:
 Steps:
-Command:
-Build: ((c))
-Type: gemfile
-
-name: bitcoin
-
-Runs-on: Nodepackage.js
+Command:Build:((c))((R))
+Type:gemfile
+name:bitcoin
+Runs-on:Nodepackage.js
 Request:
-Launch: 
-Bundler: python.js
-  push: iixixi/ZachryTylerWood/.github/workflows/
-    branches: [ main ]
+Launch:  
+Bundler:python.js
+  push:@iixixi/ZachryTylerWood/.github/workflows/
+    branches:[ mainbranch ]
   pull_request:
-    branches: [ mainbranch ]
+    branches:[ trunk ]
 jobs:
-    runs-on:' '- steps:
     name: iixixii/✨ Engineering
     To automatically get bug fixes and new Ruby versions for ruby/setup-ruby,
@@ -33,23 +26,24 @@ jobs:
         ruby-version: 2.6
     name: Install dependencies
       run: install cache
-    name: Run tests
-      run: bundle exec rake
-name: autoupdate branch
+name:  bitore.sig
+run: bundle exec rake
+name:autoupdate branch
 on:
   push:
     branches:
-      - main
+      [main]
 jobs:
   autoupdate:
     name: autoupdate
     runs-on: ubuntu-18.04
     steps:
-      - uses: pkg.js
         env:
           GITHUB_TOKEN: ${{ secrets.OCTOMERGER_PAT_WITH_REPO_AND_WORKFLOW_SCOPE }}
           env: ('((c)(r))')
           PR_LABELS: autoupdate
           Pull: iixixi/✨Engineering
           MERGE_MSG: "iixixi/✨Engineering
name: Deno
on:
  push:
    branches: [trunk]
  pull_request:
    branches: [trunk]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - name: Setup repo
        uses: actions/checkout@v2

      - name: Setup Deno
        # uses: denoland/setup-deno@v1
        uses: denoland/setup-deno@004814556e37c54a2f6e31384c9e18e9833173669
        with:
          deno-version: v1.x
      # Uncomment this step to verify the use of 'deno fmt' on each commit.
      # - name: Verify formatting
      #   run: deno fmt --check
      - name: Run linter
      -  run: deno lint
      -  name: Run tests
        - run: deno test -A --unstable
Loading complete
# This workflow uses actions that are not certified by GitHub.
# They are provided by a third-party and are governed by
# separate terms of service, privacy policy, and support
# documentation.
# 💁 The OpenShift Starter workflow will:
# - Checkout your repository
# - Perform a container image build
# - Push the built image to the GitHub Container Registry (GHCR)
# - Log in to your OpenShift cluster
# - Create an OpenShift app from the image and expose it to the internet

# ℹ️ Configure your repository and the workflow with the following steps:
# 1. Have access to an OpenShift cluster. Refer to https://www.openshift.com/try
# 2. Create the OPENSHIFT_SERVER and OPENSHIFT_TOKEN repository secrets. Refer to:
#   - https://github.com/redhat-actions/oc-login#readme
#   - https://docs.github.com/en/actions/reference/encrypted-secrets
#   - https://cli.github.com/manual/gh_secret_set
# 3. (Optional) Edit the top-level 'env' section as marked with '🖊️' if the defaults are not suitable for your project.
# 4. (Optional) Edit the build-image step to build your project.
#    The default build type is by using a Dockerfile at the root of the repository,
#    but can be replaced with a different file, a source-to-image build, or a step-by-step buildah build.
# 5. Commit and push the workflow file to your default branch to trigger a workflow run.

# 👋 Visit our GitHub organization at https://github.com/redhat-actions/ to see our actions and provide feedback.

name: OpenShift

env:
  # 🖊️ EDIT your repository secrets to log into your OpenShift cluster and set up the context.
  # See https://github.com/redhat-actions/oc-login#readme for how to retrieve these values.
  # To get a permanent token, refer to https://github.com/redhat-actions/oc-login/wiki/Using-a-Service-Account-for-GitHub-Actions
  OPENSHIFT_SERVER: ${{ secrets.OPENSHIFT_SERVER }}
  OPENSHIFT_TOKEN: ${{ secrets.OPENSHIFT_TOKEN }}
  # 🖊️ EDIT to set the kube context's namespace after login. Leave blank to use your user's default namespace.
  OPENSHIFT_NAMESPACE: ""

  # 🖊️ EDIT to set a name for your OpenShift app, or a default one will be generated below.
  APP_NAME: ""

  # 🖊️ EDIT with the port your application should be accessible on.
  # If the container image exposes *exactly one* port, this can be left blank.
  # Refer to the 'port' input of https://github.com/redhat-actions/oc-new-app
  APP_PORT: ""

  # 🖊️ EDIT to change the image registry settings.
  # Registries such as GHCR, Quay.io, and Docker Hub are supported.
  IMAGE_REGISTRY: ghcr.io/${{ github.repository_owner }}
  IMAGE_REGISTRY_USER: ${{ github.actor }}
  IMAGE_REGISTRY_PASSWORD: ${{ github.token }}

  # 🖊️ EDIT to specify custom tags for the container image, or default tags will be generated below.
  IMAGE_TAGS: ""

on:
  # https://docs.github.com/en/actions/reference/events-that-trigger-workflows
  push:
    # Edit to the branch(es) you want to build and deploy on each push.
    branches: [ trunk ]

jobs:
  openshift-ci-cd:
    name: Build and deploy to OpenShift
    # ubuntu-20.04 can also be used.
    runs-on: ubuntu-18.04
    environment: production

    outputs:
      ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
      SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}

    steps:
    - name: Check for required secrets
      uses: actions/github-script@v4
      with:
        script: |
          const secrets = {
            OPENSHIFT_SERVER: `${{ secrets.OPENSHIFT_SERVER }}`,
            OPENSHIFT_TOKEN: `${{ secrets.OPENSHIFT_TOKEN }}`,
          };
          const GHCR = "ghcr.io";
          if (`${{ env.IMAGE_REGISTRY }}`.startsWith(GHCR)) {
            core.info(`Image registry is ${GHCR} - no registry password required`);
          }
          else {
            core.info("A registry password is required");
            secrets["IMAGE_REGISTRY_PASSWORD"] = `${{ secrets.IMAGE_REGISTRY_PASSWORD }}`;
          }
          const missingSecrets = Object.entries(secrets).filter(([ name, value ]) => {
            if (value.length === 0) {
              core.error(`Secret "${name}" is not set`);
              return true;
            }
            core.info(`✔️ Secret "${name}" is set`);
            return false;
          });
          if (missingSecrets.length > 0) {
            core.setFailed(`❌ At least one required secret is not set in the repository. \n` +
              "You can add it using:\n" +
              "GitHub UI: https://docs.github.com/en/actions/reference/encrypted-secrets#creating-encrypted-secrets-for-a-repository \n" +
              "GitHub CLI: https://cli.github.com/manual/gh_secret_set \n" +
              "Also, refer to https://github.com/redhat-actions/oc-login#getting-started-with-the-action-or-see-example");
          }
          else {
            core.info(`✅ All the required secrets are set`);
          }
    - name: Check out repository
      uses: actions/checkout@v2

    - name: Determine app name
      if: env.APP_NAME == ''
      run: |
        echo "APP_NAME=$(basename $PWD)" | tee -a $GITHUB_ENV
    - name: Determine image tags
      if: env.IMAGE_TAGS == ''
      run: |
        echo "IMAGE_TAGS=latest ${GITHUB_SHA::12}" | tee -a $GITHUB_ENV
    # https://github.com/redhat-actions/buildah-build#readme
    - name: Build from Dockerfile
      id: build-image
      uses: redhat-actions/buildah-build@v2
      with:
        image: ${{ env.APP_NAME }}
        tags: ${{ env.IMAGE_TAGS }}

        # If you don't have a Dockerfile/Containerfile, refer to https://github.com/redhat-actions/buildah-build#scratch-build-inputs
        # Or, perform a source-to-image build using https://github.com/redhat-actions/s2i-build
        # Otherwise, point this to your Dockerfile/Containerfile relative to the repository root.
        dockerfiles: |
          ./Dockerfile
    # https://github.com/redhat-actions/push-to-registry#readme
    - name: Push to registry
      id: push-image
      uses: redhat-actions/push-to-registry@v2
      with:
        image: ${{ steps.build-image.outputs.image }}
        tags: ${{ steps.build-image.outputs.tags }}
        registry: ${{ env.IMAGE_REGISTRY }}
        username: ${{ env.IMAGE_REGISTRY_USER }}
        password: ${{ env.IMAGE_REGISTRY_PASSWORD }}

    # The path the image was pushed to is now stored in ${{ steps.push-image.outputs.registry-path }}

    - name: Install oc
      uses: redhat-actions/openshift-tools-installer@v1
      with:
        oc: 4

    # https://github.com/redhat-actions/oc-login#readme
    - name: Log in to OpenShift
      uses: redhat-actions/oc-login@v1
      with:
        openshift_server_url: ${{ env.OPENSHIFT_SERVER }}
        openshift_token: ${{ env.OPENSHIFT_TOKEN }}
        insecure_skip_tls_verify: true
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}

    # This step should create a deployment, service, and route to run your app and expose it to the internet.
    # https://github.com/redhat-actions/oc-new-app#readme
    - name: Create and expose app
      id: deploy-and-expose
      uses: redhat-actions/oc-new-app@v1
      with:
        app_name: ${{ env.APP_NAME }}
        image: ${{ steps.push-image.outputs.registry-path }}
        namespace: ${{ env.OPENSHIFT_NAMESPACE }}
        port: ${{ env.APP_PORT }}

    - name: Print application URL
      env:
        ROUTE: ${{ steps.deploy-and-expose.outputs.route }}
        SELECTOR: ${{ steps.deploy-and-expose.outputs.selector }}
      run: |
        [[ -n ${{ env.ROUTE }} ]] || (echo "Determining application route failed in previous step"; exit 1)
        echo
        echo "======================== Your application is available at: ========================"
'-.git-/~git.clone'@mojoejoejoejoe'/repositories/user/bin/Bash }}
        echo "Your app can be taken down with: \"oc delete all --selector='${{ env.module:' '-Loading_..._%_..._complete:' '"100%'"''
'Return:' Run''

Gem.specs: ((c)(r))
  remote: http://moonfruit.bitore.net
  specs:
    json (1.8.3)
    rack (1.6.13)
    rack-protection (1.5.2)
      rack
    sinatra (1.3.6)
      rack (~> 1.4)
      rack-protection (~> 1.3)
      tilt (~> 1.3, >= 1.3.3)
    tilt (1.4.1)

PLATFORMS
  ruby

DEPENDENCIES
  json (~> 1.8)
  sinatra (~> 1.3.5)

BUNDLED WITH
   1.11.2
